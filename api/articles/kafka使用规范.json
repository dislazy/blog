{"title":"kafka使用规范","slug":"kafka使用规范","date":"2018-10-12T01:56:05.000Z","updated":"2022-06-02T01:05:59.615Z","comments":true,"path":"api/articles/kafka使用规范.json","excerpt":"客户端：根据具体消息业务需要，调整配置以下参数：","covers":null,"content":"<h3 id=\"客户端：\"><a href=\"#客户端：\" class=\"headerlink\" title=\"客户端：\"></a>客户端：</h3><p>根据具体消息业务需要，调整配置以下参数：</p>\n<p>1.是否启用压缩方式compressionCodec</p>\n<p>2.消息确认方式：request.required.acks</p>\n<p>3.消息发送类型，同步异步：producer.type</p>\n<p>4.异步模式下缓冲的最大消息数(queue.buffering.max.messages)</p>\n<p>5.异步模式下，每次发送的消息数(batch.num.messages)</p>\n<p>6.消费者socket接收缓存空间大小(socket.receive.buffer.bytes)</p>\n<p>7.消费者从每个分区fetch的消息大小(fetch.message.max.bytes)</p>\n<p>8.消费者配置rebalance.max.retries * rebalance.backoff.ms &gt; zookeeper.session.timeout.ms</p>\n<p>9.消费者消费起始位置配置：auto.offset.reset</p>\n<p>10.消费者group.id</p>\n<h3 id=\"服务端：\"><a href=\"#服务端：\" class=\"headerlink\" title=\"服务端：\"></a>服务端：</h3><p>1.调整服务器最大打开文件数限制：ulimit</p>\n<p>2.Kafka建议开启JMX监控端口</p>\n<p>3.broker配置：</p>\n<p>kafka server.properties配置参数策略</p>\n<p>注：以下各值仅供参考，具体配置值需根据实际硬件环境情况调整</p>\n<p>必须的参数配置：</p>\n<p> #broker在集群中的唯一表示</p>\n<p>broker.id&#x3D;0</p>\n<p> #broker处理消息的最大线程数，建议为cpu核数</p>\n<p>num.network.threads&#x3D;4</p>\n<p> #broker处理磁盘IO的线程数 ，建议为cpu核数2倍</p>\n<p>num.io.threads&#x3D;8</p>\n<p> #socket的发送缓冲区</p>\n<p>socket.send.buffer.bytes&#x3D;1048576</p>\n<p> #socket的接受缓冲区</p>\n<p>socket.receive.buffer.bytes&#x3D;1048576</p>\n<p> #socket请求的最大数值，防止serverOOM，message.max.bytes要小于socket.request.max.bytes，会被topic创建时的指定参数覆盖</p>\n<p>socket.request.max.bytes&#x3D;104857600</p>\n<p> #kafka数据的存放地址，多个地址的话用逗号分割,多个目录分布在不同磁盘上可以提高读写性能 log.dirs&#x3D;&#x2F;tmp&#x2F;kafka-logs</p>\n<p> #topic的分区个数,根据broker数量灵活调整</p>\n<p>num.partitions&#x3D;2</p>\n<p> #数据文件保留多长时间， 存储的最大时间,超过这个时间会根据log.cleanup.policy设置数据清除策略 log.retention.hours&#x3D;168</p>\n<p> #topic的分区是以一堆segment文件存储的，控制每个segment的大小</p>\n<p>log.segment.bytes&#x3D;536870912</p>\n<p> #文件大小检查的周期时间，是否触发 log.cleanup.policy中设置的策略</p>\n<p>log.retention.check.interval.ms&#x3D;600000</p>\n<p> #是否开启日志清理</p>\n<p>log.cleaner.enable&#x3D;true</p>\n<p> #zookeeper集群的地址，逗号分隔多个</p>\n<p>zookeeper.connect&#x3D;</p>\n<p> #ZooKeeper连接超时时间</p>\n<p>zookeeper.connection.timeout.ms&#x3D;1000000</p>\n<p>建议优化的参数配置：</p>\n<p> #broker的主机地址，默认null,一般不设置.</p>\n<p> #若是设置会绑定到这个特定地址（IP或hostName,若设置为hostname时消费者端服务器需配置host解析）</p>\n<p> #若是没有，会绑定到所有的IP地址上，并将其中之一发送到ZK</p>\n<p>host.name&#x3D;borkerIp</p>\n<p> #为提高producer写入TPS,建议设置如下参数，取值根据应用情况</p>\n<p> #每达到消息数时写入磁盘</p>\n<p>log.flush.interval.messages&#x3D;10000</p>\n<p> #每间隔1秒钟时间，刷数据到磁盘</p>\n<p>log.flush.interval.ms&#x3D;1000</p>\n<p> #日志文件清理策略：delete和compact（删除\\压缩）主要针对过期数据的处理</p>\n<p>log.cleanup.policy &#x3D; delete</p>\n<p> #replication对写入TPS有影响，建议设置为最小副本数</p>\n<p>default.replication.factor&#x3D;3</p>\n\n","more":"\n<p>1.是否启用压缩方式compressionCodec</p>\n<p>2.消息确认方式：request.required.acks</p>\n<p>3.消息发送类型，同步异步：producer.type</p>\n<p>4.异步模式下缓冲的最大消息数(queue.buffering.max.messages)</p>\n<p>5.异步模式下，每次发送的消息数(batch.num.messages)</p>\n<p>6.消费者socket接收缓存空间大小(socket.receive.buffer.bytes)</p>\n<p>7.消费者从每个分区fetch的消息大小(fetch.message.max.bytes)</p>\n<p>8.消费者配置rebalance.max.retries * rebalance.backoff.ms &gt; zookeeper.session.timeout.ms</p>\n<p>9.消费者消费起始位置配置：auto.offset.reset</p>\n<p>10.消费者group.id</p>\n<h3 id=\"服务端：\"><a href=\"#服务端：\" class=\"headerlink\" title=\"服务端：\"></a>服务端：</h3><p>1.调整服务器最大打开文件数限制：ulimit</p>\n<p>2.Kafka建议开启JMX监控端口</p>\n<p>3.broker配置：</p>\n<p>kafka server.properties配置参数策略</p>\n<p>注：以下各值仅供参考，具体配置值需根据实际硬件环境情况调整</p>\n<p>必须的参数配置：</p>\n<p> #broker在集群中的唯一表示</p>\n<p>broker.id&#x3D;0</p>\n<p> #broker处理消息的最大线程数，建议为cpu核数</p>\n<p>num.network.threads&#x3D;4</p>\n<p> #broker处理磁盘IO的线程数 ，建议为cpu核数2倍</p>\n<p>num.io.threads&#x3D;8</p>\n<p> #socket的发送缓冲区</p>\n<p>socket.send.buffer.bytes&#x3D;1048576</p>\n<p> #socket的接受缓冲区</p>\n<p>socket.receive.buffer.bytes&#x3D;1048576</p>\n<p> #socket请求的最大数值，防止serverOOM，message.max.bytes要小于socket.request.max.bytes，会被topic创建时的指定参数覆盖</p>\n<p>socket.request.max.bytes&#x3D;104857600</p>\n<p> #kafka数据的存放地址，多个地址的话用逗号分割,多个目录分布在不同磁盘上可以提高读写性能 log.dirs&#x3D;&#x2F;tmp&#x2F;kafka-logs</p>\n<p> #topic的分区个数,根据broker数量灵活调整</p>\n<p>num.partitions&#x3D;2</p>\n<p> #数据文件保留多长时间， 存储的最大时间,超过这个时间会根据log.cleanup.policy设置数据清除策略 log.retention.hours&#x3D;168</p>\n<p> #topic的分区是以一堆segment文件存储的，控制每个segment的大小</p>\n<p>log.segment.bytes&#x3D;536870912</p>\n<p> #文件大小检查的周期时间，是否触发 log.cleanup.policy中设置的策略</p>\n<p>log.retention.check.interval.ms&#x3D;600000</p>\n<p> #是否开启日志清理</p>\n<p>log.cleaner.enable&#x3D;true</p>\n<p> #zookeeper集群的地址，逗号分隔多个</p>\n<p>zookeeper.connect&#x3D;</p>\n<p> #ZooKeeper连接超时时间</p>\n<p>zookeeper.connection.timeout.ms&#x3D;1000000</p>\n<p>建议优化的参数配置：</p>\n<p> #broker的主机地址，默认null,一般不设置.</p>\n<p> #若是设置会绑定到这个特定地址（IP或hostName,若设置为hostname时消费者端服务器需配置host解析）</p>\n<p> #若是没有，会绑定到所有的IP地址上，并将其中之一发送到ZK</p>\n<p>host.name&#x3D;borkerIp</p>\n<p> #为提高producer写入TPS,建议设置如下参数，取值根据应用情况</p>\n<p> #每达到消息数时写入磁盘</p>\n<p>log.flush.interval.messages&#x3D;10000</p>\n<p> #每间隔1秒钟时间，刷数据到磁盘</p>\n<p>log.flush.interval.ms&#x3D;1000</p>\n<p> #日志文件清理策略：delete和compact（删除\\压缩）主要针对过期数据的处理</p>\n<p>log.cleanup.policy &#x3D; delete</p>\n<p> #replication对写入TPS有影响，建议设置为最小副本数</p>\n<p>default.replication.factor&#x3D;3</p>\n\n","categories":[{"name":"研发规范","path":"api/categories/研发规范.json"}],"tags":[{"name":"kafka","path":"api/tags/kafka.json"}]}