{"meta":{"title":"星空","subtitle":"Storms make trees take deeper roots.","description":"Jack，现居于北京朝阳，专注于Devops 技术人生 Java Golang 微服务 云计算，这是Jack的个人博客站","author":"Jack","url":"https://blog.bosong.online"},"pages":[{"title":"404","date":"2022-06-02T01:05:59.611Z","updated":"2022-06-02T01:05:59.611Z","comments":false,"path":"/404.html","permalink":"https://blog.bosong.online/404.html","excerpt":"","text":"12345678910111213██╗ ██╗ ██████╗ ██╗ ██╗ ███╗ ██╗ ██████╗ ████████╗██║ ██║██╔═████╗██║ ██║ ████╗ ██║██╔═══██╗╚══██╔══╝███████║██║██╔██║███████║ ██╔██╗ ██║██║ ██║ ██║╚════██║████╔╝██║╚════██║ ██║╚██╗██║██║ ██║ ██║ ██║╚██████╔╝ ██║ ██║ ╚████║╚██████╔╝ ██║ ╚═╝ ╚═════╝ ╚═╝ ╚═╝ ╚═══╝ ╚═════╝ ╚═╝ ███████╗ ██████╗ ██╗ ██╗███╗ ██╗██████╗ ██╔════╝██╔═══██╗██║ ██║████╗ ██║██╔══██╗ █████╗ ██║ ██║██║ ██║██╔██╗ ██║██║ ██║ ██╔══╝ ██║ ██║██║ ██║██║╚██╗██║██║ ██║ ██║ ╚██████╔╝╚██████╔╝██║ ╚████║██████╔╝ ╚═╝ ╚═════╝ ╚═════╝ ╚═╝ ╚═══╝╚═════╝","raw":null,"content":null},{"title":"关于","date":"2018-10-10T07:05:27.000Z","updated":"2022-06-02T01:05:59.618Z","comments":true,"path":"about/index.html","permalink":"https://blog.bosong.online/about/index.html","excerpt":"","text":"只此一生,何必从众 我 base帝都的后端程序员, Java&#x2F;Golang&#x2F;Python 都有涉猎，主要从事web开发、数据分析、微服务的devops相关，欢迎与我交流 爱好 喜欢尝试与实践新的技术 经常参与各种有趣的活动 喜欢写个人博客，记录生活点滴 联系方式 email ：&#115;&#111;&#x6e;&#x67;&#x62;&#x6f;&#x32;&#48;&#x32;&#49;&#x40;&#x6f;&#x75;&#116;&#x6c;&#111;&#111;&#107;&#x2e;&#x63;&#x6f;&#x6d; github: https://github.com/dislazy 公益工具 人生若只如初见: https://www.songbo.fun dailynotes: https://daily.songbo.fun bitwarden: https://bitwarden.songbo.fun docs: https://docs.songbo.fun","raw":null,"content":null},{"title":"archives","date":"2018-10-10T07:06:55.000Z","updated":"2022-06-02T01:05:59.618Z","comments":true,"path":"archives/index.html","permalink":"https://blog.bosong.online/archives/index.html","excerpt":"","text":"","raw":null,"content":null},{"title":"分类","date":"2018-10-10T12:20:25.000Z","updated":"2022-06-02T01:05:59.618Z","comments":false,"path":"categories/index.html","permalink":"https://blog.bosong.online/categories/index.html","excerpt":"","text":"","raw":null,"content":null},{"title":"标签","date":"2018-10-10T12:20:47.000Z","updated":"2022-06-02T01:05:59.618Z","comments":false,"path":"tags/index.html","permalink":"https://blog.bosong.online/tags/index.html","excerpt":"","text":"","raw":null,"content":null}],"posts":[{"title":"使用Authelia来实现多站的OIDC登录","slug":"使用Authelia来实现多站的OIDC登录","date":"2022-06-02T00:58:35.000Z","updated":"2022-06-02T01:05:59.617Z","comments":true,"path":"使用Authelia来实现多站的OIDC登录.html","link":"","permalink":"https://blog.bosong.online/%E4%BD%BF%E7%94%A8Authelia%E6%9D%A5%E5%AE%9E%E7%8E%B0%E5%A4%9A%E7%AB%99%E7%9A%84OIDC%E7%99%BB%E5%BD%95.html","excerpt":" \n简单说说什么是OIDC简单来说，OIDC是一个OAuth2上层的简单身份层协议。它允许客户端验证用户的身份并获取基本的用户配置信息。OIDC使用JSON Web Token（JWT）作为信息返回，通过符合OAuth2的流程来获取对应的TOKEN信息。\n它的作用是为多个不同的站点提供登录功能（和SSO类似）。每次需要使用OIDC登录网站时，都会被重定向到登录的OpenID网站，然后再回到该网站。例如，如果选择使用Github帐户登录Grafana，这就使用了OIDC。成功通过Github身份验证并授权Grafana访问您的信息后，Github会将有关用户和执行的身份验证的信息发送回Grafana。此信息在JWT中返回，包含ID Token或者Access Token。\n这样就实现了简单的登录流程，OIDC主要有以下几个作用：\n1、OIDC的协议简化了登录的流程开发工作，在支持OIDC的应用简单配置即可使用\n2、OIDC的协议有组别概念，可以限制用户可访问的资源内容\n3、一个账号根据不同的资源权限访问不同的站点内容\n","text":"简单说说什么是OIDC简单来说，OIDC是一个OAuth2上层的简单身份层协议。它允许客户端验证用户的身份并获取基本的用户配置信息。OIDC使用JSON Web Token（JWT）作为信息返回，通过符合OAuth2的流程来获取对应的TOKEN信息。 它的作用是为多个不同的站点提供登录功能（和SSO类似）。每次需要使用OIDC登录网站时，都会被重定向到登录的OpenID网站，然后再回到该网站。例如，如果选择使用Github帐户登录Grafana，这就使用了OIDC。成功通过Github身份验证并授权Grafana访问您的信息后，Github会将有关用户和执行的身份验证的信息发送回Grafana。此信息在JWT中返回，包含ID Token或者Access Token。 这样就实现了简单的登录流程，OIDC主要有以下几个作用： 1、OIDC的协议简化了登录的流程开发工作，在支持OIDC的应用简单配置即可使用 2、OIDC的协议有组别概念，可以限制用户可访问的资源内容 3、一个账号根据不同的资源权限访问不同的站点内容 如何配置Authelia来支持grafana通过OIDC登录先看官方文档 ，官方文档写的还是比较详细的，创建一个OIDC应用，只需要在configuration.yml的后面加上对应的配置即可,在本文中我以grafana配置为例，简单说明grafana使用Authelia来进行登录 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152identity_providers: oidc: hmac_secret: rc9uqHMWXf69M9TXrEfa2XoAtbXsbSGMvqWC # issuer_private_key 这个字段的内容我直接用docker-compose里面的env来替代，减少yaml中的配置长度和保护机密 #AUTHELIA_IDENTITY_PROVIDERS_OIDC_ISSUER_PRIVATE_KEY_FILE=/config/key.pem #issuer_private_key: access_token_lifespan: 1h authorize_code_lifespan: 1m id_token_lifespan: 1h refresh_token_lifespan: 90m enable_client_debug_messages: false enforce_pkce: public_clients_only cors: endpoints: - authorization - token - revocation - introspection #这里允许配置为`*`,代表全部网站 allowed_origins: &quot;*&quot; # - https://example.com allowed_origins_from_client_redirect_uris: false clients: #如果多个应用，复制下面同样的一大串进行具体配置即可 - id: grafana description: grafana secret: GzPji9HrYbLQEX sector_identifier: &#x27;&#x27; public: false #校验的级别，可以是one_factor等 authorization_policy: two_factor pre_configured_consent_duration: &#x27;&#x27; audience: [] #可以访问到的用户信息，具体有哪些，可以直接看官方文档的说明 scopes: - openid - groups - email - profile #在auth登录成功后需要重定向的接口地址，不同的应用需要根据实际情况配置 redirect_uris: - https://grafana.abc.com/login/generic_oauth grant_types: - refresh_token - authorization_code response_types: - code response_modes: - form_post - query - fragment userinfo_signing_algorithm: none 这样一个很简单的配置，就让Authelia实现了自身作为OIDC的身份提供商供 grafana 这个应用登录访问。 我们可以直接访问到你的authelia的地址来查看登录需要配置的端点信息：https://auth.example.com/.well-known/openid-configuration 将对应的auth.example.com 换成你自己的域名。 如何配置Grafana来使用Authelia提供的OIDC进行登录grafana 配置OIDC的登录官方也有完善的文档，但是我也遇到了一些小的坑点，所以我会在贴配置的同时，说明我遇到的坑点（其实是我菜）。 使用开源项目的对应功能，肯定第一步是看官方文档 ，官方文档还是写的比较详细，但是它是一个通用文档，我们需要根据实际情况做一下小的变更。 grafana使用docker-compose启动我的grafana是使用docker-compose启动的，它的配置很简单： 1234567891011121314151617181920212223242526---version: &#x27;3.3&#x27;services: grafana: image: grafana/grafana-oss:$&#123;grafana_version&#125; networks: - gateway container_name: grafana command: - &#x27;grafana-server --config /etc/grafana/grafana.ini&#x27; restart: unless-stopped env_file: .env volumes: - ./grafana.ini:/etc/grafana/grafana.ini - /data/grafana:/var/lib/grafana healthcheck: disable: false environment: - TZ=Asia/Shanghai ports: - 4000:3000networks: gateway: external: true... 这时候需要复制grafana的默认配置文件 来写到grafana.ini 文件中了，数据库信息什么的配置。 注意我在这里碰到了一个坑点：当你需要启用对应的配置时候，需要将 ;去掉，这样配置才能生效。（惯性思维是#，突然来个;号有点懵）。 grafana支持Authelia登录访问grafana 的配置写的比较简单命令，其他配置忽略的情况下，以下几个配置就能支持到authelia的登录访问了。 12345678910111213141516171819# The full public facing url you use in browser, used for redirects and emails# 这个配置为你的grafana地址，需要进行配置root_url = https://grafana.abc.com# 如果仅限OAuth仅限登录的话设置为true（建议先设置为false，待修改OIDC的权限配置为admin之后再关闭）disable_login_form = true#################################### Generic OAuth ##########################[auth.generic_oauth]enabled = truename = autheliaallow_sign_up = trueclient_id = grafanaclient_secret = GzPji9HrYbLQEXscopes = openid profile groups emailempty_scopes = falseauth_url = https://auth.example.com/api/oidc/authorizationtoken_url = https://auth.example.com/api/oidc/tokenapi_url = https://auth.example.com/oidc/userinfouse_pkce = true 配置完成后重启grafana之后，再次访问grafana就可以看到你配置的authelia登录框了，成果如下： 总结实际上我总共配置了三个client: outline、portainer 这个参考官方文档即可配置成功、grafana，除了grafana花费了些许时间之外（主要是我菜，配置没有去掉;），其他两个配置都很简单。 现在authelia这个服务已经为我的数个网站提供登录保护支持，如果你有兴趣，可以与我一起交流探索更多的有趣的玩法，如果有遇到的一些问题欢迎一起探讨。","raw":null,"content":null,"categories":[{"name":"技术手册","slug":"技术手册","permalink":"https://blog.bosong.online/categories/%E6%8A%80%E6%9C%AF%E6%89%8B%E5%86%8C/"}],"tags":[{"name":"oidc","slug":"oidc","permalink":"https://blog.bosong.online/tags/oidc/"},{"name":"authelia","slug":"authelia","permalink":"https://blog.bosong.online/tags/authelia/"},{"name":"grafana","slug":"grafana","permalink":"https://blog.bosong.online/tags/grafana/"}]},{"title":"Notebook软件的自我进化历程","slug":"Notebook软件的自我进化历程","date":"2022-05-29T13:03:59.000Z","updated":"2022-06-02T01:05:59.614Z","comments":true,"path":"Notebook软件的自我进化历程.html","link":"","permalink":"https://blog.bosong.online/Notebook%E8%BD%AF%E4%BB%B6%E7%9A%84%E8%87%AA%E6%88%91%E8%BF%9B%E5%8C%96%E5%8E%86%E7%A8%8B.html","excerpt":"说说过去对于程序员来说，有时候会有很多灵感爆发出来，然后这个时候就需要一个很灵活的笔记本能够记录自己的所思所想，快速的把想法沉淀到纸面上，而我也一直在寻找这样的一个好用的notebook。\n我曾经用过好多款的notebook，但是或多或少的不是特别符合我的需求：\n\nnotion 笔记应用中的神器了，因为是商业化的有一些限制的，或者有一些个人隐私的内容不方便记录，试用了一段时间后放弃\ntrilium 也算是一个非常好用的笔记本了，优点就是无线层级，并且能快速记录每日的一个笔记，缺点可能就是颜值过低，然后数据存储是Sqlite,使用了很长一段时间后放弃\n语雀 国产的笔记软件，它的定位是类似于wiki这样的模式，创建一个文档还是比较繁琐，至少需要连续点3击三次以上，我要的是点击一次就能创建一个文档，给提了需求无果以后放弃。\n蚂蚁笔记 蚂蚁笔记实际上是国内各种社区上推文比较多的一款了，文档也很详实，但是因为开源不再更新，所以不考虑使用\nstandardnotes  这个是用截止到目前用的时间最长的笔记软件，够简洁，但是毕竟作为一个开源的商业化软件，自建的文档写的不是特别详细，很多功能都能设置，但是不生效，备份措施很多，但是只局限于付费会员（也不提供开源的方法配置），所以我一直在寻找替代品\ndailynotes dailynotes是一款小众的开源笔记本，它的作用主要是以日期为标题记录一些工作内容，当天的todo啥的，非常好用，一开始只支持了Sqlite，但是我看完源码之后，发现非常简单，进行了一些自定义的改造和自动化部署，一直把它当做每日todo在使用，现在还用着，非常好用\nwikijs wikijs是一款我用来替代standardnotes的笔记本，部署简单，操作简单，但是它的作用还是wiki类，创建一个文档，至少要点三次，所以找到替代品以后无奈放弃\noutline 这个我发现的最晚，但是发现是最好用的笔记本，部署比较简单，但是需要的组件比较繁琐，需要PostgreSQL、自建的oidc登录、aws s3或者兼容的tencent cos等,主要是有层级结构，颜值还行，操作简单，我创建文档点一下就可以，备份也很简单，会帮我直接存储到tencent cos上，不用担心数据丢失。\n\n我对Notebook的要求也比较简单:\n\n支持web页面访问，我有几个电脑，用软件的话一个一个下载怕是要疯\n创建文档或者笔记简单，最好是点一下就可以，并且支持markdown编辑器\n备份简单，最好能直接备份我的原始markdown文档，不给markdown重命名或者添加一个特别的标签\n数据安全 数据安全最合适的方法就是开源笔记，数据都在自己手上，不用担心泄密\n\n说说当前自从发现了outline以后，我还尝试着去注册，试用一下，然而在官网给了我致命打击，只支持组织类的账户注册，还都是google&#x2F;slack等软件，然后发现开源，我就试着看对应的搭建文档，总体还是比较简单，它面向的客户主要是企业类客户，所以很多方面设计是偏向于企业化设计的，包括组件，刚好我有一些替代品：\n\nPostgreSQL 刚好我有自建的,没有成本直接使用\nRedis 刚好我有自建的，没有成本直接使用\nMail 刚好我有自己的邮箱服务器，也是可以直接使用\nOIDC 刚好我自己一直在使用的web层sso软件: authelia 支持OIDC,简单配置一番即可使用\nAWS S3 我是长期使用tencent cos 它是兼容s3协议的，虽然稍微有些不完美，但是还是可以使用，这个备份的文件直接存储到cos上\n\n一切就是那么的巧合，我迫不及待的创建好数据库和对应的账户，创建好cos的存储桶和单独的ak,配置基于authelia的OIDC，那么一切就开始了，就很简单，创建好.env 然后放入在github仓库中复制的模板，创建好docker-compose文件，一键启动。\n","text":"说说过去对于程序员来说，有时候会有很多灵感爆发出来，然后这个时候就需要一个很灵活的笔记本能够记录自己的所思所想，快速的把想法沉淀到纸面上，而我也一直在寻找这样的一个好用的notebook。 我曾经用过好多款的notebook，但是或多或少的不是特别符合我的需求： notion 笔记应用中的神器了，因为是商业化的有一些限制的，或者有一些个人隐私的内容不方便记录，试用了一段时间后放弃 trilium 也算是一个非常好用的笔记本了，优点就是无线层级，并且能快速记录每日的一个笔记，缺点可能就是颜值过低，然后数据存储是Sqlite,使用了很长一段时间后放弃 语雀 国产的笔记软件，它的定位是类似于wiki这样的模式，创建一个文档还是比较繁琐，至少需要连续点3击三次以上，我要的是点击一次就能创建一个文档，给提了需求无果以后放弃。 蚂蚁笔记 蚂蚁笔记实际上是国内各种社区上推文比较多的一款了，文档也很详实，但是因为开源不再更新，所以不考虑使用 standardnotes 这个是用截止到目前用的时间最长的笔记软件，够简洁，但是毕竟作为一个开源的商业化软件，自建的文档写的不是特别详细，很多功能都能设置，但是不生效，备份措施很多，但是只局限于付费会员（也不提供开源的方法配置），所以我一直在寻找替代品 dailynotes dailynotes是一款小众的开源笔记本，它的作用主要是以日期为标题记录一些工作内容，当天的todo啥的，非常好用，一开始只支持了Sqlite，但是我看完源码之后，发现非常简单，进行了一些自定义的改造和自动化部署，一直把它当做每日todo在使用，现在还用着，非常好用 wikijs wikijs是一款我用来替代standardnotes的笔记本，部署简单，操作简单，但是它的作用还是wiki类，创建一个文档，至少要点三次，所以找到替代品以后无奈放弃 outline 这个我发现的最晚，但是发现是最好用的笔记本，部署比较简单，但是需要的组件比较繁琐，需要PostgreSQL、自建的oidc登录、aws s3或者兼容的tencent cos等,主要是有层级结构，颜值还行，操作简单，我创建文档点一下就可以，备份也很简单，会帮我直接存储到tencent cos上，不用担心数据丢失。 我对Notebook的要求也比较简单: 支持web页面访问，我有几个电脑，用软件的话一个一个下载怕是要疯 创建文档或者笔记简单，最好是点一下就可以，并且支持markdown编辑器 备份简单，最好能直接备份我的原始markdown文档，不给markdown重命名或者添加一个特别的标签 数据安全 数据安全最合适的方法就是开源笔记，数据都在自己手上，不用担心泄密 说说当前自从发现了outline以后，我还尝试着去注册，试用一下，然而在官网给了我致命打击，只支持组织类的账户注册，还都是google&#x2F;slack等软件，然后发现开源，我就试着看对应的搭建文档，总体还是比较简单，它面向的客户主要是企业类客户，所以很多方面设计是偏向于企业化设计的，包括组件，刚好我有一些替代品： PostgreSQL 刚好我有自建的,没有成本直接使用 Redis 刚好我有自建的，没有成本直接使用 Mail 刚好我有自己的邮箱服务器，也是可以直接使用 OIDC 刚好我自己一直在使用的web层sso软件: authelia 支持OIDC,简单配置一番即可使用 AWS S3 我是长期使用tencent cos 它是兼容s3协议的，虽然稍微有些不完美，但是还是可以使用，这个备份的文件直接存储到cos上 一切就是那么的巧合，我迫不及待的创建好数据库和对应的账户，创建好cos的存储桶和单独的ak,配置基于authelia的OIDC，那么一切就开始了，就很简单，创建好.env 然后放入在github仓库中复制的模板，创建好docker-compose文件，一键启动。 数据迁移数据迁移一直是一件比较难受的事情，我之前从standardnotes迁移到wikijs 在周末的深夜花了两三个小时，迁移我的接近100多篇的各种文档，然后第二天睡醒就感觉wikijs可能用不长久了，因为创建一个文档要点三次以上。 然而outline的迁移远比我想象的要简单，直接把wikijs的github上的备份仓库下载下来，然后直接把markdown里面的标题等信息全部手动移除，直接导入到outline就可以了，它支持直接导入文档，我只花了十几分钟来去掉markdown里面的多余信息，就完成了备份迁移过程。 我目前使用的开源软件使用开源软件最多的目的是为了减少数据泄密，还有方便自己的生活，列举一下我目前在使用的开源软件 bitwarden 开源的密码管理软件，我用的是社区爱好者自己根据官方的接口进行重新实现的版本，它搭配chrome的bitwarden插件我压根没手动输入过密码，而且我的绝大多数密码都是复杂密码，不用担心账号被盗取 authelia 开源的SSO，它可以直接在Nginx层配置没有账号密码管理的软件，给他们套上一层登录，减少了大量的账号系统的开发工作，它目前在防护我的web版ssh页面、大学毕业班级相册、包括OIDC的outline等服务 squoosh 是google开源的图片压缩软件，我主要担心图片被泄露，所以打包开源代码自建了一个，放在cdn上也能加快访问速度，它是完全本地化的图片裁剪，不会把图片存储到服务器上 sshwifty 颜值比较高的还比较简单的web版ssh管理工具，用过很多，要么特别重，要么颜值很低，这款比较轻量，我在前面套上authelia提供的SSO，也不用担心被随意访问我的私人服务器 dailynotes 目前使用的每日记录工具，它和notebook的区别是以当天日期记录的一个笔记，适合用来做日常工作todo，时间久了往前倒倒看最近每天或者过去一个阶段做了点啥，还是比较合适，比较轻量，导出备份也是特别简单 grafana 这个主要是用来看云服务器监控指标，属于运维类的，平常使用率不是特别高 serverStatus 主要是用来看云服务器的基础指标，部署和使用都比较简单 outline 日常使用的笔记本，目前使用起来非常顺畅，导出数据也是很简单 portainer docker容器的管理软件，基本上用它来在线看各个机器上的docker指标等信息 cloudbeaver 在线的mysql等的链接工具，直接在网页上使用，平常如果换到陌生机器的话不用安装软件就可以直接快速查找数据库 …其实还有一些，但是因为使用频次不是特别高，所以没有特别的列举出来 总结这篇文章主要就是讲述一下我的网络版notebook的软件使用历史，一个好用的工具能让你节省很多的时间和精力，并且能让你的思绪能够快速的被记录下来。工欲善其事必先利其器，我算是一个喜欢折腾的人，平常会收集很多自己常用的软件，大部分是开源软件，对于我来说数据安全得到了保障，并且能增加我的阅历和生活，给无聊的生活带来一些乐趣，像OIDC这种东西，如果不是运维啊什么的，基本上很难去接触到，这也算是对自己技术能力的一个提升。 我对现代化软件最大的期望就是都能够在浏览器里直接运行，并且最好能在国内访问，这样速度和安全性都能得到保障，安装软件还算是一件比较痛苦的事情。 作为喜欢使用开源软件的程序员，也是深深的感谢开源文化，我日常也在积极参与开源，不局限于给常用的软件提PR，提升用户体验和自己的一些体验，自己也有一些开源的项目，比较简单，就主要是为了增加自己各种项目的自动化进程，减少人工干预。","raw":null,"content":null,"categories":[{"name":"常用软件","slug":"常用软件","permalink":"https://blog.bosong.online/categories/%E5%B8%B8%E7%94%A8%E8%BD%AF%E4%BB%B6/"}],"tags":[{"name":"开源","slug":"开源","permalink":"https://blog.bosong.online/tags/%E5%BC%80%E6%BA%90/"},{"name":"notebook","slug":"notebook","permalink":"https://blog.bosong.online/tags/notebook/"}]},{"title":"使用简单脚本实现github与其他所有git仓库的双向同步","slug":"使用简单脚本实现github与其他所有git仓库的双向同步","date":"2022-05-20T00:35:48.000Z","updated":"2022-06-02T01:05:59.617Z","comments":true,"path":"使用简单脚本实现github与其他所有git仓库的双向同步.html","link":"","permalink":"https://blog.bosong.online/%E4%BD%BF%E7%94%A8%E7%AE%80%E5%8D%95%E8%84%9A%E6%9C%AC%E5%AE%9E%E7%8E%B0github%E4%B8%8E%E5%85%B6%E4%BB%96%E6%89%80%E6%9C%89git%E4%BB%93%E5%BA%93%E7%9A%84%E5%8F%8C%E5%90%91%E5%90%8C%E6%AD%A5.html","excerpt":"前言写这篇文章的初衷是昨天晚上记录一下我从gitee迁移到codeup的一系列过程，其中最后一步涉及到了github与codeup代码的双向同步，所以记录趁热记录一下我的github action如何使用。\nMore Hub Mirror Action我给这个github action起名叫做More Hub Mirror Action,代表它能在多个hub托管平台之上相互同步代码，主要用来做代码备份以及开源镜像同步。\n我的介绍大概是这样写的：\n一个用于在hub间（例如Github，Gitee、Coding，不局限，可以是所有）账户代码仓库同步的action，这个项目脱胎于Yikun&#x2F;hub-mirror-action@master。\n\n由于我是想要一个纯粹的不同的hub之间 同步的脚本，所以将该脚本进行了删减，不是作者做的不好，只是我仅仅需要简单的功能罢了\n\n目前只支持，也只会支持两个仓库必须在两个hub之间存在的情况，不再创建新的仓库（由于创建仓库需要api支持，但是为了更通用，所以决定不支持对应的功能）\n\n根据能量守恒定律，失去些什么，必然能得到些什么，这样就可以在不同的hub之间同步数据，不管是 从 github-&gt;gitee 还是 gitee-github 都可以支持到\n\nsrc、dst 都需要写全路径了，例如：github.com&#x2F;kunpengcompute\n\nstatic_list 是必传参数，因为不会再动态获取对应的repos了\n\ndst_key 也是必传参数，因为为了安全考虑，我决定全部使用ssh的方式进行同步，如果后期有需要，可以兼容https\n\n\n","text":"前言写这篇文章的初衷是昨天晚上记录一下我从gitee迁移到codeup的一系列过程，其中最后一步涉及到了github与codeup代码的双向同步，所以记录趁热记录一下我的github action如何使用。 More Hub Mirror Action我给这个github action起名叫做More Hub Mirror Action,代表它能在多个hub托管平台之上相互同步代码，主要用来做代码备份以及开源镜像同步。 我的介绍大概是这样写的： 一个用于在hub间（例如Github，Gitee、Coding，不局限，可以是所有）账户代码仓库同步的action，这个项目脱胎于Yikun&#x2F;hub-mirror-action@master。 由于我是想要一个纯粹的不同的hub之间 同步的脚本，所以将该脚本进行了删减，不是作者做的不好，只是我仅仅需要简单的功能罢了 目前只支持，也只会支持两个仓库必须在两个hub之间存在的情况，不再创建新的仓库（由于创建仓库需要api支持，但是为了更通用，所以决定不支持对应的功能） 根据能量守恒定律，失去些什么，必然能得到些什么，这样就可以在不同的hub之间同步数据，不管是 从 github-&gt;gitee 还是 gitee-github 都可以支持到 src、dst 都需要写全路径了，例如：github.com&#x2F;kunpengcompute static_list 是必传参数，因为不会再动态获取对应的repos了 dst_key 也是必传参数，因为为了安全考虑，我决定全部使用ssh的方式进行同步，如果后期有需要，可以兼容https 怎么用同步过程主要分为两步： 使用定时任务同步或者使用github的webhook触发同步 配置好对应的项目，然后让github action跑起来即可。 创建一个单独仓库，专门用来跑github action创建好对应的github action，有两个，可以使用同一个action进行操作，我创建的仓库名是：github-sync,下面我都以该仓库名作为github action的webhook进行请求。 先要做几个准备： 创建一个ssh密钥，在github和你创建的仓库都进行配置，不会创建ssh密钥的话参考文档即可。 创建一个github的token它的作用主要是给你的webhook做安全验证的，点击创建token。 该仓库下的github action配置如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344# This is a basic workflow to help you get started with Actionsname: signle_repo_codeup2github# Controls when the workflow will runon: #定时任务自动触发（最好和webhook的拆分为两个） #schedule: # - cron: 0 */12 * * * #使用github的webhook触发 repository_dispatch: types: - codeup_push #手动触发 workflow_dispatch:# A workflow run is made up of one or more jobs that can run sequentially or in paralleljobs: repo-sync: env: dst_key: $&#123;&#123; secrets.GIT_PRIVATE_KEY &#125;&#125; runs-on: ubuntu-latest steps: - uses: actions/checkout@v2 with: persist-credentials: false - name: sync codeup repo to github repo uses: dislazy/hub-mirror-action@v2.0.0 if: env.dst_key with: # 必选，需要同步的 git 用户（源） src: &#x27;codeup.aliyun.com/dislazy&#x27; # 必选，需要同步到的 git 用户（目的） dst: &#x27;github.com/dislazy&#x27; # 必选，公钥对应的私钥，https://gitee.com/profile/sshkeys dst_key: $&#123;&#123; secrets.GIT_PRIVATE_KEY &#125;&#125; #必选，同步的仓库列表，多个用,分开即可 static_list: $&#123;&#123; github.event.client_payload.repo &#125;&#125; #启用git push -f强制同步，注意：开启后，会强制覆盖目的端仓库。 force_update: true #配置cache cache_path: /codeup/workspace 简单说明： codeup_push，这个是webhook和github约定好的event，填已有的即可 secrets.GIT_PRIVATE_KEY 这个是上面提到的ssh密钥，及时放在github的secrets中 src、dst使用除了https之外的个人路径全路径，src和dst可以随便填你想要同步的两个hub，甚至可以不是github(身在曹营心在汉的即视感) github.event.client_payload.repo 这个是你在webhook中提到的你要同步的仓库 在任意处创建对应的webhook请求github api同步仓库1curl -X POST -H &#x27;Accept: application/vnd.github.v3+json&#x27; -H &#x27;Authorization: token $&#123;github-token&#125;&#x27; https://api.github.com/repos/dislazy/github-sync/dispatches -d &#x27;&#123;&quot;event_type&quot;:&quot;codeup_push&quot;,&quot;client_payload&quot;:&#123;&quot;repo&quot;:&quot;$&#123;repos_name&#125;&quot;,&quot;message&quot;:&quot;github action sync&quot;&#125;&#125;&#x27; 简单说明： github-token 替换为你准备工作中创建的github token repos_name 你需要同步的仓库列表，多个用,分隔开即可 event_type 就是上面约定的event密钥，保持一致即可 总结我目前使用以上的脚本基本上分为两个大块： 使用定时任务执行github api，用来同步一些固定需要同步的仓库，如果仓库新增了直接改webhook的请求参数即可 当codeup提交代码的时候使用对应的flow工作流触发github api请求，异步完成github 同步请求 开源的工具有很多，大多数都是为不同的需求不同的人群定制的，如果找不到合适的，如果有能力改一改也是极好的。","raw":null,"content":null,"categories":[{"name":"git","slug":"git","permalink":"https://blog.bosong.online/categories/git/"}],"tags":[{"name":"github","slug":"github","permalink":"https://blog.bosong.online/tags/github/"},{"name":"github action","slug":"github-action","permalink":"https://blog.bosong.online/tags/github-action/"}]},{"title":"从gitee到codeup,我经历了什么？","slug":"从gitee到codeup-我经历了什么？","date":"2022-05-19T16:16:56.000Z","updated":"2022-06-02T01:05:59.616Z","comments":true,"path":"从gitee到codeup-我经历了什么？.html","link":"","permalink":"https://blog.bosong.online/%E4%BB%8Egitee%E5%88%B0codeup-%E6%88%91%E7%BB%8F%E5%8E%86%E4%BA%86%E4%BB%80%E4%B9%88%EF%BC%9F.html","excerpt":"前言gitee是目前国内做的比较好的公共git托管仓库和开源交流平台，codeup是阿里云的企业git托管，包括一整套devops的解决方案。\n这篇文章主要分享一下我最近将代码从gitee迁移到codeup并且将几乎所有的devops都迁移到flow的过程。\n为什么？主要还是想要一个简洁的git仓库管理平台和完善的devops生态系统，codeup早期时候使用过，但是没有这次的感觉这么惊艳，当一个产品让你产生了惊艳的感觉的时候，你可能已经想迫不及待的尝试它了，我也是这样，codeup恰好就是我想要的样子。\n","text":"前言gitee是目前国内做的比较好的公共git托管仓库和开源交流平台，codeup是阿里云的企业git托管，包括一整套devops的解决方案。 这篇文章主要分享一下我最近将代码从gitee迁移到codeup并且将几乎所有的devops都迁移到flow的过程。 为什么？主要还是想要一个简洁的git仓库管理平台和完善的devops生态系统，codeup早期时候使用过，但是没有这次的感觉这么惊艳，当一个产品让你产生了惊艳的感觉的时候，你可能已经想迫不及待的尝试它了，我也是这样，codeup恰好就是我想要的样子。 迁移过程迁移过程总的来说分为三大步； 同步所有的gitee仓库到codeup 所有的自动部署、自动打包等的流水线迁移 适配和github的sync Step1：同步现在所有的git仓库幸运的是，codeup支持一键同步很多平台的仓库，gitee恰好就被快速而便捷的同步到了codeup中，唯一出现的波澜就是：codeup是默认以代码组来创建仓库的，有点类似gitlab中project的概念，然而作为一个个人开发者,我不需要组别进行管理，这个时候在同步仓库的时候就把仓库的地址修改为不分组就可以了。 同步的过程很顺利，改好组别，一键全选，然后等待同步完成就可以。 Step2：流水线迁移到flowflow是阿里云云效的一个组成部分，主要就是负责干devops这件事的。如果你不想迁移仓库，只是想单独使用flow作为你的devops工具也是完全可以的，它最多每个月送你5400分钟的构建打包时间，节点还可以使用国内和香港的节点，再也不用为node项目的编译而改一堆的仓库地址还没啥用而发愁了。 flow的配置过程也是相当简单，主要是阿里云提供了一大堆齐全的模板供你使用和查找，原生的文档也还是写的不错，说实话我在用xxx go的时候配置一步一个坑，构建速度还慢的感人。 拿一个最简单的docker镜像来说，我的打包到部署过程就只分为两个步骤：打包，部署。刚好我使用的也是阿里云的镜像仓库，然后直接选择个人仓库，填写一下你dockerfile的位置，其他的flow都给你搞定了，不需要你再写任何代码，效率之高谁用谁知道。 部署就更简单了,flow有全局的环境变量（真正的全局，配置好了，在对应的流水线引用一下，就so easy，在github等都是付费功能）,在服务器安装agent,然后直接cd /aaa/ &amp;&amp; docker-compose up -d 就部署完成了。不需要去配置服务器的密码什么的，地址都不需要填。 我有98个git仓库，21个流水线任务（多数是一样的，换个参数即可），在不到4小时的时间里，完全迁移完成，主要我的流水线都足够简单，打包，部署仅此而已。 再简单说一下，一个简单的node项目，原来在xxx go打包需要18+分钟，迁移完成后打包+部署耗时2分钟20s,主要是它的免费时长是5400分钟，效率可见一斑。 Step3：codeup 与github 代码双向同步说双向同步其实有点牵强，真实情况是：大部分仓库从codeup同步到github（主要是私人项目），小部分仓库从github同步到github（主要是开源项目）。 这个过程还是稍微有点坎坷，但是没有让人失望，我之前就用过Yikun&#x2F;hub-mirror-action来同步我的镜像仓库，但是看完源码发现，它好像不支持我从codeup同步到github，然后我就自己动手丰衣足食，根据他的源码修改了一个适合我自己使用场景的项目dislazy&#x2F;hub-mirror-action，在此也非常感谢原作者，开源的力量很强大，值得我们有能力的人都尽一下自己的力量，我的action非常简单，可以以ssh的方式同步任何你想互相同步的代码，你可以从github同步到codeup，也可以从codeup同步到github。 我的同步action都放在github的同一个仓库中，新建了几个action，分别是：将github的全量仓库每天定时备份到gitee，同步codeup的单个仓库到github（近实时，通过api触发），同步github的单个仓库到codeup（近实时，通过api触发）。 说到同步，其实更多的是为了备份，发现codeup有一个很人性化的功能，能帮你备份你所有的仓库到阿里云的oss中，存储费用低廉（5年40G才45块钱，还是比较良心的），这样备份就有很多份，能防止任何一个仓库突然出现问题。 总结从决定迁移，到迁移完成，改一大堆东西，4个小时完成这个项目，有一方面是自己的能力问题，另外一方面我觉得和工具的易用性脱不开关系，就例如我配置xxx go的打包部署一样，一个项目我花了1小时配置，相当痛苦。 写这篇文章的目的纯粹是觉得工具好用，而我刚好用到，能节省我的时间和精力，所以想记录一下其中的过程，这篇文章没有任何代码，原因是因为flow的代码不直接存在仓库中，它是独立的，只是你需要关联仓库而已，如此简单。 其他的就从文档中找把，用之前看一遍文档，比尝试很多次都有用。 其他想说的最近持续的居家办公生活，让我略感焦虑，说孤独也是很有感触，独立工作还是挺考验自己的自律性，以及工作和生活糅杂在一块的些许不便，然后该适应总是要适应，最近有很多的经历想变成文章记录下来，也因为情绪和工作的原因没有及时的记录下来，以后要多多记录，纯粹记录自己想记录的，给未来的自己看看。 加油吧，皮卡丘。","raw":null,"content":null,"categories":[{"name":"git","slug":"git","permalink":"https://blog.bosong.online/categories/git/"}],"tags":[{"name":"github","slug":"github","permalink":"https://blog.bosong.online/tags/github/"},{"name":"gitee","slug":"gitee","permalink":"https://blog.bosong.online/tags/gitee/"},{"name":"codeup","slug":"codeup","permalink":"https://blog.bosong.online/tags/codeup/"},{"name":"flow","slug":"flow","permalink":"https://blog.bosong.online/tags/flow/"},{"name":"devops","slug":"devops","permalink":"https://blog.bosong.online/tags/devops/"}]},{"title":"github自动同步到gitee最佳实践","slug":"github自动同步到gitee最佳实践","date":"2022-04-05T02:28:16.000Z","updated":"2022-06-02T01:05:59.615Z","comments":true,"path":"github自动同步到gitee最佳实践.html","link":"","permalink":"https://blog.bosong.online/github%E8%87%AA%E5%8A%A8%E5%90%8C%E6%AD%A5%E5%88%B0gitee%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5.html","excerpt":"\n前段时间对github同步到gitee并且实现自动化devops写了一篇简单版的文章，后期也遇到了很多问题，这篇文章主要解决遇到的痛点。\n\n痛点\n仓库数量多的情况下每个都需要配置，十分繁琐。\n如果统一配置在一个github action中时单个仓库提交无法被感知。\ngithub的私有仓库如果gitee没有则会被原来的github action创建为公有仓库，隐私信息容易被泄露。\n\n","text":"前段时间对github同步到gitee并且实现自动化devops写了一篇简单版的文章，后期也遇到了很多问题，这篇文章主要解决遇到的痛点。 痛点 仓库数量多的情况下每个都需要配置，十分繁琐。 如果统一配置在一个github action中时单个仓库提交无法被感知。 github的私有仓库如果gitee没有则会被原来的github action创建为公有仓库，隐私信息容易被泄露。 解决方案遇到问题是正常的，我们需要思考如何去解决问题，也需要针对具体的问题去解决问题，如果可以一劳永逸当然是最好的，然而大多数情况下不能，只能一步一步的探索。 Q3解决方案先从问题3开始解决，只需要去查看对应的api文档，看看有没有对应参数，查看了文档之后发现有，然后去分析对应的github action的代码然后fork到自己的账户下面，去改动对应的代码即可，我这边已经改动完了，提交到PR但是因为理念原因目前没有被merge，可以直接上github查看我的fix。 giteeApi文档 githubApi文档 自行修改的创建私有仓库的pr Q1和Q2解决方案多个仓库配置和单个仓库配置其实是冲突但是又不冲突的，可以分开来实现，创建一个新的github仓库，然后专门来做这件事，这样就不用一个一个去进行繁琐的配置了。 针对多个仓库的同步，这种同步实际上不需要实时，定时同步即可，这样可以用一个github action task去实现即可，以下是对应的解决方案代码 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869# 定时同步多个仓库name: github2gitee# Controls when the workflow will runon: # Triggers the workflow on push or pull request events but only for the main branch push: # branches: [ main ] 注释代表全部分支、 schedule: - cron: 0 */12 * * * # Allows you to run this workflow manually from the Actions tab workflow_dispatch:# A workflow run is made up of one or more jobs that can run sequentially or in paralleljobs: repo-sync: env: dst_key: $&#123;&#123; secrets.GITEE_PRIVATE_KEY &#125;&#125; dst_token: $&#123;&#123; secrets.GITEE_TOKEN &#125;&#125; gitee_user: $&#123;&#123; secrets.GITEE_USER &#125;&#125; runs-on: ubuntu-latest steps: - uses: actions/checkout@v2 with: persist-credentials: false - name: Get Time id: get-time run: | echo &quot;::set-output name=date::$(/bin/date -u &quot;+%Y%m%d%H%M%S&quot;)&quot; shell: bash - name: Cache src repos uses: actions/cache@v1 id: cache with: path: $&#123;&#123; github.workspace &#125;&#125;/github-cache key: $&#123;&#123; runner.os &#125;&#125;-hub-repos-cache-$&#123;&#123; steps.get-time.outputs.date &#125;&#125; restore-keys: $&#123;&#123; runner.os &#125;&#125;-hub-repos-cache - name: sync github -&gt; gitee uses: dislazy/hub-mirror-action@master if: env.dst_key &amp;&amp; env.dst_token &amp;&amp; env.gitee_user with: # 必选，需要同步的 Github 用户（源） src: &#x27;github/$&#123;&#123; github.repository_owner &#125;&#125;&#x27; # 必选，需要同步到的 Gitee 用户（目的） dst: &#x27;gitee/$&#123;&#123; secrets.GITEE_USER &#125;&#125;&#x27; # 必选，Gitee公钥对应的私钥，https://gitee.com/profile/sshkeys dst_key: $&#123;&#123; secrets.GITEE_PRIVATE_KEY &#125;&#125; # 必选，Gitee对应的用于创建仓库的token，https://gitee.com/profile/personal_access_tokens dst_token: $&#123;&#123; secrets.GITEE_TOKEN &#125;&#125; # 如果是组织，指定组织即可，默认为用户 user account_type: user # 需要同步的仓库列表 static_list: &quot;repo-a,repo-b,repo-c&quot; #启用git push -f强制同步，注意：开启后，会强制覆盖目的端仓库。 clone_style: ssh #默认为https，可以设置为ssh或者https。当设置为ssh时，你需要将dst_key所对应的公钥同时配置到源端和目的端 force_update: true #配置cache cache_path: $&#123;&#123; github.workspace &#125;&#125;/github-cache #默认创建仓库为私有仓库 dst_private: true - name: Print cache path run: | ls -la $&#123;&#123; github.workspace &#125;&#125;/github-cache 针对单个仓库，因为需要进行及时进行后续的devops流程，所以针对它需要在push完之后进行同步。 我们去调研一下github的github action文档之后发现可以直接进行webhook触发，这个就可以直接帮助我们实现对应的实时同步过程。 可以先行查看对应的 文档。 此时分为两步走，在此之前先创建一个github的token,点击 申请一个 token，配置repos的所有权限即可，后面会用到。 在上面的仓库里再创建一个单仓库的action，只不过这个触发方式是webhook事件(github_push这个自定义事件)触发此时同步的是github.event.client_payload.repo 这个参数的对应的仓库，它由wenhook传递过来，见代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748# This is a basic workflow to help you get started with Actionsname: signle_repo_github2gitee# Controls when the workflow will runon: repository_dispatch: types: - github_push # Allows you to run this workflow manually from the Actions tab workflow_dispatch:# A workflow run is made up of one or more jobs that can run sequentially or in paralleljobs: repo-sync: env: dst_key: $&#123;&#123; secrets.GITEE_PRIVATE_KEY &#125;&#125; dst_token: $&#123;&#123; secrets.GITEE_TOKEN &#125;&#125; gitee_user: $&#123;&#123; secrets.GITEE_USER &#125;&#125; runs-on: ubuntu-latest steps: - uses: actions/checkout@v2 with: persist-credentials: false - name: sync github -&gt; gitee uses: Yikun/hub-mirror-action@master if: env.dst_key &amp;&amp; env.dst_token &amp;&amp; env.gitee_user with: # 必选，需要同步的 Github 用户（源） src: &#x27;github/$&#123;&#123; github.repository_owner &#125;&#125;&#x27; # 必选，需要同步到的 Gitee 用户（目的） dst: &#x27;gitee/$&#123;&#123; secrets.GITEE_USER &#125;&#125;&#x27; # 必选，Gitee公钥对应的私钥，https://gitee.com/profile/sshkeys dst_key: $&#123;&#123; secrets.GITEE_PRIVATE_KEY &#125;&#125; # 必选，Gitee对应的用于创建仓库的token，https://gitee.com/profile/personal_access_tokens dst_token: $&#123;&#123; secrets.GITEE_TOKEN &#125;&#125; # 如果是组织，指定组织即可，默认为用户 user account_type: user # 直接取当前项目的仓库名 static_list: $&#123;&#123; github.event.client_payload.repo &#125;&#125; #启用git push -f强制同步，注意：开启后，会强制覆盖目的端仓库。 clone_style: ssh #默认为https，可以设置为ssh或者https。当设置为ssh时，你需要将dst_key所对应的公钥同时配置到源端和目的端 force_update: true #配置cache cache_path: /github/workspace/$&#123;&#123; github.event.client_payload.repo &#125;&#125; 在你需要同步的仓库内创建一个webhook对应的action，如下： 1234567891011121314151617181920212223242526272829# This is a basic workflow to help you get started with Actionsname: webhook# Controls when the workflow will runon: # 注释代表所有分支 push:# branches: [ main ] # Allows you to run this workflow manually from the Actions tab workflow_dispatch: jobs: build: runs-on: ubuntu-latest steps: - uses: actions/checkout@v3 # Runs a set of commands using the runners shell - name: Run a multi-line script run: | curl \\ -X POST \\ -H &quot;Accept: application/vnd.github.v3+json&quot; \\ -H &quot;Authorization: token &#123;&#123;githubToken&#125;&#125;&quot; \\ https://api.github.com/repos/:owner/:repo/dispatches \\ -d &#x27;&#123;&quot;event_type&quot;:&quot;github_push&quot;,&quot;client_payload&quot;:&#123;&quot;repo&quot;:&quot;$&#123;&#123; github.event.repository.name &#125;&#125;&quot;,&quot;message&quot;:&quot;github action sync&quot;&#125;&#125;&#x27; echo &#x27;success&#x27; 其中，owner 是你的用户名，替换即可，repo 是你上面创建仓库的仓库名， githubToken 是上面申请的 Token 凭证，前面的token单词要保留githubToken存到仓库的secrets中，然后将，event_type 是自定义的事件名字，client_payload是一个对象，它可以传递你需要传递的参数，我上面就传递了repo这个参数。 然后提交代码到对应仓库，查看webhook是否发送成功，再校验webhook触发的task是否执行成功即可。 结果通过以上方案解决了多个仓库配置不便和单个仓库繁琐配置的问题，还有隐私安全的问题，大大节省了配置的时间和你花费的精力，如果针对上面的方案有疑问，欢迎与我多多交流。","raw":null,"content":null,"categories":[{"name":"Github","slug":"Github","permalink":"https://blog.bosong.online/categories/Github/"}],"tags":[{"name":"git","slug":"git","permalink":"https://blog.bosong.online/tags/git/"}]},{"title":"从github迁移到gitee和以coding为基础的的全链路devops","slug":"从github迁移到gitee和以coding为基础的的全链路devops","date":"2022-03-13T05:39:19.000Z","updated":"2022-06-02T01:05:59.616Z","comments":true,"path":"从github迁移到gitee和以coding为基础的的全链路devops.html","link":"","permalink":"https://blog.bosong.online/%E4%BB%8Egithub%E8%BF%81%E7%A7%BB%E5%88%B0gitee%E5%92%8C%E4%BB%A5coding%E4%B8%BA%E5%9F%BA%E7%A1%80%E7%9A%84%E7%9A%84%E5%85%A8%E9%93%BE%E8%B7%AFdevops.html","excerpt":"前言文章的标题起的比较长，实际上这篇文章将以我的hugo-blog项目为例，讲述一下我将代码提交到github，然后自动同步到gitee，再根据gitee的webhook通过coding的持续集成部署的整个过程。\n感谢github、gitee的给我们个人开发者提供足够的资源来完成这一系列的数据存储过程，也感谢coding提供的在我认为目前足够使用的持续集成功能，关键是这整个过程都是不需要付费的，需要的是灵快的小脑筋以及网上前人的经验罢了（文章中会用一些英文单词，避免敏感词汇，敬请原谅）。\n为什么迁移事情的起因由俄乌战争引起，我认为没有战争是正义或者邪恶的，因为史诗是由胜利者书写的。\n一直以来秉承一个原则：技术是自由的，它不能也不应该掺和到politics中去。\n然而真实的情况是：技术必须与politics共存，它是在保证politics下才有的产物。\n从这次俄乌战争中就可以看出来，以USA为首的西方国家彻底粉碎了技术是自由的谎言，甚至开源也不是自由的，由人主导的所谓的开源并非自由，从React到Github等一系列国外的开源软件的官网就能看出来很多现实：当我们的国家发生战争时，甚至是收复TW时，我们将受到从金融、政治、外交、贸易、技术等一系列的和不能预知的威胁。\n由此，为保障个人的权益，我决定将自己的代码库逐渐迁移到gitee中来，以预防未来可能发生的某些事情。\n","text":"前言文章的标题起的比较长，实际上这篇文章将以我的hugo-blog项目为例，讲述一下我将代码提交到github，然后自动同步到gitee，再根据gitee的webhook通过coding的持续集成部署的整个过程。 感谢github、gitee的给我们个人开发者提供足够的资源来完成这一系列的数据存储过程，也感谢coding提供的在我认为目前足够使用的持续集成功能，关键是这整个过程都是不需要付费的，需要的是灵快的小脑筋以及网上前人的经验罢了（文章中会用一些英文单词，避免敏感词汇，敬请原谅）。 为什么迁移事情的起因由俄乌战争引起，我认为没有战争是正义或者邪恶的，因为史诗是由胜利者书写的。 一直以来秉承一个原则：技术是自由的，它不能也不应该掺和到politics中去。 然而真实的情况是：技术必须与politics共存，它是在保证politics下才有的产物。 从这次俄乌战争中就可以看出来，以USA为首的西方国家彻底粉碎了技术是自由的谎言，甚至开源也不是自由的，由人主导的所谓的开源并非自由，从React到Github等一系列国外的开源软件的官网就能看出来很多现实：当我们的国家发生战争时，甚至是收复TW时，我们将受到从金融、政治、外交、贸易、技术等一系列的和不能预知的威胁。 由此，为保障个人的权益，我决定将自己的代码库逐渐迁移到gitee中来，以预防未来可能发生的某些事情。 迁移的步骤得益于github和gitee的用户群体都同样的大，绝大部分的坑都已经被前人趟过，我们只要稍加整理就好了。 从github迁移到gitee主要分为两步走： 将github的所有个人仓库全量迁移到gitee 将github的相关代码提交使用自动化的方式提交到gitee，保持仓库同步 以上的方案是不是很熟悉：完全就是数据库的数据热迁移步骤。下面我将详细说明以上两个步骤的具体情况： 数据仓库的全量迁移感谢gitee提供的数据全量迁移功能，让我如此没有障碍的快速进行数据迁移，不得不说软件国产化做的越来越好，越来越贴近中国人的使用习惯。 先登录到gitee进入主页，点击+号，然后可以看到从 GitHub &#x2F; GitLab 导入仓库 按钮，如果没有授权及时授权,如图: 进入菜单以后，可以看到你的github仓库列表（及时授权），然后选择你要导入的仓库导入就可以了，这样就完成了数据的全量迁移过程，非常简单。如图： 数据仓库的增量同步全量迁移进行的非常顺利，接下来是对你需要经常写入的仓库进行数据的增量同步了，可以慢慢来，先将关键步骤记录下来，然后逐步逐个迁移，这样能将大量的工作分散开来。 迁移的技术方案：使用github的actions将当前仓库的提交记录同步到gitee中，个人免费版每个月有2000分钟的actions使用时间，相对来说还是比较富余的，大概1-2分钟可以同步一次commit，能同步一千来个commit，基本上够用。 迁移的步骤： 准备github和gitee需要的秘钥，例如github和gitee对应的专用ssh秘钥、gitee的个人token、gitee的用户名 编写github action的action.yml文件，按照实际情况进行跳转，我使用的是: Yikun&#x2F;hub-mirror-action，一点开进去就是对应的说明介绍，我就不作多说 提交commit 查看对应的gitee仓库是否更新到了最新的commit 需要注意的点： 我在action中拉取代码和提交代码都使用的是ssh方式，所以需要自己创建一对ssh秘钥，可以点击此处查看教程，此时github、gitee都需要配置这个ssh公钥。 在此过程中，如果是新创建的仓库需要同步，可以不在gitee那创建对应的仓库，action会自动创建，此时需要gitee的token，可以点击此处生成token（实测发现gitee的企业版有坑，注意）。 注意源仓库（github）对应的用户属性，设置src_account_type为user or org ，目标仓库（gitee）的参数是dst_account_type ，设置也同样如此。 将GITEE_PRIVATE_KEY、GITEE_TOKEN 、GITEE_USER 都配置到github的Actions secrets中去,然后再编写如下所示的action。 配置Actions secrets 创建github action 入口 对应的yml文件： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152# This is a basic workflow to help you get started with Actionsname: CI# Controls when the workflow will runon: # Triggers the workflow on push or pull request events but only for the main branch push: branches: [ main ] # Allows you to run this workflow manually from the Actions tab workflow_dispatch:# A workflow run is made up of one or more jobs that can run sequentially or in paralleljobs: repo-sync: env: dst_key: $&#123;&#123; secrets.GITEE_PRIVATE_KEY &#125;&#125; dst_token: $&#123;&#123; secrets.GITEE_TOKEN &#125;&#125; gitee_user: $&#123;&#123; secrets.GITEE_USER &#125;&#125; runs-on: ubuntu-latest steps: - uses: actions/checkout@v2 with: persist-credentials: false - name: sync github 2 gitee uses: Yikun/hub-mirror-action@master if: env.dst_key &amp;&amp; env.dst_token &amp;&amp; env.gitee_user with: # 必选，需要同步的 Github 用户（源） src: &#x27;github/$&#123;&#123; github.repository_owner &#125;&#125;&#x27; # 必选，需要同步到的 Gitee 用户（目的） dst: &#x27;gitee/$&#123;&#123; secrets.GITEE_USER &#125;&#125;&#x27; # 必选，Gitee公钥对应的私钥，https://gitee.com/profile/sshkeys dst_key: $&#123;&#123; secrets.GITEE_PRIVATE_KEY &#125;&#125; # 必选，Gitee对应的用于创建仓库的token，https://gitee.com/profile/personal_access_tokens dst_token: $&#123;&#123; secrets.GITEE_TOKEN &#125;&#125; # 如果是组织，指定组织即可，默认为用户 user # account_type: org # 直接取当前项目的仓库名 static_list: $&#123;&#123; github.event.repository.name &#125;&#125; #启用git push -f强制同步，注意：开启后，会强制覆盖目的端仓库。 clone_style: ssh #默认为https，可以设置为ssh或者https。当设置为ssh时，你需要将dst_key所对应的公钥同时配置到源端和目的端 force_update: true #配置cache cache_path: /github/workspace/hub-mirror-cache #源账户的类型：user or org src_account_type: user #目标账户的类型：user or org dst_account_type: org 直接按照以上配置进行修改即可，开箱即用，配置好了之后，可以提交一条commit 试试效果，job执行结果如下： 查看源仓库和目标仓库的记录是否对应检查一下源仓库（github）和目标仓库（gitee）对应的提交记录是否对应，如果对应上了就没啥问题，不然就再看看actions的执行情况。 到这就完成了从github到gitee的迁移过程了，标准的数据库数据迁移做法：全量迁移+增量同步，如果有啥情况，随时可以无损迁移到gitee。 codng的devops其实从github迁移到gitee不仅仅是代码数据库的迁移，还有后面的一系列的devops对应的地址改变，我这边主要就是在coding的持续集成,由于我的Jenkinsfile全部都是写在代码仓库里的，这时候切换就非常方便了，直接将对应的代码源从github切换成gitee的同名仓库即可，基本没有代价。 可能会有人问gitee也有对应的持续集成 gitee go 为啥不直接在gitee中生态圈使用，主要还是因为不能和coding一样我直接在自己的主机上执行任务，这样就不计算它的免费时间了，而且coding每个月会给1000分钟的免费时间，基本上也是用不完的。（主要是省钱和合理资源利用）。 直接将github的源代码仓库修改为gitee： 如果有自有云主机，可以配置在coding的资源池中使用，这样还不占用coding的免费时间，达到资源合理利用的目的 其实从github迁移到gitee 还有一层大的好处：不需要考虑你的国内云服务器拉不下来github代码的问题了，我的云主机十次有九次拉不下来github的代码，所以我一直使用coding自带的资源池。 另外一部分还有就是如何使用coding的持续集成功能部署hugo 项目，我会出一篇文章详细说明。 结果和想法有些事想想觉得还挺费劲，但是一旦深入了解后做起来，发现还是挺简单，有时候就需要突破思维定势，你理解的难是建立在你固有的思维体系中的，如果要说难，先详细的去了解过整个过程后再去说难。 迁移和部署都出乎我想象的顺利，整个过程几个小时就完成了，支持重要的软件国产化，自有化，这样才能不被卡脖子。只要你足够强大，那么别人的制裁就只是个笑话了。","raw":null,"content":null,"categories":[{"name":"技术手册","slug":"技术手册","permalink":"https://blog.bosong.online/categories/%E6%8A%80%E6%9C%AF%E6%89%8B%E5%86%8C/"}],"tags":[{"name":"github","slug":"github","permalink":"https://blog.bosong.online/tags/github/"},{"name":"gitee","slug":"gitee","permalink":"https://blog.bosong.online/tags/gitee/"},{"name":"devops","slug":"devops","permalink":"https://blog.bosong.online/tags/devops/"},{"name":"coding","slug":"coding","permalink":"https://blog.bosong.online/tags/coding/"}]},{"title":"CentOS7升级Git版本","slug":"CentOS7升级Git版本","date":"2022-03-13T03:11:34.000Z","updated":"2022-06-02T01:05:59.611Z","comments":true,"path":"CentOS7升级Git版本.html","link":"","permalink":"https://blog.bosong.online/CentOS7%E5%8D%87%E7%BA%A7Git%E7%89%88%E6%9C%AC.html","excerpt":"前言在将自有云服务器导入到coding中作为持续集成的云主机时，提示git版本太老，所以无法继续进行安装，所以参考一篇文章对Centos 7上的Git进行了重新安装升级。\n查看当前服务器的git版本\n12[root@ce-88 ~]# git --versiongit version 1.8.3.1\n查看当前的系统版本\n12[root@ce-88 ~]# cat /etc/redhat-releaseCentOS Linux release 7.9.2009 (Core)\n\n安装依赖本次我们安装git使用编译源代码的方式安装，此前需要安装一些必要的依赖\n12[root@ce-88 ~]# yum install curl-devel expat-devel gettext-devel openssl-devel zlib-devel asciidoc[root@ce-88 ~]# yum install  gcc perl-ExtUtils-MakeMaker\n\n","text":"前言在将自有云服务器导入到coding中作为持续集成的云主机时，提示git版本太老，所以无法继续进行安装，所以参考一篇文章对Centos 7上的Git进行了重新安装升级。 查看当前服务器的git版本 12[root@ce-88 ~]# git --versiongit version 1.8.3.1 查看当前的系统版本 12[root@ce-88 ~]# cat /etc/redhat-releaseCentOS Linux release 7.9.2009 (Core) 安装依赖本次我们安装git使用编译源代码的方式安装，此前需要安装一些必要的依赖 12[root@ce-88 ~]# yum install curl-devel expat-devel gettext-devel openssl-devel zlib-devel asciidoc[root@ce-88 ~]# yum install gcc perl-ExtUtils-MakeMaker 卸载旧版本直接使用yum将git的旧版本remove掉 1[root@ce-88 ~]# yum remove git 编译安装GitGit软件包可在此获取：https://mirrors.edge.kernel.org/pub/software/scm/git/。 我发现源代码不区分你的CPU架构，直接找最新的版的下载即可 1git-2.9.5.tar.gz 安装步骤12345678[root@ce-88 ~]# cd /usr/local/src/[root@ce-88 ~]# wget https://mirrors.edge.kernel.org/pub/software/scm/git/git-2.9.5.tar.gz --no-check-certificate[root@ce-88 ~]# tar -zxvf git-2.9.5.tar.gz[root@ce-88 ~]# cd git-2.9.5/[root@ce-88 ~]# make prefix=/usr/local/git all[root@ce-88 ~]# make prefix=/usr/local/git install[root@ce-88 ~]# echo &quot;export PATH=$PATH:/usr/local/git/bin&quot; &gt;&gt; /etc/profile[root@ce-88 ~]# source /etc/profile 验证版本12[root@227 ~]# git versiongit version 2.9.5 非root用户使用如果是非root用户使用git，则需要配置下该用户下的环境变量。 12$ echo &quot;export PATH=$PATH:/usr/local/git/bin&quot; &gt;&gt; ~/.bashrc$ source ~/.bashrc 参考 本文参考CentOS7升级Git版本","raw":null,"content":null,"categories":[{"name":"Linux","slug":"Linux","permalink":"https://blog.bosong.online/categories/Linux/"}],"tags":[{"name":"git","slug":"git","permalink":"https://blog.bosong.online/tags/git/"},{"name":"linux","slug":"linux","permalink":"https://blog.bosong.online/tags/linux/"}]},{"title":"Docker升级到最新版本","slug":"Docker升级到最新版本","date":"2022-03-11T09:31:03.000Z","updated":"2022-06-02T01:05:59.611Z","comments":true,"path":"Docker升级到最新版本.html","link":"","permalink":"https://blog.bosong.online/Docker%E5%8D%87%E7%BA%A7%E5%88%B0%E6%9C%80%E6%96%B0%E7%89%88%E6%9C%AC.html","excerpt":"1、查看系统要求\nDocker 要求 CentOS 系统的内核版本高于 3.10 ,查看CentOS的内核版本。","text":"1、查看系统要求 Docker 要求 CentOS 系统的内核版本高于 3.10 ,查看CentOS的内核版本。 1uname -a 2、删除旧版本 1yum remove docker docker-common docker-selinux docker-engine 3、安装需要的软件包 yum-util 提供yum-config-manager功能，另外两个是devicemapper驱动依赖的 1sudo yum install -y yum-utils device-mapper-persistent-data lvm2 4、设置Docker yum源 1sudo yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo 5、查看所有仓库中所有docker版本 可以查看所有仓库中所有docker版本,并选择特定的版本安装。 1yum list docker-ce --showduplicates | sort -r 6、安装docker 1sudo yum install docker-ce 由于repo中默认只开启stable仓库，故这里安装的是最新稳定版。 如果要安装特定版本： 1sudo yum install docker-ce-18.06.1.ce 7、启动 设置为开机启动 1systemctl enable docker 启动 1systemctl start docker 查看启动状态 1systemctl status docker 查看版本 1docker version ** 版权声明 ** 本文来源于：Docker升级到最新版本;","raw":null,"content":null,"categories":[{"name":"Linux","slug":"Linux","permalink":"https://blog.bosong.online/categories/Linux/"}],"tags":[{"name":"linux","slug":"linux","permalink":"https://blog.bosong.online/tags/linux/"}]},{"title":"vue项目实现CDN动静分离及自动化部署","slug":"vue项目实现CDN动静分离及自动化部署","date":"2022-03-02T09:32:33.000Z","updated":"2022-06-02T01:05:59.616Z","comments":true,"path":"vue项目实现CDN动静分离及自动化部署.html","link":"","permalink":"https://blog.bosong.online/vue%E9%A1%B9%E7%9B%AE%E5%AE%9E%E7%8E%B0CDN%E5%8A%A8%E9%9D%99%E5%88%86%E7%A6%BB%E5%8F%8A%E8%87%AA%E5%8A%A8%E5%8C%96%E9%83%A8%E7%BD%B2.html","excerpt":"前世今生1410是刚毕业那会做一个毕业照展示网站项目。\n早期使用的是Vue.js作为前端项目，Java作为后端项目。\n中间将Python写的服务端替换了Java后端。\n最后将Golang写的服务端替换了Python后端。\n近期又做了一些前端方面的改造：\n\n使用authelia作为Nginx层的SSO网关，设置为登录可访问（不能实现全站CDN的原因是需要NGINX层）\n照片使用腾讯云CDN访问，并且为加快访问速度还使用了腾讯云的万象图片处理\n抛弃后端接口，直接使用json存储照片列表\n实现前端项目动静分离，引入CDN加快访问速度\n使用coding的持续集成实现自动化部署\n\n以后再也不用操心改完代码还要做一堆的操作让代码上线了，网站访问速度和安全性都得到了提升。\n升级打怪过程这篇文章就主要介绍一下将vue项目build后实现动静分离和自动化部署过程，以及遇到的一些坑点。以下是1410前端项目的项目结构：\n1234567891011121314151617|-- public //存放不可变静态资源\t\t|-- index.html\t\t|-- favicon.ico\t\t|-- data.json|-- src\t\t|-- plugins  //存放要引入的插件例如iview\t\t|-- App.vue  //项目入口\t\t|-- main.js  //项目配置|-- config //存放打包成容器后的nginx的配置    |-- nginx.conf|-- .env.deploy 打包时指定的文件|-- index.js 上传打包后dist文件夹到COS|-- Dockerfile 打包成docker镜像的配置|-- Jenkinsfile 持续集成的配置文件|-- vue.config.js vue的配置文件|-- package.json //存放打包命令以及依赖...\n改造vue项目实现动静分离如我上述的结构，改造vue项目非常简单，主要分为三步：\n\n在根目录中创建.env.deploy文件，然后写入\n12NODE_ENV=productionDEPLOY=online\n\n修改vue.config.js，将一下内容写入：\n1234567891011// 根据自定义的变量来进行内容设置，将这块放在整个js文件的最上面即可let BASE_URL = &#x27;/&#x27;switch(process.env.DEPLOY) &#123;    case &#x27;online&#x27;:        BASE_URL = &#x27;https://cdn.songbo.fun/&#x27;        break    default:        BASE_URL = &#x27;/&#x27;&#125;然后在module.exports中增加一行，注意&#x27;,&#x27;publicPath: BASE_URL\n在package.json中的scripts增加一行&quot;deploy&quot;: &quot;vue-cli-service build --mode deploy&quot; 此处注意**,**\n\n\n完成已上三步后就改造完成了，如果需要打包正常的项目使用npm run build 如果需要动静分离，使用npm run deploy 即可。最终效果如下,在dist/index.html,对应的css地址就换成了如下的内容：\n1&lt;link href=http://cdn.songbo.fun/static/css/app.887c93b2.css rel=preload as=style&gt;\n\n** 注意 这一步也没有遇到什么坑点，很快就完成了项目的动静分离。\n实现自动化部署上一步已经实现了打包的过程，初步具备了前端站点动静分离的条件，最终生成的dist目录结构如下：\n12345|-- index.html   // 需要copy到docker镜像中|-- static // 整个文件夹都需要放到COS上去，使用CDN访问    |-- js    |-- img    |-- css\n\n自动化部署总体流程比较简单，分为如下几步：\n\n选择一个devops服务提供商，我目前主要用两个：coding的持续集成以及github的action，配置起来都比较简单。\n选定Docker镜像并且准备好对应的配置，我这里选用的是nginx的docker镜像，准备了config/nginx.conf文件和Dockerfile文件，对应的文件存放位置可以在上文中看到，文件具体内容如下：nginx.conf:123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778# nginx.confuser nginx;worker_processes 1;error_log /var/log/nginx/error.log warn;pid /var/run/nginx.pid;events &#123;  worker_connections 1024;&#125;http &#123;  map $http_x_forwarded_for  $clientRealIp &#123;      &quot;&quot;      $remote_addr;      ~^(?P&lt;firstAddr&gt;[0-9\\.]+),?.*$  $firstAddr;  &#125;  include /etc/nginx/mime.types;  default_type application/octet-stream;  log_format main &#x27;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &#x27;  &#x27;$status $body_bytes_sent &quot;$http_referer&quot; &#x27;  &#x27;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&#x27;;  access_log /var/log/nginx/access.log main;  sendfile on;  tcp_nopush on;  gzip on;  client_max_body_size 100m;  client_body_buffer_size 10m;  proxy_connect_timeout 600s;  proxy_send_timeout 600s;  proxy_read_timeout 600s;  send_timeout 600s;  proxy_request_buffering off;  proxy_buffering off;  server &#123;    listen 80;    server_name localhost;    charset utf-8;    root /usr/share/nginx/html;    location / &#123;      try_files $uri $uri/ /index.html;    &#125;    location ~* \\.(?:jpg|jpeg|gif|png|ico|cur|gz|svg|svgz|mp4|ogg|ogv|webm|htc)$ &#123;      expires 1y;      access_log off;      add_header Cache-Control &quot;public&quot;;    &#125;    location ~* \\.(?:css|js)$ &#123;      try_files $uri =404;      expires 1y;      access_log off;      add_header Cache-Control &quot;public&quot;;    &#125;    location ~ ^.+\\..+$ &#123;      try_files $uri =404;    &#125;    error_page 500 502 503 504 /50x.html;    location = /50x.html &#123;      root /usr/share/nginx/html;    &#125;  &#125;&#125;\nDockerfile:1234567891011FROM nginx:1.17.9-alpineENV TZ=Asia/ShanghaiWORKDIR /usr/share/nginx/htmlCOPY ./config/nginx.conf /etc/nginx/nginx.confCOPY ./dist /usr/share/nginx/htmlEXPOSE 80\n将对应的文件打包成镜像，然后部署到宿主机上，我使用的是coding的持续集成，对应的jenkinsfile如下：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990pipeline &#123;  agent any  stages &#123;    stage(&#x27;检出&#x27;) &#123;      steps &#123;        checkout([$class: &#x27;GitSCM&#x27;, branches: [[name: env.GIT_BUILD_REF]],        userRemoteConfigs: [[url: env.GIT_REPO_URL, credentialsId: env.CREDENTIALS_ID]]])      &#125;    &#125;    stage(&#x27;构建&#x27;) &#123;      steps &#123;        echo &#x27;构建中...&#x27;        sh &#x27;npm install&#x27;        sh &#x27;npm run deploy&#x27;        sh &#x27;docker build -t $&#123;registry&#125;/$&#123;projectName&#125;:$&#123;GIT_COMMIT&#125;  .&#x27;        sh &quot;docker login --username=&#x27;$&#123;username&#125;&#x27;  --password=&#x27;$&#123;password&#125;&#x27;  &#x27;$&#123;registry&#125;&#x27;&quot;        sh &#x27;docker push $&#123;registry&#125;/$&#123;projectName&#125;:$&#123;GIT_COMMIT&#125;&#x27;        echo &#x27;构建完成.&#x27;      &#125;    &#125;    stage(&quot;部署到远端服务&quot;) &#123;      steps &#123;        script &#123;          def remoteConfig = [:]          remoteConfig.name = &quot;my-remote-server&quot;          remoteConfig.host = &quot;10.0.0.1&quot;          remoteConfig.port = 22          remoteConfig.allowAnyHosts = true          withCredentials([            sshUserPrivateKey(              credentialsId: &quot;$&#123;remote_cred&#125;&quot;,              keyFileVariable: &#x27;id_rsa&#x27;            ),          ]) &#123;            // SSH 登陆用户名            remoteConfig.user = &quot;root&quot;            // SSH 私钥文件地址            remoteConfig.identityFile = id_rsa            // 请确保远端环境中有 Docker 环境            sshCommand(              remote: remoteConfig,              command: &quot;docker login -u $&#123;username&#125; -p $&#123;password&#125; $&#123;registry&#125;&quot;,              sudo: true,            )            sshCommand(              remote: remoteConfig,              command: &quot;docker rm -f  $&#123;containerName&#125; | true&quot;,              sudo: true,            )            // DOCKER_IMAGE_VERSION 中涉及到 GIT_LOCAL_BRANCH / GIT_TAG / GIT_COMMIT 的环境变量的使用            // 需要在本地完成拼接后，再传入到远端服务器中使用            DOCKER_IMAGE_URL = sh(              script: &quot;echo $&#123;registry&#125;/$&#123;projectName&#125;:$&#123;GIT_COMMIT&#125;&quot;,              returnStdout: true            )            sshCommand(              remote: remoteConfig,              command: &quot;docker run -d -p 2111:80 --name $&#123;containerName&#125; $&#123;DOCKER_IMAGE_URL&#125;&quot;,              sudo: true,            )            echo &quot;部署成功，请到 https://1410.xxxx.com 预览效果&quot;          &#125;        &#125;      &#125;    &#125;    stage(&#x27;上传CDN&#x27;) &#123;      steps &#123;        echo &#x27;构建中...&#x27;        sh &#x27;node index.js&#x27;        echo &#x27;上传完成&#x27;      &#125;    &#125;  &#125;  environment &#123;    registry = &#x27;&#x27;    username = &#x27;&#x27;    password = &#x27;&#x27;    projectName = &#x27;1410&#x27;    containerName = &#x27;1410&#x27;    remote_cred = &#x27;&#x27;  &#125;&#125;\n为防止docker镜像启动不成功，导致原有的网站不可访问，所以将对应的dist中的文件上传到CDN中作为最后一步，这样可以保证服务启动后，访问的是最新的站点，将dist文件上传到cos上我使用的是我前期写的一个开源项目alidaodao-cos-uploader,具体的步骤可以访问项目后进行配置。\n\n到此整个自动化部署的过程也结束了，可以看看对应的运行步骤截图：\n","text":"前世今生1410是刚毕业那会做一个毕业照展示网站项目。 早期使用的是Vue.js作为前端项目，Java作为后端项目。 中间将Python写的服务端替换了Java后端。 最后将Golang写的服务端替换了Python后端。 近期又做了一些前端方面的改造： 使用authelia作为Nginx层的SSO网关，设置为登录可访问（不能实现全站CDN的原因是需要NGINX层） 照片使用腾讯云CDN访问，并且为加快访问速度还使用了腾讯云的万象图片处理 抛弃后端接口，直接使用json存储照片列表 实现前端项目动静分离，引入CDN加快访问速度 使用coding的持续集成实现自动化部署 以后再也不用操心改完代码还要做一堆的操作让代码上线了，网站访问速度和安全性都得到了提升。 升级打怪过程这篇文章就主要介绍一下将vue项目build后实现动静分离和自动化部署过程，以及遇到的一些坑点。以下是1410前端项目的项目结构： 1234567891011121314151617|-- public //存放不可变静态资源 |-- index.html |-- favicon.ico |-- data.json|-- src |-- plugins //存放要引入的插件例如iview |-- App.vue //项目入口 |-- main.js //项目配置|-- config //存放打包成容器后的nginx的配置 |-- nginx.conf|-- .env.deploy 打包时指定的文件|-- index.js 上传打包后dist文件夹到COS|-- Dockerfile 打包成docker镜像的配置|-- Jenkinsfile 持续集成的配置文件|-- vue.config.js vue的配置文件|-- package.json //存放打包命令以及依赖... 改造vue项目实现动静分离如我上述的结构，改造vue项目非常简单，主要分为三步： 在根目录中创建.env.deploy文件，然后写入 12NODE_ENV=productionDEPLOY=online 修改vue.config.js，将一下内容写入： 1234567891011// 根据自定义的变量来进行内容设置，将这块放在整个js文件的最上面即可let BASE_URL = &#x27;/&#x27;switch(process.env.DEPLOY) &#123; case &#x27;online&#x27;: BASE_URL = &#x27;https://cdn.songbo.fun/&#x27; break default: BASE_URL = &#x27;/&#x27;&#125;然后在module.exports中增加一行，注意&#x27;,&#x27;publicPath: BASE_URL 在package.json中的scripts增加一行&quot;deploy&quot;: &quot;vue-cli-service build --mode deploy&quot; 此处注意**,** 完成已上三步后就改造完成了，如果需要打包正常的项目使用npm run build 如果需要动静分离，使用npm run deploy 即可。最终效果如下,在dist/index.html,对应的css地址就换成了如下的内容： 1&lt;link href=http://cdn.songbo.fun/static/css/app.887c93b2.css rel=preload as=style&gt; ** 注意 这一步也没有遇到什么坑点，很快就完成了项目的动静分离。 实现自动化部署上一步已经实现了打包的过程，初步具备了前端站点动静分离的条件，最终生成的dist目录结构如下： 12345|-- index.html // 需要copy到docker镜像中|-- static // 整个文件夹都需要放到COS上去，使用CDN访问 |-- js |-- img |-- css 自动化部署总体流程比较简单，分为如下几步： 选择一个devops服务提供商，我目前主要用两个：coding的持续集成以及github的action，配置起来都比较简单。 选定Docker镜像并且准备好对应的配置，我这里选用的是nginx的docker镜像，准备了config/nginx.conf文件和Dockerfile文件，对应的文件存放位置可以在上文中看到，文件具体内容如下：nginx.conf:123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778# nginx.confuser nginx;worker_processes 1;error_log /var/log/nginx/error.log warn;pid /var/run/nginx.pid;events &#123; worker_connections 1024;&#125;http &#123; map $http_x_forwarded_for $clientRealIp &#123; &quot;&quot; $remote_addr; ~^(?P&lt;firstAddr&gt;[0-9\\.]+),?.*$ $firstAddr; &#125; include /etc/nginx/mime.types; default_type application/octet-stream; log_format main &#x27;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &#x27; &#x27;$status $body_bytes_sent &quot;$http_referer&quot; &#x27; &#x27;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&#x27;; access_log /var/log/nginx/access.log main; sendfile on; tcp_nopush on; gzip on; client_max_body_size 100m; client_body_buffer_size 10m; proxy_connect_timeout 600s; proxy_send_timeout 600s; proxy_read_timeout 600s; send_timeout 600s; proxy_request_buffering off; proxy_buffering off; server &#123; listen 80; server_name localhost; charset utf-8; root /usr/share/nginx/html; location / &#123; try_files $uri $uri/ /index.html; &#125; location ~* \\.(?:jpg|jpeg|gif|png|ico|cur|gz|svg|svgz|mp4|ogg|ogv|webm|htc)$ &#123; expires 1y; access_log off; add_header Cache-Control &quot;public&quot;; &#125; location ~* \\.(?:css|js)$ &#123; try_files $uri =404; expires 1y; access_log off; add_header Cache-Control &quot;public&quot;; &#125; location ~ ^.+\\..+$ &#123; try_files $uri =404; &#125; error_page 500 502 503 504 /50x.html; location = /50x.html &#123; root /usr/share/nginx/html; &#125; &#125;&#125; Dockerfile:1234567891011FROM nginx:1.17.9-alpineENV TZ=Asia/ShanghaiWORKDIR /usr/share/nginx/htmlCOPY ./config/nginx.conf /etc/nginx/nginx.confCOPY ./dist /usr/share/nginx/htmlEXPOSE 80 将对应的文件打包成镜像，然后部署到宿主机上，我使用的是coding的持续集成，对应的jenkinsfile如下：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990pipeline &#123; agent any stages &#123; stage(&#x27;检出&#x27;) &#123; steps &#123; checkout([$class: &#x27;GitSCM&#x27;, branches: [[name: env.GIT_BUILD_REF]], userRemoteConfigs: [[url: env.GIT_REPO_URL, credentialsId: env.CREDENTIALS_ID]]]) &#125; &#125; stage(&#x27;构建&#x27;) &#123; steps &#123; echo &#x27;构建中...&#x27; sh &#x27;npm install&#x27; sh &#x27;npm run deploy&#x27; sh &#x27;docker build -t $&#123;registry&#125;/$&#123;projectName&#125;:$&#123;GIT_COMMIT&#125; .&#x27; sh &quot;docker login --username=&#x27;$&#123;username&#125;&#x27; --password=&#x27;$&#123;password&#125;&#x27; &#x27;$&#123;registry&#125;&#x27;&quot; sh &#x27;docker push $&#123;registry&#125;/$&#123;projectName&#125;:$&#123;GIT_COMMIT&#125;&#x27; echo &#x27;构建完成.&#x27; &#125; &#125; stage(&quot;部署到远端服务&quot;) &#123; steps &#123; script &#123; def remoteConfig = [:] remoteConfig.name = &quot;my-remote-server&quot; remoteConfig.host = &quot;10.0.0.1&quot; remoteConfig.port = 22 remoteConfig.allowAnyHosts = true withCredentials([ sshUserPrivateKey( credentialsId: &quot;$&#123;remote_cred&#125;&quot;, keyFileVariable: &#x27;id_rsa&#x27; ), ]) &#123; // SSH 登陆用户名 remoteConfig.user = &quot;root&quot; // SSH 私钥文件地址 remoteConfig.identityFile = id_rsa // 请确保远端环境中有 Docker 环境 sshCommand( remote: remoteConfig, command: &quot;docker login -u $&#123;username&#125; -p $&#123;password&#125; $&#123;registry&#125;&quot;, sudo: true, ) sshCommand( remote: remoteConfig, command: &quot;docker rm -f $&#123;containerName&#125; | true&quot;, sudo: true, ) // DOCKER_IMAGE_VERSION 中涉及到 GIT_LOCAL_BRANCH / GIT_TAG / GIT_COMMIT 的环境变量的使用 // 需要在本地完成拼接后，再传入到远端服务器中使用 DOCKER_IMAGE_URL = sh( script: &quot;echo $&#123;registry&#125;/$&#123;projectName&#125;:$&#123;GIT_COMMIT&#125;&quot;, returnStdout: true ) sshCommand( remote: remoteConfig, command: &quot;docker run -d -p 2111:80 --name $&#123;containerName&#125; $&#123;DOCKER_IMAGE_URL&#125;&quot;, sudo: true, ) echo &quot;部署成功，请到 https://1410.xxxx.com 预览效果&quot; &#125; &#125; &#125; &#125; stage(&#x27;上传CDN&#x27;) &#123; steps &#123; echo &#x27;构建中...&#x27; sh &#x27;node index.js&#x27; echo &#x27;上传完成&#x27; &#125; &#125; &#125; environment &#123; registry = &#x27;&#x27; username = &#x27;&#x27; password = &#x27;&#x27; projectName = &#x27;1410&#x27; containerName = &#x27;1410&#x27; remote_cred = &#x27;&#x27; &#125;&#125; 为防止docker镜像启动不成功，导致原有的网站不可访问，所以将对应的dist中的文件上传到CDN中作为最后一步，这样可以保证服务启动后，访问的是最新的站点，将dist文件上传到cos上我使用的是我前期写的一个开源项目alidaodao-cos-uploader,具体的步骤可以访问项目后进行配置。 到此整个自动化部署的过程也结束了，可以看看对应的运行步骤截图： 遇到的问题以及解决方案coding持续集成部署到宿主机时始终报错：invalid privatekey: [B@51d78dde最终查到该问题是由于我使用的连接到宿主机的SSH密钥的版本过新导致的，我使用的密钥如下： 123456-----BEGIN OPENSSH PRIVATE KEY-----PRIVATE KEY-----END OPENSSH PRIVATE KEY----- 但是coding使用的Jenkins只支持如下密钥： 123456-----BEGIN RSA PRIVATE KEY-----PRIVATE KEY-----END RSA PRIVATE KEY----- 问题找到，解决就简单了，将对应的OPENSSH的密钥改成RSA的密钥即可：ssh-keygen -p -m PEM -f 你的密钥地址,然后再转化的密钥存入对应凭据中就解决了。 总结对于服务端开发者，自动化早已深入人心，它能帮你节省大量的时间和精力，如何用好自动化技术也是我们的挑战,欢迎与我一起交流。 参考文献： 持续集成 &#x2F; 自动部署 &#x2F; Linux 服务器","raw":null,"content":null,"categories":[{"name":"技术手册","slug":"技术手册","permalink":"https://blog.bosong.online/categories/%E6%8A%80%E6%9C%AF%E6%89%8B%E5%86%8C/"}],"tags":[{"name":"nginx","slug":"nginx","permalink":"https://blog.bosong.online/tags/nginx/"},{"name":"docker","slug":"docker","permalink":"https://blog.bosong.online/tags/docker/"},{"name":"CDN","slug":"CDN","permalink":"https://blog.bosong.online/tags/CDN/"},{"name":"DEVOPS","slug":"DEVOPS","permalink":"https://blog.bosong.online/tags/DEVOPS/"}]},{"title":"minio改造支持tencent-cos","slug":"minio改造支持tencent-cos","date":"2022-01-28T02:55:50.000Z","updated":"2022-06-02T01:05:59.616Z","comments":true,"path":"minio改造支持tencent-cos.html","link":"","permalink":"https://blog.bosong.online/minio%E6%94%B9%E9%80%A0%E6%94%AF%E6%8C%81tencent-cos.html","excerpt":"背景最近在调研一款能管理我的tencent-cos的在线管理端软件，然后调研了很多软件，之前试用过nextcloud发现一般，然后看中了minio，看评测说性能比较好，并且支持S3协议。\n在实际使用过程中是使用的docker部署，具体命令如下,对应文档可以点击minio-gateway：\n1234docker run -p 9000:9000 --name minio-s3 \\ -e &quot;MINIO_ACCESS_KEY=access_key&quot; \\ -e &quot;MINIO_SECRET_KEY=secret_key&quot; \\ minio/minio gateway s3  https://cos.ap-beijing.myqcloud.com\n然而在我将信息填入以后，发现始终无法创建,提示：ERROR Unable to initialize gateway backend: Could not parse the specified URI.然而通过中心搜索并不能寻找到结果，然后使用全英文搜索就找到问题所在了，原因是：tencent-cos的bucket命名是以: bucket名+个人的账号数字为命名方式的，和minio的默认创建桶的方式不一样，所以始终提示该错误。\n改造过程既然问题已经找到，剩下的问题就解决问题了，解决问题一般有两种方案，一般是解决创造问题的人，一种是直接解决，然而通过腾讯云的工单并不能解决问题，直接说是第三方的原因导致的，无法进行修改。直接解决问题也很简单：\n\n先找到minio的github仓库，然后fork到自己的仓库中，\n按文件夹查找cmd-&gt;gateway-&gt;s3-&gt;gateway-s3.go文件\n然后找到randString这个方法\n修改最后的返回值为：return prefix + string(b[0:30-len(prefix)]) + &quot;-123&quot;。\n此时问题解决。\n\n","text":"背景最近在调研一款能管理我的tencent-cos的在线管理端软件，然后调研了很多软件，之前试用过nextcloud发现一般，然后看中了minio，看评测说性能比较好，并且支持S3协议。 在实际使用过程中是使用的docker部署，具体命令如下,对应文档可以点击minio-gateway： 1234docker run -p 9000:9000 --name minio-s3 \\ -e &quot;MINIO_ACCESS_KEY=access_key&quot; \\ -e &quot;MINIO_SECRET_KEY=secret_key&quot; \\ minio/minio gateway s3 https://cos.ap-beijing.myqcloud.com 然而在我将信息填入以后，发现始终无法创建,提示：ERROR Unable to initialize gateway backend: Could not parse the specified URI.然而通过中心搜索并不能寻找到结果，然后使用全英文搜索就找到问题所在了，原因是：tencent-cos的bucket命名是以: bucket名+个人的账号数字为命名方式的，和minio的默认创建桶的方式不一样，所以始终提示该错误。 改造过程既然问题已经找到，剩下的问题就解决问题了，解决问题一般有两种方案，一般是解决创造问题的人，一种是直接解决，然而通过腾讯云的工单并不能解决问题，直接说是第三方的原因导致的，无法进行修改。直接解决问题也很简单： 先找到minio的github仓库，然后fork到自己的仓库中， 按文件夹查找cmd-&gt;gateway-&gt;s3-&gt;gateway-s3.go文件 然后找到randString这个方法 修改最后的返回值为：return prefix + string(b[0:30-len(prefix)]) + &quot;-123&quot;。 此时问题解决。 修改完代码如何投入使用其实记录本篇文章的目的不仅仅是解决上面遇到的问题，更是记录一下实际在修改完代码后如何投入使用，最简单的方法有两种： 如果直接使用宿主机安装的，那么用带有go环境的电脑，直接进入仓库运行make 打包出可执行文件minio然后替换原来的直接执行 如果使用docker安装的稍微有些麻烦,但是原理是替换容器中的可执行文件，然后再次执行，下面详细讲解一下 docker容器修改启动minio 如果没有go环境先安装go环境，如果会github action的可以先用github action来进行打包和封装进镜像 然后运行make 运行完后会打包出一个minio的可执行文件 然后将官方镜像文件下载下来，先运行一下，再通过docker cp minio minio:/opt/bin/ 将minio 这个容器中的可执行文件直接替换成新的，如果你的容器名不叫这个，可以更换成自己的名字或者容器ID 不知道minio在容器中存放的位置，可以镜像仓库中的Dockerfile.release中找到，如：curl -s -q https://dl.min.io/server/minio/release/linux-$&#123;TARGETARCH&#125;/archive/minio.$&#123;RELEASE&#125; -o /opt/bin/minio 此时就找到了/opt/bin/minio的存放位置 改造结果注意：改造完成后，容器可以正常运行，此时可以将该容器打造成一个镜像，再上传到你的镜像仓库中，作为cos的专用版使用。 此时整个过程都比较简单，就是需要安装go环境和利用docker容器的一些常用方法，进行对应的改造。 就写到这了，有问题可以直接通过邮件联系我一起交流。","raw":null,"content":null,"categories":[{"name":"minio","slug":"minio","permalink":"https://blog.bosong.online/categories/minio/"}],"tags":[{"name":"Golang","slug":"Golang","permalink":"https://blog.bosong.online/tags/Golang/"},{"name":"docker","slug":"docker","permalink":"https://blog.bosong.online/tags/docker/"},{"name":"minio","slug":"minio","permalink":"https://blog.bosong.online/tags/minio/"}]},{"title":"程序员抢火车票攻略-用技术创造美好生活","slug":"程序员抢火车票攻略-用技术创造美好生活","date":"2022-01-10T03:55:53.000Z","updated":"2022-06-02T01:05:59.618Z","comments":true,"path":"程序员抢火车票攻略-用技术创造美好生活.html","link":"","permalink":"https://blog.bosong.online/%E7%A8%8B%E5%BA%8F%E5%91%98%E6%8A%A2%E7%81%AB%E8%BD%A6%E7%A5%A8%E6%94%BB%E7%95%A5-%E7%94%A8%E6%8A%80%E6%9C%AF%E5%88%9B%E9%80%A0%E7%BE%8E%E5%A5%BD%E7%94%9F%E6%B4%BB.html","excerpt":"背景春运已至，又到了回家团圆的时候了，现在春运抢票越来越难，原因是很多人开始使用技术来抢票，在高配置高带宽的服务器上抢票几率要稍微高一点，希望我这篇文章能帮助正在阅读的你抢到回家的火车票。","text":"背景春运已至，又到了回家团圆的时候了，现在春运抢票越来越难，原因是很多人开始使用技术来抢票，在高配置高带宽的服务器上抢票几率要稍微高一点，希望我这篇文章能帮助正在阅读的你抢到回家的火车票。 2021年始开始从win转向了macos，再也没有win机器了，然而抢票软件是12306分流，目前还只能在win服务器上运行，所以就想起了云服务器，我自己也有好几个服务器，但是都是centos服务器，上面有服务器在运行，然后我就想起了阿里云的抢占式实例服务器。 说干就干，用抢占式实例服务器（2H4G5M费用大概5毛钱一小时）成功抢到了回家的高铁票，所以将教程分享出来。 上阿里云（腾讯云）注册账号、实名认证直接上阿里云 官网进行注册和实名认证即可。 由于按量付费服务器或者抢占式实例服务器是后付费账单，这时候需要提前充值好金额（建议100及以上），用完服务器费用支付完成后可以直接将剩余的费用提现出来。 抢占式实例购买步骤阿里云购买服务器大致上分为五个步骤：基础配置-&gt;网络和安全组配置-&gt;系统配置(选填)-&gt;分组配置(选填)-&gt;确认订单，还可以在确认订单步骤将该次的配置保存为模板，以后每次创建服务器都直接从模板创建，减少操作的时间。 进入菜单，选择购买直接选择云服务器ECS进入，可以选择地区，这里我选的北京区域。 选择配置 STEP1：点击抢占式实例的标签页 STEP2：选择一个合适的价格便宜的配置，这里我选的是2H4G，价格是1毛钱多点 STEP3：选择操作系统是Windows Server 2019 数据中心版 64位中文版（安全加固） STEP4：选择网络，我选的是固定带宽5M(因为需要远程连接，这个带宽速度和费用比较合适) STEP5：查看总体配置费用，在页面中显示的价格是你所选的全部配置的费用，可以查看详情 系统配置（选填）系统配置中主要是将 登录凭证设置为创建后设置，因为抢占式实例，需要创建后设置，在开通服务器5分钟后重置你需要的密码就可以登录上去了。 分组配置（选填）分组配置随意填即可 确认配置-下单或者保存模板仔细检查你需要的详细配置，然后点击保存模板，或者直接创建实例即可。 抢票环节当服务器购买完成以后，如果不用VPC模式直接连接到服务器，而是使用Microsoft Remote Desktop客户端连接到服务器时，需要等5分钟将密码设置为你的密码，然后连接到服务上。 接下来几步直接抢票支付即可： 去12306分流下载bypass软件 解压缩bypass软件 登录你的12306账号进入软件 设置你的始发站和目的地、时间，点击抢票即可。 结语云服务器不局限于阿里云，这里只是使用阿里云举个栗子，实际上腾讯云也同样支持，其他云服务商我还没怎么使用过，过程比较简单，费用也还算便宜，适合用于手头没有win电脑或者IP被封的用户去买票。 最后，希望各位新年胜旧年，都能抢到回家的票，阖家团圆。","raw":null,"content":null,"categories":[{"name":"12306","slug":"12306","permalink":"https://blog.bosong.online/categories/12306/"}],"tags":[{"name":"云服务器","slug":"云服务器","permalink":"https://blog.bosong.online/tags/%E4%BA%91%E6%9C%8D%E5%8A%A1%E5%99%A8/"},{"name":"12306","slug":"12306","permalink":"https://blog.bosong.online/tags/12306/"},{"name":"抢占式实例","slug":"抢占式实例","permalink":"https://blog.bosong.online/tags/%E6%8A%A2%E5%8D%A0%E5%BC%8F%E5%AE%9E%E4%BE%8B/"}]},{"title":"mysql的table复制","slug":"mysql的table复制","date":"2022-01-09T06:58:14.000Z","updated":"2022-06-02T01:05:59.616Z","comments":true,"path":"mysql的table复制.html","link":"","permalink":"https://blog.bosong.online/mysql%E7%9A%84table%E5%A4%8D%E5%88%B6.html","excerpt":"起因前段时间在鼓捣数据表的数据上线，主要流程是将线下的数据同步到线上去，线上的部分需要需要和线下保持一直，并且每一次操作都需要自动化将表进行备份， 这个过程主要是靠自己进行代码同步，因为规则比较自定义，所以没有使用一些现有的数据同步。\n主要流程如下：\n123456789- #备份NX的SCHEMA中的表并查询特定数据进行备用NX-SCHEMA: 备份NX-TABLE ==&gt; NX-TABLE_COPY ==&gt; SELECT * FROM NX-TABLE_COPY WHERE ID =xx- #备份JAPAB的SCHEMA中的表并且将上一步的数据写入到备份表中JAPAN-SCHEMA: BEFEN JAPAN-TABLE ==&gt; JAPAN-TABLE_COPY ==&gt; INSERT INTO JAPAN-TABLE_COPY VALUE (xxx)- #将JAPAN的SCHEMA中的原表和备份表进行重命名，将备份表的表名变成源表名，完成数据上线JAPAN-SCHEMA: JAPAN-TABLE ==&gt; RENAME JAPAN-TABL XXX ==&gt; RENAME JAPAN-TABLE_COPY TO JAPAN-TABLE\n\n在这个过程中，我们最主要的一步是在同一个schema下进行将原表进行备份，创建一个对应的不同表，后续所有的操作都改这个表中操作，在这个过程中也是出现了一些问题，后续经过实践后解决了相关问题，特此记录。\n经过我们在备份源Schema中的table时，直接采取了简单粗暴的SQL语句，如下：create table table_name_copy as select * from table_name,该SQL实现了创建table_name_copy并且将table_name中的数据也插入到对应的新表中，看似满足了我们的需求：朴素的备份源表，不进行任何操作。\n然而，简单的事情总是不会那么简单，在我们进行数据比对时，发现数据没啥问题，但是在校验表的DDL时，发现麻烦稍微有点大，此次备份基本没用，因为此时我们的表的主键、索引等等都丢失了，然后我们再查询相关的文档，发现弊端还挺多。\n然后在此上进行了改进，先根据ddl创建表的结构，然后再讲数据导入进来，这样就避免了锁、和索引等问题。SQL如下：\n12345678910第一步：创建表结构方法一： 按照老表的结构创建新表create table new_table like old_table;方法二： 此种方法是先获取ddl，然后再修改表名再次执行DDL，进行表结构创建SHOW CREATE TABLE old_table;第二步：同步原表数据INSERT INTO new_table SELECT * FROM old_table;\n备份表的结构和数据都还是比较简单，但是这个只适用于少量数据的备份，大量数据的备份暂时还没有进行实践，我们大量的数据备份一般使用CSV或者ETL进行同步。\n","text":"起因前段时间在鼓捣数据表的数据上线，主要流程是将线下的数据同步到线上去，线上的部分需要需要和线下保持一直，并且每一次操作都需要自动化将表进行备份， 这个过程主要是靠自己进行代码同步，因为规则比较自定义，所以没有使用一些现有的数据同步。 主要流程如下： 123456789- #备份NX的SCHEMA中的表并查询特定数据进行备用NX-SCHEMA: 备份NX-TABLE ==&gt; NX-TABLE_COPY ==&gt; SELECT * FROM NX-TABLE_COPY WHERE ID =xx- #备份JAPAB的SCHEMA中的表并且将上一步的数据写入到备份表中JAPAN-SCHEMA: BEFEN JAPAN-TABLE ==&gt; JAPAN-TABLE_COPY ==&gt; INSERT INTO JAPAN-TABLE_COPY VALUE (xxx)- #将JAPAN的SCHEMA中的原表和备份表进行重命名，将备份表的表名变成源表名，完成数据上线JAPAN-SCHEMA: JAPAN-TABLE ==&gt; RENAME JAPAN-TABL XXX ==&gt; RENAME JAPAN-TABLE_COPY TO JAPAN-TABLE 在这个过程中，我们最主要的一步是在同一个schema下进行将原表进行备份，创建一个对应的不同表，后续所有的操作都改这个表中操作，在这个过程中也是出现了一些问题，后续经过实践后解决了相关问题，特此记录。 经过我们在备份源Schema中的table时，直接采取了简单粗暴的SQL语句，如下：create table table_name_copy as select * from table_name,该SQL实现了创建table_name_copy并且将table_name中的数据也插入到对应的新表中，看似满足了我们的需求：朴素的备份源表，不进行任何操作。 然而，简单的事情总是不会那么简单，在我们进行数据比对时，发现数据没啥问题，但是在校验表的DDL时，发现麻烦稍微有点大，此次备份基本没用，因为此时我们的表的主键、索引等等都丢失了，然后我们再查询相关的文档，发现弊端还挺多。 然后在此上进行了改进，先根据ddl创建表的结构，然后再讲数据导入进来，这样就避免了锁、和索引等问题。SQL如下： 12345678910第一步：创建表结构方法一： 按照老表的结构创建新表create table new_table like old_table;方法二： 此种方法是先获取ddl，然后再修改表名再次执行DDL，进行表结构创建SHOW CREATE TABLE old_table;第二步：同步原表数据INSERT INTO new_table SELECT * FROM old_table; 备份表的结构和数据都还是比较简单，但是这个只适用于少量数据的备份，大量数据的备份暂时还没有进行实践，我们大量的数据备份一般使用CSV或者ETL进行同步。 结果在同步表结构的过程中出现了一些小的插曲，但是还是圆满的解决了问题，在严格检查的前提下发现了问题，在没有发生故障的情况下及时止损，以后的相关内容也是需要多查文档，锁看看原理，严格进行数据和DDL校验，发现问题速度处理，及时止损。","raw":null,"content":null,"categories":[{"name":"mysql","slug":"mysql","permalink":"https://blog.bosong.online/categories/mysql/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"https://blog.bosong.online/tags/mysql/"}]},{"title":"使用 Pulsar IO 打造流数据管道","slug":"streaming-data-pipelines-with-pulsar-io","date":"2021-11-19T13:22:26.000Z","updated":"2022-06-02T01:05:59.616Z","comments":true,"path":"streaming-data-pipelines-with-pulsar-io.html","link":"","permalink":"https://blog.bosong.online/streaming-data-pipelines-with-pulsar-io.html","excerpt":"\n本文翻译自 StreamNative 博客。博客原作者：Ioannis Polyzos，StreamNative 解决方案工程师。原文链接：https://streamnative.io/blog/engineering/2021-11-10-streaming-data-pipelines-with-pulsar-io/\n\n翻译背景","text":"本文翻译自 StreamNative 博客。博客原作者：Ioannis Polyzos，StreamNative 解决方案工程师。原文链接：https://streamnative.io/blog/engineering/2021-11-10-streaming-data-pipelines-with-pulsar-io/ 翻译背景今年以来就加入到了Pulsar的开源志愿者中，主要翻译一些英文文档以及做对Pulsar的深入研究。这是我翻译的一篇完整的外文博客，以此作为一个记录，相关文章已发布在StreamNative的公众号中。详情点击 背景构建现代数据基础设施一直是当今企业的难题。当今的企业需要管理全天候生成和交付的大量异构数据。然而，由于企业对数据的数量和速度等等有多种要求，没有“一刀切”的解决方案。相反，企业需在不同系统之间移动数据，以便存储、处理和提供数据。 粗看搭建基础设施的历史，企业使用了许多不同的工具来尝试移动数据，例如用于流式工作负载的 Apache Kafka 和用于消息工作负载的 RabbitMQ。现在，Apache Pulsar 的诞生为企业简化了这个过程。 Apache Pulsar 是一个云原生的分布式消息流平台。Pulsar 旨在满足现代数据需求，支持灵活的消息传递语义、分层存储、多租户和异地复制（跨区域数据复制）。自 2018 年毕业成为 Apache 软件基金会顶级项目以来，Pulsar 项目经历了快速的社区增长、周边生态的发展和全球用户的增长。 将 Pulsar 用作数据基础设施的支柱，公司能够以快速且可扩展的方式移动数据。在这篇博文中，我们将介绍如何使用 Pulsar IO 在 Pulsar 和外部系统之间轻松导入和导出数据。 1. Pulsar IO 简介Pulsar IO 是一个完整的工具包，用于创建、部署和管理与外部系统（如键&#x2F;值存储、分布式文件系统、搜索索引、数据库、数据仓库、其他消息传递系统等）集成的 Pulsar 连接器。由于 Pulsar IO 构建在 Pulsar 的无服务器计算层（称为Pulsar Function ）之上，因此编写 Pulsar IO 连接器就像编写 Pulsar Function 一样简单。 借助 Pulsar IO，用户可以使用现有的 Pulsar 连接器或编写自己的自定义连接器，轻松地将数据移入和移出 Pulsar。Pulsar IO 拥有以下优势： 多样的连接器：当前 Pulsar 生态中有许多现有的 Pulsar IO 连接器用于外部系统，例如 Apache Kafka、Cassandra 和 Aerospike。使用这些连接器有助于缩短生产时间，因为创建集成所需的所有部件都已就位。开发人员只需要提供配置（如连接 url 和凭据）来运行连接器。 托管运行时：Pulsar IO 带有托管运行时，负责执行、调度、扩展和容错。开发人员可以专注于配置和业务逻辑。 多接口：通过 Pulsar IO 提供的接口，用户可以减少用于生成和使用应用程序的样板代码。 高扩展性：在需要更多实例来处理传入流量的场景下，用户可以通过更改一个简单的配置值轻松横向扩展；如果用户使用 Kubernetes 运行时，可根据流量需求进行弹性扩展。 充分利用 schema：Pulsar IO 通过在数据模型上指定 schema 类型来帮助用户充分运用 schema，Pulsar IO 支持 JSON、Avro 和 Protobufs 等 schema 类型。 2. Pulsar IO 运行时由于 Pulsar IO 建立在 Pulsar Function 之上，因此 Pulsar IO 和 Pulsar Function 具有相同的运行时选项。部署 Pulsar IO 连接器时，用户有以下选择： 线程：在与工作线程相同的 JVM 中运行。（通常用于测试的和本地运行，不推荐用于生产部署。） 进程：在不同的进程中运行，用户可以使用多个工作线程跨多个节点横向扩展。 Kubernetes：在 Kubernetes 集群中作为 Pod 运行，worker 与 Kubernetes 协调。这种运行时方式保证用户可以充分利用 Kubernetes 这样的云原生环境提供的优势，比如轻松横向扩展。 3. Pulsar IO 接口如前所述，Pulsar IO 减少了生成和消费应用程序所需的样板代码。它通过提供不同的基本接口来实现这一点，这些接口抽象出样板代码并允许我们专注于业务逻辑。Pulsar IO 支持 Source 和 Sink 的基本接口。Source 连接器（Source connector）允许用户将数据从外部系统带入 Pulsar，而 Sink 连接器（Sink Connector）可用于将数据移出 Pulsar 并移入外部系统，例如数据库。还有一种特殊类型的 Source 连接器，称为 Push Source。Push Source 连接器可以轻松实现某些需要推送数据的集成。举例来说，Push Source 可以是变更数据捕获源系统，它在接收到新变更后，会自动将该变更推送到 Pulsar。 Source 接口12345678910111213141516171819public interface Source&lt;T&gt; extends AutoCloseable &#123; /** * Open connector with configuration. * * @param config initialization config * @param sourceContext environment where the source connector is running * @throws Exception IO type exceptions when opening a connector */ void open(final Map&lt;String, Object&gt; config, SourceContext sourceContext) throws Exception; /** * Reads the next message from source. * If source does not have any new messages, this call should block. * @return next message from source. The return result should never be null * @throws Exception */ Record&lt;T&gt; read() throws Exception;&#125; Push Source 接口12345678910111213141516171819202122232425262728293031323334public interface BatchSource&lt;T&gt; extends AutoCloseable &#123; /** * Open connector with configuration. * * @param config config that&#x27;s supplied for source * @param context environment where the source connector is running * @throws Exception IO type exceptions when opening a connector */ void open(final Map&lt;String, Object&gt; config, SourceContext context) throws Exception; /** * Discovery phase of a connector. This phase will only be run on one instance, i.e. instance 0, of the connector. * Implementations use the taskEater consumer to output serialized representation of tasks as they are discovered. * * @param taskEater function to notify the framework about the new task received. * @throws Exception during discover */ void discover(Consumer&lt;byte[]&gt; taskEater) throws Exception; /** * Called when a new task appears for this connector instance. * * @param task the serialized representation of the task */ void prepare(byte[] task) throws Exception; /** * Read data and return a record * Return null if no more records are present for this task * @return a record */ Record&lt;T&gt; readNext() throws Exception;&#125; Sink 接口123456789101112131415161718public interface Sink&lt;T&gt; extends AutoCloseable &#123; /** * Open connector with configuration. * * @param config initialization config * @param sinkContext environment where the sink connector is running * @throws Exception IO type exceptions when opening a connector */ void open(final Map&lt;String, Object&gt; config, SinkContext sinkContext) throws Exception; /** * Write a message to Sink. * * @param record record to write to sink * @throws Exception */ void write(Record&lt;T&gt; record) throws Exception;&#125; 4. 总结Apache Pulsar 能够作为现代数据基础设施的支柱，它使企业能够以快速且可扩展的方式搬运数据。Pulsar IO 是一个连接器框架，它为开发人员提供了所有必要的工具来创建、部署和管理与不同系统集成的 Pulsar 连接器。Pulsar IO 抽象掉所有样板代码，使开发人员可以专注于应用程序逻辑。 5. 延伸阅读如果您有兴趣了解更多信息并构建自己的连接器，请查看以下资源： 查看 Pulsar 周边生态中所有 Pulsar IO 连接器 构建和部署 Source 连接器 为 Pulsar IO 编写自定义 Sink 连接器 监控和故障排除连接器","raw":null,"content":null,"categories":[{"name":"Pulsar","slug":"Pulsar","permalink":"https://blog.bosong.online/categories/Pulsar/"}],"tags":[{"name":"Pulsar","slug":"Pulsar","permalink":"https://blog.bosong.online/tags/Pulsar/"},{"name":"IO","slug":"IO","permalink":"https://blog.bosong.online/tags/IO/"},{"name":"Stream","slug":"Stream","permalink":"https://blog.bosong.online/tags/Stream/"}]},{"title":"苹果M1芯片的MBP安装WIN10","slug":"苹果M1芯片的MBP安装WIN10","date":"2021-07-22T14:43:00.000Z","updated":"2022-06-02T01:05:59.618Z","comments":true,"path":"苹果M1芯片的MBP安装WIN10.html","link":"","permalink":"https://blog.bosong.online/%E8%8B%B9%E6%9E%9CM1%E8%8A%AF%E7%89%87%E7%9A%84MBP%E5%AE%89%E8%A3%85WIN10.html","excerpt":"前言朋友买了一台M1的MBP，但是又需要安装财务软件(财务软件需要安装在windows系统上)，M1目前还不支持原生安装WIN10,所以采用虚拟安装的方法来安装对应的WIN10。","text":"前言朋友买了一台M1的MBP，但是又需要安装财务软件(财务软件需要安装在windows系统上)，M1目前还不支持原生安装WIN10,所以采用虚拟安装的方法来安装对应的WIN10。 安装步骤一开始不知道这里面有坑，直接在https://next.itellyou.cn/ 网站上下载了普通的WIN10企业版，结果自然不可用。 然后发现镜像列表中是有ARM的镜像可下，然而经过漫长的文件下载过程后，发现镜像仍不可用。 这时候就各种查文档，然后查到了网上说去微软官网下载官方ARM的官方预览版，我兴致冲冲的找到了对应的版本，然后不给下，需要注册成为预览版的体验用户，但是并没有告诉我成为预览版体验用户的入口。。。 但是这时候我并没有放弃，找了一大堆文档，终于找到了下载镜像的方法。 如果需要在M1芯片的Mac电脑上安装基于ARM64内部预览版的Windows 10虚拟机，需要ARM64安装源 (VHDX)。下面是详细步骤: 点击访问微软 Windows内部预览下载网页. 如果自己已经是内部体验用户，请使用页面右上角的 “登录” 选项进行登录。 如果不是内部体验用户，请点击 链接点击注册选项注册Windows内部体验的用户。 成功注册Windows 内部体验用户后，再次登录然后回到 微软 Windows内部预览下载网页. 在页面的下面可以找到WIN10的ARM64位镜像的VHDX的文件下载，如图所示: 然后在https://www.parallels.cn/ 网站下载Parallels Desktop 然后先安装好它（激活考虑到版权原因，此处不作说明），静静的等待WIN10下载完成 当WIN10 镜像的VHDX文件下载完成后，双击VHDX文件，将自动打开Parallels Desktop 然后进入了配置页面，选择用途时候可以选择生产力，或者测试均可 点继续，填一下你需要创建的镜像名称和地址，默认可不修改 进入了这一步就静静等待WIN10镜像初始化安装完成，可以安装需要的软件了。 温馨提示： WIN10镜像原版是全英文的，如果需要换成英文在设置中下载中文语言包然后更改语言为中文即可。 WIN10关闭后如果下次启动，直接打开Parallels Desktop，然后选择你上次创建的VM名称，右键恢复即可。 以上就是我在M1的MBP安装WIN10的全部步骤。 结语整个过程因为是第一次安装，提前没有做很多的准备，所以一步一坑，花了接近4个小时才解决问题，写这篇文章的目的就是将对应的步骤记录下来，以便参考或者下次自己安装的时候还知道怎么安装。","raw":null,"content":null,"categories":[{"name":"Macos","slug":"Macos","permalink":"https://blog.bosong.online/categories/Macos/"}],"tags":[{"name":"apple","slug":"apple","permalink":"https://blog.bosong.online/tags/apple/"},{"name":"win10","slug":"win10","permalink":"https://blog.bosong.online/tags/win10/"}]},{"title":"clickhouse和mysql的不同用法之陷入误区","slug":"clickhouse和mysql的不同用法之陷入误区","date":"2021-07-19T14:25:31.000Z","updated":"2022-06-02T01:05:59.615Z","comments":true,"path":"clickhouse和mysql的不同用法之陷入误区.html","link":"","permalink":"https://blog.bosong.online/clickhouse%E5%92%8Cmysql%E7%9A%84%E4%B8%8D%E5%90%8C%E7%94%A8%E6%B3%95%E4%B9%8B%E9%99%B7%E5%85%A5%E8%AF%AF%E5%8C%BA.html","excerpt":"前言我们的数据计算式基于clickhouse的，由于接触clickhouse不久，看官网介绍语法和mysql是类似的，就放心大胆的使用mysql的大量语法，然后遇到了一个很奇怪的问题，也是这个奇怪的问题让我对列式数据库有了更深入的了解。","text":"前言我们的数据计算式基于clickhouse的，由于接触clickhouse不久，看官网介绍语法和mysql是类似的，就放心大胆的使用mysql的大量语法，然后遇到了一个很奇怪的问题，也是这个奇怪的问题让我对列式数据库有了更深入的了解。 遇到的问题先了解一下clickhouse对列式数据库的图表述： 再了解一下mysql的行式数据库的图表述： 然后下面这样一段sql: 123456select a,0 as b,0 as cfrom tbl_xxxwhere del = 1 and (1&gt;1 or b in (1,2,3) or c in (4,5,6))group by a,b,corder by a desc 这样一段很简单的sql，在clickhouse中却无论如何都查询不出结果，明明在where条件在数据库中满足条件的数据量非常的多，却出现这样奇怪的现象。 排查问题 排查到的问题1：以为是 1&gt;1这个语句导致了数据库无法查询出数据，所以将1&gt;1 改成了 2&gt;1，然而能查询出数据了，但是查询出的是全量的数据，所以经过验证后发现该问题无解 排查到的问题2：突然想到会不会是由于对clikhouse不熟悉导致了相关的问题出现，所以将同样的表在mysql中创建好，并导入一部分数据，这时……，令人惊奇的事情发生了，mysql可以查出对应的数据 其实通过两个方法就定位到了问题所在，还是比较幸运的，接下来就是解决方案了。 解决问题在经过现象验证后，发现行式数据库是这样的规则，当你查询的数据被你赋值了，其实where中的语句如果有相同的字段，那么直接就是对你赋值的值的查询了，所以 1，2，3怎么可以匹配上0这个数呢。既然发现了问题，解决问题也很简单，有个最简单的方案： 将b&#x2F;c的select中的列名和group&#x2F;order by中的列名都进行修改，修改为b_tmp,c_tmp即可解决问题了，因为这条sql使用了好几个union all，所以是无法舍弃对应的字段的，否则会报错。 结语遇到不熟悉的组件还是要多多查看文档，工欲善其事必先利其器，多看文档，了解一下不同的话也是不会出现这样很简单但是有时候也能让人摸不着头脑的问题了，吃一堑长一智，也让我对列式数据库有了更深的理解。","raw":null,"content":null,"categories":[{"name":"ClickHouse","slug":"ClickHouse","permalink":"https://blog.bosong.online/categories/ClickHouse/"}],"tags":[{"name":"ClickHouse","slug":"ClickHouse","permalink":"https://blog.bosong.online/tags/ClickHouse/"},{"name":"Mysql","slug":"Mysql","permalink":"https://blog.bosong.online/tags/Mysql/"}]},{"title":"go-web容器化中遇到的两个问题","slug":"go-web容器化中遇到的两个问题","date":"2021-07-18T15:53:43.000Z","updated":"2022-06-02T01:05:59.615Z","comments":true,"path":"go-web容器化中遇到的两个问题.html","link":"","permalink":"https://blog.bosong.online/go-web%E5%AE%B9%E5%99%A8%E5%8C%96%E4%B8%AD%E9%81%87%E5%88%B0%E7%9A%84%E4%B8%A4%E4%B8%AA%E9%97%AE%E9%A2%98.html","excerpt":"前言今年开始接触并且实践到Golang，近期自己写了一个相册的服务，是基于前后端分离的模式，由Go提供rest给web页面使用。在项目前期是直接使用的打包完成的二进制文件执行，在管理方面存在一些不方便的地方，所以周末抽时间将其容器化，实现自动化的部署方案，主要就是采用coding的devops流程，容器化使用的还是docker容器，使用的是alpine的镜像，在这个过程中遇到一些问题，下面会详细讲出，以此记录。","text":"前言今年开始接触并且实践到Golang，近期自己写了一个相册的服务，是基于前后端分离的模式，由Go提供rest给web页面使用。在项目前期是直接使用的打包完成的二进制文件执行，在管理方面存在一些不方便的地方，所以周末抽时间将其容器化，实现自动化的部署方案，主要就是采用coding的devops流程，容器化使用的还是docker容器，使用的是alpine的镜像，在这个过程中遇到一些问题，下面会详细讲出，以此记录。 docker容器化过程将服务自动化发布流程还是比较简单的，分为以下几步：1、github上创建对应的代码仓库，作为源代码的提交2、在coding上新建一个项目，与github的代码库绑定（github同时也提供github action，也是非常好用的，但是我的服务器主机都在国内，所以涉及到一个跨境网络同步延时很高的问题）3、在创建的项目中有个持续集成-构建计划，此时就是自己编写对应的jenkins文件，当代码有更新时，会自动hook到流程中，执行对应的build&#x2F;deploy过程4、完成deploy过程后，检查对应容器的服务状态以及接口状态是否ok，整个自动化发布流程算是结束。 go-web在使用alpine过程中出现的问题Q1 and A在启动容器时，一直启动不成功，提示standard_init_linux.go:211: exec user process caused &quot;no such file or directory&quot;,这个问题查了一下google，发现是一个非常基本的问题，有很多的blog上都有这样的问题，原因是由于go动态引用了特殊的包，在alpine的包中不存在的问题，详情可以查看,解决方案也很简单，在build时，加个参数即可：-tags netgo，打包时就用命令GOARCH=amd64 go build -tags netgo -o app即可。 Q2 and A启动容器后，日志一切正常，但是访问接口无论如何也访问不通，当执行curl localhost:8111时，提示curl: (56) Recv failure: Connection reset by peer,此时查看容器的端口映射情况，也是正常映射的：0.0.0.0:8111-&gt;8111/tcp, :::8111-&gt;8111/tcp,然后查看我的config配置，发现有一行是host的地址，我填的是127.0.0.1,然后将它修改为0.0.0.0后，外部服务正常可以访问，发现在容器内部127.0.0.1的地址可以直接访问通，当在宿主机进行访问时，即使端口映射是对的也是访问不通的，当改成0.0.0.0后，有端口映射的情况是可以访问通的，代表发布到外部访问 总结遇到的都是两个小问题，解决和查文档，思考的过程中也是很快的，在计算机的世界里很多都是相通的，所谓好记性不如烂笔头，所以将其记录。如果有更多想要交流的，欢迎联系我，可以直接给我发邮件：&#115;&#111;&#x6e;&#103;&#98;&#x6f;&#x32;&#x30;&#50;&#x31;&#64;&#111;&#x75;&#x74;&#108;&#x6f;&#111;&#x6b;&#x2e;&#99;&#111;&#x6d;。","raw":null,"content":null,"categories":[{"name":"Docker","slug":"Docker","permalink":"https://blog.bosong.online/categories/Docker/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://blog.bosong.online/tags/Docker/"},{"name":"Golang","slug":"Golang","permalink":"https://blog.bosong.online/tags/Golang/"}]},{"title":"standard-notes之集成自己的插件库","slug":"standard-notes之集成自己的插件库","date":"2021-07-16T14:58:49.000Z","updated":"2022-06-02T01:05:59.616Z","comments":true,"path":"standard-notes之集成自己的插件库.html","link":"","permalink":"https://blog.bosong.online/standard-notes%E4%B9%8B%E9%9B%86%E6%88%90%E8%87%AA%E5%B7%B1%E7%9A%84%E6%8F%92%E4%BB%B6%E5%BA%93.html","excerpt":"前言上一篇文章写了怎么部署standardnotes的自建笔记本，在使用过程中发现还需要很多的插件来配合更好的使用standardnotes,来做数据备份以及更好的编辑文档。standardnotes的插件是可插拔的，简而言之就是将静态页面加载到页面中，来使用其中的功能，达到增强的目的。","text":"前言上一篇文章写了怎么部署standardnotes的自建笔记本，在使用过程中发现还需要很多的插件来配合更好的使用standardnotes,来做数据备份以及更好的编辑文档。standardnotes的插件是可插拔的，简而言之就是将静态页面加载到页面中，来使用其中的功能，达到增强的目的。 关于standardnotes 作为开源软件和服务提供商，它本身的写笔记和同步笔记是不收费的，提供了mac&#x2F;win的客户端和web端应用，所以多端同步是它最大的优势之一，但它对于插件是使用的收费订阅的模式，每个月基本在3美金以内，但是我都自建服务了，为啥还需要去用它本身的服务了，所以参考了一些文档，调查了一些插件的接入步骤，陆续接入了很多插件。 接入插件步骤查看对应的插件接入文档作为开发人员，一般了解到一个不太熟悉的内容，或者需要接入某些组件，第一件事就是查看对应的文档，自己了解到一些细节点，文档地址：https://docs.standardnotes.org/extensions/intro/ 查看github上大牛帮你收集好的插件集合github上有很多各种领域的大牛，能让你减少很多的收集软件的时间，这个大牛将standardnotes的一些常用的组件都进行了收集，并且还写成了脚本帮助我们将对应的插件一次性生成到某个地方，来供我们直接使用，减去很多繁琐的步骤，大牛对应的github地址：https://github.com/iganeshk/standardnotes-extensions 。由于大牛的仓库没有及时更新，所以我根据最新的版本库，fork了一下大牛的仓库并且完成了对应的最新适配：https://github.com/dislazy/standardnotes-extensions 可以直接使用我fork的仓库，下面的文档基于dislazy的仓库进行构建过程 拉取github的代码并且生成对应的插件文件夹 查看 插件接入文档 了解插入的接入方式 查看 github上集成对应插件的文档 将对应github的代码拉取到本地服务器中，然后以env.simple文件作为模板，创建自己的插件生成配置，包括插件的对应域名和你的github-token，github-token用于拉取githun上的代码时不受速度等的限制 创建并配置好.env文件后，我是直接运行docker生成对应的public的插件文件夹，运行在插件文件夹中运行docker run -v $PWD/.env:/build/.env -v $PWD/extensions:/build/extensions -v $PWD/public:/build/public mtoohey/standardnotes-extensions 当public文件夹配置完成了之后，直接将之前配置过sync服务器对应的反向代理配置一下即可，代码块中是nginx的配置文件。 当配置完成了重新reload一下nginx的配置文件完成配置，直接可以在网页中应用了。1234567891011121314151617181920212223242526272829303132location ^~ /extensions &#123; autoindex off; alias /path/to/standardnotes-extensions/public; -- 此处修改为你自己的public路径即可 # CORS HEADERS if ($request_method = &#x27;OPTIONS&#x27;) &#123; add_header &#x27;Access-Control-Allow-Origin&#x27; &#x27;*&#x27;; add_header &#x27;Access-Control-Allow-Methods&#x27; &#x27;GET, POST, OPTIONS&#x27;; # # Custom headers and headers various browsers *should* be OK with but aren&#x27;t # add_header &#x27;Access-Control-Allow-Headers&#x27; &#x27;DNT,User-Agent,X-Requested-With,If-Modified-Since,Cache-Control,Content-Type,Range&#x27;; # # Tell client that this pre-flight info is valid for 20 days # add_header &#x27;Access-Control-Max-Age&#x27; 1728000; add_header &#x27;Content-Type&#x27; &#x27;text/plain; charset=utf-8&#x27;; add_header &#x27;Content-Length&#x27; 0; return 204; &#125; if ($request_method = &#x27;POST&#x27;) &#123; add_header &#x27;Access-Control-Allow-Origin&#x27; &#x27;*&#x27;; add_header &#x27;Access-Control-Allow-Methods&#x27; &#x27;GET, POST, OPTIONS&#x27;; add_header &#x27;Access-Control-Allow-Headers&#x27; &#x27;DNT,User-Agent,X-Requested-With,If-Modified-Since,Cache-Control,Content-Type,Range&#x27;; add_header &#x27;Access-Control-Expose-Headers&#x27; &#x27;Content-Length,Content-Range&#x27;; &#125; if ($request_method = &#x27;GET&#x27;) &#123; add_header &#x27;Access-Control-Allow-Origin&#x27; &#x27;*&#x27;; add_header &#x27;Access-Control-Allow-Methods&#x27; &#x27;GET, POST, OPTIONS&#x27;; add_header &#x27;Access-Control-Allow-Headers&#x27; &#x27;DNT,User-Agent,X-Requested-With,If-Modified-Since,Cache-Control,Content-Type,Range&#x27;; add_header &#x27;Access-Control-Expose-Headers&#x27; &#x27;Content-Length,Content-Range&#x27;; &#125; &#125; 需要注意的点 按需在extensions-reposity文件夹中选择合适的插件配置复制到extension 文件夹中，尽量按需选用，否则构建的时间会很长 在yaml文件中有一项配置github: sn-extensions/xxxx 中的sn-extensions地址已被官方修改为：standardnotes即可，在dislazy仓库中已被修复 由于大牛的更新不是特别及时，所以很多插件的版本比较过时，或者插件被原作者删除，及时根据对应的github地址去看看release版本，将插件的版本更新最新的版本 可以在github上的standardnotes组织中找到一些未被收录的其他好用的插件，集成到你的插件库中，根据文档：https://docs.standardnotes.org/extensions/intro/ 进行操作 结语我的插件库主要是将markdown的编辑器，以及推送github的插件集成了，为了更好的编辑文档和推送文档更新。尤其对github推送点赞，直接一键推送，真的太棒了。如果有更好用的插件库或者插件，欢迎给我推荐，如果想要联系我，也可以直接给我发邮件：&#x73;&#x6f;&#110;&#x67;&#98;&#111;&#x32;&#48;&#x32;&#x31;&#64;&#x6f;&#117;&#116;&#x6c;&#111;&#111;&#107;&#46;&#99;&#111;&#109;。","raw":null,"content":null,"categories":[{"name":"Docker","slug":"Docker","permalink":"https://blog.bosong.online/categories/Docker/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://blog.bosong.online/tags/Docker/"},{"name":"Note","slug":"Note","permalink":"https://blog.bosong.online/tags/Note/"}]},{"title":"好用的日常笔记本standard notes","slug":"好用的日常笔记本Standard-notes","date":"2021-07-11T13:22:01.000Z","updated":"2022-06-02T01:05:59.617Z","comments":true,"path":"好用的日常笔记本Standard-notes.html","link":"","permalink":"https://blog.bosong.online/%E5%A5%BD%E7%94%A8%E7%9A%84%E6%97%A5%E5%B8%B8%E7%AC%94%E8%AE%B0%E6%9C%ACStandard-notes.html","excerpt":"前言很久很久之前就一直在找一些好用的并且开源的note app，尝试过trilium、蚂蚁笔记、notion、语雀 都没有找到我心仪的那一款，要么是数据是存储在境外，一旦国家的墙更厚了，就尬了，另外一些就是数据很分散，备份出来的数据无法很顺利的导入到其他的app中。直到有一天我发现了Standard notes。","text":"前言很久很久之前就一直在找一些好用的并且开源的note app，尝试过trilium、蚂蚁笔记、notion、语雀 都没有找到我心仪的那一款，要么是数据是存储在境外，一旦国家的墙更厚了，就尬了，另外一些就是数据很分散，备份出来的数据无法很顺利的导入到其他的app中。直到有一天我发现了Standard notes。 关于Standard notesStandard notes是一款免费、开源且完全加密的笔记应用程序。 简单介绍一些它的优点： 开源 代码开源，可以自己创建对应的服务，将数据存储在自己的自建数据库中，这也是我最看重的一点 免费 知识付费时代，有一些免费的可维护的项目也是很难得，该产品也是通过开源的形式，然后使用官方的服务队插件进行收费 完全加密 按照文档的说法是完全的端到端加密，数据在浏览器进行接口传输之前就已经进行了加密，避免网络传输过程中被拦截后数据泄露的场景 部署Standard notesStandard notes大部分语言是使用node写的，按照微服务的方式进行拆分，分为几大块： 服务层： 同步服务器 业务逻辑的核心，负责对用户数据的所有操作。 同步服务器 work 同步服务器 JS Worker 负责同步服务器 JS 可能为后台处理卸载的所有异步任务。这包括例如处理电子邮件备份、解决笔记重复问题、将笔记发送到扩展服务器等等。 身份验证 该服务器负责所有授权和认证机制。身份验证是处理和处理所有与帐户相关的元数据的地方。 身份验证 work Auth Worker 负责所有与认证和授权领域相关的异步任务例如，处理帐户删除请求和用户的注册后任务。 API网关 这是整个架构的主要“入口点”。API 网关充当所有无法直接访问的服务的路由器和代理。数据层： 数据库 MySQL 数据库服务器。这是存储所有数据的地方。 缓存 Redis 缓存节点，其中保留所有临时数据以进行性能优化和自动过期功能。在自托管模式下，Redis 默认用作服务与其work之间的通信队列。 部署步骤我是使用的docker-compose 加上自己的公有云数据库和缓存进行部署的，官方给出的docker-compose文件可以参见:文档 第一步：将https://github.com/standardnotes/standalone git仓库的内容clone或者下载下来放到服务器的对应目录 第二步：进行对应的文件夹，然后执行：./server.sh init 第三步：编辑 .env文件配置自己的数据库以及对应的token，编辑docker文件内的api-gatewat.env文件和auth.env文件，修改对应的token 第四步：当配置文件修改完成以后，执行./server.sh start 启动服务 第五步：执行./server.sh logs 查看服务日志，如果出现问题根据对应的提示进行解决 第六步：给api-gateway服务配置对应的代理，我是使用的nginx，用域名进行代理即可 以上的所有步骤都可以在官方文档中看到。 注意：我的docker-compose根据官方的文件修改而来，使用的是自己的数据层，所以没有启动对应的数据库，如下，具体步骤可以参考以上文档。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899version: &#x27;3.5&#x27;services: syncing-server-js: image: standardnotes/syncing-server-js:1.35.1 entrypoint: [ &quot;./docker/entrypoint.sh&quot;, &quot;start-web&quot; ] env_file: .env environment: PORT: 3000 restart: unless-stopped networks: - standardnotes_standalone syncing-server-js-worker: image: standardnotes/syncing-server-js:1.35.1 depends_on: - syncing-server-js entrypoint: [ &quot;./wait-for.sh&quot;, &quot;syncing-server-js&quot;, &quot;3000&quot;, &quot;./docker/entrypoint.sh&quot;, &quot;start-worker&quot; ] env_file: .env environment: PORT: 3000 restart: unless-stopped networks: - standardnotes_standalone api-gateway: image: standardnotes/api-gateway:1.19.0 depends_on: - auth - syncing-server-js env_file: docker/api-gateway.env ports: - $&#123;EXPOSED_PORT&#125;:3000 environment: PORT: 3000 AUTH_JWT_SECRET: &#x27;$&#123;AUTH_JWT_SECRET&#125;&#x27; entrypoint: [ &quot;./wait-for.sh&quot;, &quot;auth&quot;, &quot;3000&quot;, &quot;./wait-for.sh&quot;, &quot;syncing-server-js&quot;, &quot;3000&quot;, &quot;./docker/entrypoint.sh&quot;, &quot;start-web&quot; ] networks: - standardnotes_standalone auth: image: standardnotes/auth:1.11.0 depends_on: - syncing-server-js entrypoint: [ &quot;./wait-for.sh&quot;, &quot;syncing-server-js&quot;, &quot;3000&quot;, &quot;./docker/entrypoint.sh&quot;, &quot;start-web&quot; ] env_file: docker/auth.env environment: PORT: 3000 DB_HOST: &#x27;$&#123;DB_HOST&#125;&#x27; DB_REPLICA_HOST: &#x27;$&#123;DB_REPLICA_HOST&#125;&#x27; DB_PORT: &#x27;$&#123;DB_PORT&#125;&#x27; DB_DATABASE: &#x27;$&#123;DB_DATABASE&#125;&#x27; DB_USERNAME: &#x27;$&#123;DB_USERNAME&#125;&#x27; DB_PASSWORD: &#x27;$&#123;DB_PASSWORD&#125;&#x27; DB_DEBUG_LEVEL: &#x27;$&#123;DB_DEBUG_LEVEL&#125;&#x27; DB_MIGRATIONS_PATH: &#x27;$&#123;DB_MIGRATIONS_PATH&#125;&#x27; REDIS_URL: &#x27;$&#123;REDIS_URL&#125;&#x27; AUTH_JWT_SECRET: &#x27;$&#123;AUTH_JWT_SECRET&#125;&#x27; networks: - standardnotes_standalone auth-worker: image: standardnotes/auth:1.11.0 depends_on: - auth entrypoint: [ &quot;./wait-for.sh&quot;, &quot;auth&quot;, &quot;3000&quot;, &quot;./docker/entrypoint.sh&quot;, &quot;start-worker&quot; ] env_file: docker/auth.env environment: PORT: 3000 DB_HOST: &#x27;$&#123;DB_HOST&#125;&#x27; DB_REPLICA_HOST: &#x27;$&#123;DB_REPLICA_HOST&#125;&#x27; DB_PORT: &#x27;$&#123;DB_PORT&#125;&#x27; DB_DATABASE: &#x27;$&#123;DB_DATABASE&#125;&#x27; DB_USERNAME: &#x27;$&#123;DB_USERNAME&#125;&#x27; DB_PASSWORD: &#x27;$&#123;DB_PASSWORD&#125;&#x27; DB_DEBUG_LEVEL: &#x27;$&#123;DB_DEBUG_LEVEL&#125;&#x27; DB_MIGRATIONS_PATH: &#x27;$&#123;DB_MIGRATIONS_PATH&#125;&#x27; REDIS_URL: &#x27;$&#123;REDIS_URL&#125;&#x27; AUTH_JWT_SECRET: &#x27;$&#123;AUTH_JWT_SECRET&#125;&#x27; networks: - standardnotes_standalonenetworks: standardnotes_standalone: name: standardnotes_standalone 使用Standard notes当所有的部署步骤完成，并且配置好反向代理之后，就可以正式启用对应的服务了，使用步骤如下： 打开 https://app.standardnotes.org/ 链接 点击Account，然后点击注册，在高级配置里面配置上自己的服务域名 填上自己的账号，然后就可以开始使用了 初始情况下的编辑器是默认的官方编辑器，可以引入markdown编辑器，文档如下：https://yjk.im.sb/sn-markdown/ 使用感受感觉使用起来很清爽，数据备份也很容易，备份出来的数据是我想要的样子，这样以后即使这个软件不可用了我还可以迁移到其他的服务中，也遇到了一些问题： 断网情况下可能同步的不是特别及时，所以如果断网情况下编辑内容话尽量在客户端中进行，它支持各个终端的客户端，我一般是习惯网页型的 如果不放心它们的官方网页，也可以进行自建，文档如下：https://github.com/standardnotes/web还有更多的可以自己定义的地方可以发掘。。。 结语我理想中的笔记本是随时拿来可用，我想记录一个东西的时候立刻能让我创建对应的文档并且进行记录，特别是一些零碎的内容，如果文档打开的过慢，或者操作很复杂，甚至能让我的灵感消失，所以我选用了这么一款部署起来比较折腾，但是使用起来却让我很喜欢的note app，备份也是全量的很简单的text格式，如果有更好用的，欢迎给我推荐，如果想要联系我，也可以直接给我发邮件：&#115;&#111;&#x6e;&#103;&#x62;&#x6f;&#50;&#x30;&#50;&#x31;&#64;&#x6f;&#117;&#x74;&#x6c;&#111;&#111;&#x6b;&#x2e;&#99;&#111;&#x6d;。","raw":null,"content":null,"categories":[{"name":"Docker","slug":"Docker","permalink":"https://blog.bosong.online/categories/Docker/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://blog.bosong.online/tags/Docker/"},{"name":"Note","slug":"Note","permalink":"https://blog.bosong.online/tags/Note/"}]},{"title":"如何为网站申请泛域名证书并自动续约","slug":"如何为网站配置泛域名SSL证书","date":"2021-06-02T15:33:34.000Z","updated":"2022-06-02T01:05:59.617Z","comments":true,"path":"如何为网站配置泛域名SSL证书.html","link":"","permalink":"https://blog.bosong.online/%E5%A6%82%E4%BD%95%E4%B8%BA%E7%BD%91%E7%AB%99%E9%85%8D%E7%BD%AE%E6%B3%9B%E5%9F%9F%E5%90%8DSSL%E8%AF%81%E4%B9%A6.html","excerpt":"自己有很多的网站，每次都需要申请SSL证书，所以最近在鼓捣怎么申请泛域名证书减少工作量。","text":"自己有很多的网站，每次都需要申请SSL证书，所以最近在鼓捣怎么申请泛域名证书减少工作量。 前言现在随着chrome大力推广网站HTTPS化，推进互联网的数据安全进程，SSL证书的申请渠道有非常的多，个人用户申请免费的SSL证书很方便。 阿里云、腾讯云都支持20个以内的单域名SSL证书，有效期是一年，但是因为网站比较多，所以首先考虑方案是申请一个免费的泛域名证书，这样在一级的所有网站可以复用一套SSL证书，更新起来也不用那么繁琐。 申请SSL免费证书的渠道 使用certbot申请SSL证书，可申请普通域名和泛域名证书并配置自动续约，有效期90天 使用acme.sh申请SSL证书，可申请普通域名和泛域名证书并配置自动续约，有效期90天 使用阿里云申请SSL证书，仅可申请普通单域名证书，过期需要人工再次申请，有效期365天 使用腾讯云申请SSL证书，仅可申请普通单域名证书，过期需要人工再次申请，有效期365天 …使用acme.sh申请免费的SSL证书并配置自动续期 为什么选择acme.sh? 由于certbot的方式需要安装对应的安装包并且需要支持python环境，配置起来较为麻烦，故不选 由于阿里云、腾讯云证书都是单域名的，故不选 acme.sh完全基本shell脚本，不需要安装对应依赖，直接下载脚本shell脚本即可安装对应的证书如何使用acme.sh申请证书(macos) 打开iterm，然后mkidr .acme.sh 然后git clone [https://github.com/acmesh-official/acme.sh.git](https://github.com/acmesh-official/acme.sh.git)到对应文件夹下即可 申请SSL证书需要验证域名的所有权，由于我使用的是阿里云的万网域名，所以可以直接使用阿里云的DNS进行验证并且自动完成添加TXT配置完成域名验证，参见文档 配置好ak之后，即可申请SSL证书acme.sh --issue --dns dns_ali -d &#39;*.bosong.online&#39;等待命令执行完成，完成SSL证书的申请 证书是在我的mac电脑上申请的，所以可以scp到对应服务器进行替换即可，替换完成重启nginx如何为SSL证书自动续约使用acme.sh的方式申请的SSL证书有效期只有90天，这代表一年最少得人工操作4次证书申请以及发布到对应服务器重启nginx。所以将对应的命令写成了shell命令，使用crontab -e定期执行脚本，进行证书的检查更新以及自动传送及重启nginx，对应脚本如下(仅供参考，可以根据实际情况进行修改)1234#!/bin/bashacme.sh --renew --dns dns_ali -d &#x27;*.bosong.online&#x27;scp #证书的生成路径 ce-155:/data/nginx/conf/cert/ssh ce-155 &amp;&amp; systemctl reload nginx.service &amp;&amp; exit 结语使用工具自动申请SSL证书简单并且很方便，能节省自己很多证书，泛域名证书用起来也会很酷，文章有些中如果有错误或者不到位的地方，请多多原谅。 参阅文档 acme.sh中文部署指南 acme.shDNS配置指南 acme.sh英文部署指南","raw":null,"content":null,"categories":[{"name":"ssl","slug":"ssl","permalink":"https://blog.bosong.online/categories/ssl/"}],"tags":[{"name":"linux","slug":"linux","permalink":"https://blog.bosong.online/tags/linux/"},{"name":"ssl","slug":"ssl","permalink":"https://blog.bosong.online/tags/ssl/"},{"name":"web","slug":"web","permalink":"https://blog.bosong.online/tags/web/"}]},{"title":"基于authelia的最佳实践","slug":"基于authelia的最佳实践","date":"2021-05-11T14:01:20.000Z","updated":"2022-06-02T01:05:59.617Z","comments":true,"path":"基于authelia的最佳实践.html","link":"","permalink":"https://blog.bosong.online/%E5%9F%BA%E4%BA%8Eauthelia%E7%9A%84%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5.html","excerpt":"前言作为一名工程师，在这个繁杂的网络世界中，想有自己的一片净土。自己有很多的网站，方便自己工作生活，但是苦于网络安全问题不敢轻易部署在公网中，所以发掘了这块一款SSO工具：authelia，他能很方便的在nginx层给你的网站加上独属于你的防火墙，账号密码，如果网站很多，并且没有自己独立的账号系统，那这款工具可以说非常适合你了。","text":"前言作为一名工程师，在这个繁杂的网络世界中，想有自己的一片净土。自己有很多的网站，方便自己工作生活，但是苦于网络安全问题不敢轻易部署在公网中，所以发掘了这块一款SSO工具：authelia，他能很方便的在nginx层给你的网站加上独属于你的防火墙，账号密码，如果网站很多，并且没有自己独立的账号系统，那这款工具可以说非常适合你了。 关于autheliaAuthelia是一个开源身份验证和授权服务器，可通过Web门户为您的应用程序提供2要素身份验证和单点登录（SSO）。它充当反向代理（如nginx，Traefik或HAProxy）的伴侣，以使他们知道查询是否应该通过。未经身份验证的用户将重定向到Authelia登录门户。目前主要可用功能 几种第二因素方法： 带有Yubikey的安全密钥（U2F）。 使用Google Authenticator的基于时间的一次性密码。 带有Duo的移动推送通知。 使用电子邮件确认通过身份验证重置密码。 仅单因素身份验证方法可用。 尝试过多身份验证后的访问限制。 每个子域，用户，资源和网络的细粒度访问控制。 支持受单一因素保护的端点的基本身份验证。 Beta对OpenID Connect的支持。 使用远程数据库具有很高的可用性，Redis可作为高可用性KV存储使用。 开箱即用与Kubernetesingress-nginx控制器兼容。 最佳实践-部署使用容器化部署Authelia是比较简单快捷的方法，可以直接拉取对应的镜像，编辑自定义配置文件即可完成部署，超简单的哦。 1、拉取authelia镜像：1docker pull authelia/authelia 如果存在国内拉取镜像过慢的方法，可以使用以下的命令拉取,是直接使用github actions拉取到国内来的 1docker pull registry.cn-shanghai.aliyuncs.com/bosong/autheli 2、编写docker compose文件docker-compose.yaml文件： 12345678910111213141516---version: &#x27;3.3&#x27;services: authelia: image: registry.cn-shanghai.aliyuncs.com/bosong/authelia container_name: authelia volumes: - /data-colum/authelia:/config healthcheck: disable: false environment: - TZ=Asia/Shanghai ports: - 9999:9091... 注意： /data-colum/authelia:/config 此处是直接使用docker部署的配置，需要提前将对应配置放入到对应的文件夹中 3、配置authelia具体的文件排列如下，以 文件夹为例： 1234├── /data-colum/authelia/│ ├── configuration.yml #配置文件│ └── users_database.yml #用户数据文件└── docker-compose.yaml configuration.yml模板文件如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172---################################################################ Authelia configuration #################################################################基本配置：配置端口、jwt秘钥、默认的跳转地址、totp对应的域名host: 0.0.0.0port: 9091log_level: debug# This secret can also be set using the env variables AUTHELIA_JWT_SECRET_FILEjwt_secret: adakusdhhadskdefault_redirection_url: https://www.abcd.comtotp: issuer: abcd.com# duo_api:# hostname: api-123456789.example.com# integration_key: ABCDEF# # This secret can also be set using the env variables AUTHELIA_DUO_API_SECRET_KEY_FILE# secret_key: 1234567890abcdefghifjkl#用户文件配置：目前Authelia只支持ldap和使用文件形式的用户列表authentication_backend: file: path: /config/users_database.ymlaccess_control: default_policy: one_factor rules: # Rules applied to everyone - domain: abcd.abcd.com policy: one_factor#seesion 配置session: name: authelia # This secret can also be set using the env variables AUTHELIA_SESSION_SECRET_FILE secret: asdasfjjhas expiration: 3600 # 1 hour inactivity: 300 # 5 minutes domain: abcd.com # Should match whatever your root protected domain is redis: host: redis.xxxx.com port: 6379 password: abcdhasd database_index: 5 maximum_active_connections: 100 minimum_idle_connections: 0regulation: max_retries: 3 find_time: 120 ban_time: 300#存储配置storage: mysql: host: mysql.abcd.com port: 3306 database: authelia username: authelia ## Password can also be set using a secret: https://www.authelia.com/docs/configuration/secrets.html password: 123456#邮件发件配置，主要用于修改密码等操作notifier: smtp: username: noreply@abcd.com # This secret can also be set using the env variables AUTHELIA_NOTIFIER_SMTP_PASSWORD_FILE password: abcdaklfdj host: smtp.exmail.qq.com port: 465 sender: noreply@abcd.com... 用户文件模板文件如下： 12345678users: authelia: password: $argon2id$v=19$m=65536,t=1,p=8$RUFuRGFEY291UGdaU0Jxqwqe$zqTCjJKc2Ka0MDA3OMQ8rX6HAMyLOppFQl1HPmN8mMI displayname: Authelia email: abcd@abcd.com groups: - admins - dev 注意： default_redirection_url 是直接在auth.abcd.com登录后默认跳转的地址 存储数据库可支持 mysql、sqlite等，结合官方文档来看即可 邮件发送配置如果使用即配置，不使用不配置。 如果需要修改对应的密码，使用docker exec -it 容器名 sh 后执行 authelia hash-password 123456 即可修改密码再进行填充 对应的jwt_secret、session.secret 一定记得更换 4、部署启动authelia在3中已经给出了对应的文件层级，直接根据使用docker-compose执行执行对应命令即可启动 1docker-comose -f docker-compose.yaml up -d 5、按照文档编写对应nginx的配置文件，以nginx为例，需要编写三个文件：12345├── /authelia/│ ├── authelia.conf authelia文件| ├── auth.conf auth文件│ └── proxy.conf 代理文件└── nginx.conf authelia.conf文件内容如下： 123456789101112131415161718192021222324252627282930313233343536373839set $upstream_authelia http://127.0.0.1:9999/api/verify;# Virtual endpoint created by nginx to forward auth requests.location /authelia &#123; internal; proxy_pass_request_body off; proxy_pass $upstream_authelia; proxy_set_header Content-Length &quot;&quot;; # Timeout if the real server is dead proxy_next_upstream error timeout invalid_header http_500 http_502 http_503; # [REQUIRED] Needed by Authelia to check authorizations of the resource. # Provide either X-Original-URL and X-Forwarded-Proto or # X-Forwarded-Proto, X-Forwarded-Host and X-Forwarded-Uri or both. # Those headers will be used by Authelia to deduce the target url of the user. # Basic Proxy Config client_body_buffer_size 128k; proxy_set_header Host $host; proxy_set_header X-Original-URL $scheme://$http_host$request_uri; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-Method $request_method; proxy_set_header X-Forwarded-Proto $scheme; proxy_set_header X-Forwarded-Host $http_host; proxy_set_header X-Forwarded-Uri $request_uri; proxy_set_header X-Forwarded-For $remote_addr; proxy_set_header X-Forwarded-Ssl on; proxy_redirect http:// $scheme://; proxy_http_version 1.1; proxy_set_header Connection &quot;&quot;; proxy_cache_bypass $cookie_session; proxy_no_cache $cookie_session; proxy_buffers 4 32k; # Advanced Proxy Config send_timeout 5m; proxy_read_timeout 240; proxy_send_timeout 240; proxy_connect_timeout 240;&#125; auth.conf文件内容如下： 1234567891011121314151617181920212223# Basic Authelia Config# Send a subsequent request to Authelia to verify if the user is authenticated# and has the right permissions to access the resource.auth_request /authelia;# Set the `target_url` variable based on the request. It will be used to build the portal# URL with the correct redirection parameter.auth_request_set $target_url $scheme://$http_host$request_uri;# Set the X-Forwarded-User and X-Forwarded-Groups with the headers# returned by Authelia for the backends which can consume them.# This is not safe, as the backend must make sure that they come from the# proxy. In the future, it&#x27;s gonna be safe to just use OAuth.auth_request_set $user $upstream_http_remote_user;auth_request_set $groups $upstream_http_remote_groups;auth_request_set $name $upstream_http_remote_name;auth_request_set $email $upstream_http_remote_email;proxy_set_header Remote-User $user;proxy_set_header Remote-Groups $groups;proxy_set_header Remote-Name $name;proxy_set_header Remote-Email $email;# If Authelia returns 401, then nginx redirects the user to the login portal.# If it returns 200, then the request pass through to the backend.# For other type of errors, nginx will handle them as usual.error_page 401 =302 https://auth.alidaodao.com/?rd=$target_url; **proxy.conf **文件内容如下： 1234567891011121314151617181920212223242526272829303132client_body_buffer_size 128k;#Timeout if the real server is deadproxy_next_upstream error timeout invalid_header http_500 http_502 http_503;# Advanced Proxy Configsend_timeout 5m;proxy_read_timeout 360;proxy_send_timeout 360;proxy_connect_timeout 360;# Basic Proxy Configproxy_set_header Host $host;proxy_set_header X-Real-IP $remote_addr;proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;proxy_set_header X-Forwarded-Proto $scheme;proxy_set_header X-Forwarded-Host $http_host;proxy_set_header X-Forwarded-Uri $request_uri;proxy_set_header X-Forwarded-Ssl on;proxy_redirect http:// $scheme://;#proxy_http_version 1.1;proxy_set_header Connection &quot;&quot;;proxy_cache_bypass $cookie_session;proxy_no_cache $cookie_session;proxy_buffers 64 256k;# If behind reverse proxy, forwards the correct IP#set_real_ip_from 10.0.0.0/8;#set_real_ip_from 172.16.0.0/12;#set_real_ip_from 192.168.0.0/16;#set_real_ip_from fc00::/7;#real_ip_header X-Forwarded-For;#real_ip_recursive on; 注意： auth.conf、proxy.conf 文件不需要进行改动，直接保存放入文件夹中即可 authelia.conf upstream_authelia 如果authelia使用的是远程的服务，则修改为对应远程地址即可，其他的不用改动 6、使用nginx配置auth.abcd.com 域名文件配置阶段结束了，可以进行实际的应用，除了配置auth的服务域名之外，另外配置一个demo域名来验证auth的sso服务是否可用。 12345678910111213141516171819202122232425upstream authelia &#123; server localhost:9999;&#125;server &#123; listen 80; server_name auth.abcd.com; return 301 https://$server_name$request_uri; &#125;server &#123; listen 443 ssl; server_name auth.abcd.com; charset utf-8; ssl_certificate cert/authelia.pem; ssl_certificate_key cert/authelia.key; ssl_session_timeout 5m; ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:ECDHE:ECDH:AES:HIGH:!NULL:!aNULL:!MD5:!ADH:!RC4; ssl_protocols TLSv1 TLSv1.1 TLSv1.2; ssl_prefer_server_ciphers on; access_log logs/authelia_access.log main; location / &#123; proxy_pass http://authelia; include /data/nginx/authelia/proxy.conf; &#125;&#125; 使用以上配置来使auth域名对应的服务生效，可以访问auth.abcd.com来验证服务是否正常对外提供服务。 7、配置demo.abcd.com域名给demo.abcd.com域名配置上SSO服务，在访问demo.abcd.com时，如果未进行登录则会跳转到auth.abcd.com进行登录，登录成功后会重定向回demo.abcd.com，配置文件如下： 1234567891011121314151617181920212223242526272829upstream demo &#123; server localhost:8880;&#125;server &#123; listen 80; server_name demo.abcd.com; return 301 https://$server_name$request_uri; &#125;server &#123; listen 443 ssl; server_name demo.abcd.com; charset utf-8; #ssl on; ssl_certificate cert/demo.pem; ssl_certificate_key cert/demo.key; ssl_session_timeout 5m; ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:ECDHE:ECDH:AES:HIGH:!NULL:!aNULL:!MD5:!ADH:!RC4; ssl_protocols TLSv1 TLSv1.1 TLSv1.2; ssl_prefer_server_ciphers on; access_log logs/demo_access.log main; #将authelia.conf配置在此处 include /data/nginx/authelia/authelia.conf; location / &#123; proxy_pass http://demo; #配置auth和代理 include /data/nginx/authelia/auth.conf; include /data/nginx/authelia/proxy.conf; &#125;&#125; 使用以上配置即可成功让demo.abcd.com网站接入sso服务，来保障demo.abcd.com对应的服务不被匿名访问到 总结没有十全十美的工具，只看怎么使用，在使用authelia的过程中也发现了很多的不足： 非ldap模式下配置用户比较麻烦，修改完文件后还需要进行重启 如果出现如下警告: nginx: [warn] could not build optimal proxy_headers_hash, you should increase either proxy_headers_hash_max_size: 512 or proxy_headers_hash_bucket_size: 64; ignoring proxy_headers_hash_bucket_size 在nginx.conf 配置文件中加上 以下配置即可。 12proxy_headers_hash_max_size 51200;proxy_headers_hash_bucket_size 6400; 这篇文章是自己根据实际经验编写的，如果有错漏之处可以参考官方文档","raw":null,"content":null,"categories":[{"name":"SSO","slug":"SSO","permalink":"https://blog.bosong.online/categories/SSO/"}],"tags":[{"name":"LINUX","slug":"LINUX","permalink":"https://blog.bosong.online/tags/LINUX/"},{"name":"SSO","slug":"SSO","permalink":"https://blog.bosong.online/tags/SSO/"}]},{"title":"scp日常使用记录","slug":"scp日常使用记录","date":"2021-05-06T09:48:16.000Z","updated":"2022-06-02T01:05:59.616Z","comments":true,"path":"scp日常使用记录.html","link":"","permalink":"https://blog.bosong.online/scp%E6%97%A5%E5%B8%B8%E4%BD%BF%E7%94%A8%E8%AE%B0%E5%BD%95.html","excerpt":"scp 在平常会比较常用，所以记录一下对应的基本使用方法。","text":"scp 在平常会比较常用，所以记录一下对应的基本使用方法。 scp 命令介绍scp 是使用ssh协议的sftp文件上传方式，可以将文件、文件夹在服务器和本地机器之间互传，在没有图形化客户端的条件还是比较好用的 常见使用方法从服务器下载文件或者文件夹到本地123456#下载文件scp -P 30010 &lt;username&gt;@&lt;hostname&gt;:/data/ToolsetIdeaPlugin-1.0.0.zip .#下载文件夹scp -P 30010 -r &lt;username&gt;@&lt;hostname&gt;:/data . 注意： -r 代表下载递归文件夹，如果非文件夹可去掉 -P 大写的P代表对应host的端口，为了安全考虑，我们一般不会使用22作为ssh的端口 命令最后有一个 . 表示当前目录的意思。 从服务器下载多个文件到本地12# 下载多个文件到当前文件夹scp -P 30010 &lt;username&gt;@&lt;hostname&gt;:/data/\\&#123;a.md, b.md, c.md\\&#125; . 注意： -P 大写的P代表对应host的端口，为了安全考虑，我们一般不会使用22作为ssh的端口 下载服务器上的多个文件，需要放入到 &#123;&#125; 中，用,分割，并且 &#123;&#125; 需要用\\进行转义。 从本地上传文件或者文件夹到服务器12345#上传ToolsetIdeaPlugin-1.0.0.zip到服务器上scp -P 30010 ToolsetIdeaPlugin-1.0.0.zip &lt;username&gt;@&lt;hostname&gt;:/data#上传data文件夹到服务器上scp -P 30010 -r data &lt;username&gt;@&lt;hostname&gt;:/data 注意： -r 代表上传递归文件夹，如果非文件夹可去掉 -P 大写的P代表对应host的端口，为了安全考虑，我们一般不会使用22作为ssh的端口 从本地上传多个文件到服务器1scp -P 30010 a.md b.md c.md &lt;username&gt;@&lt;hostname&gt;:/data 注意： -P 大写的P代表对应host的端口，为了安全考虑，我们一般不会使用22作为ssh的端口 多个文件上传直接使用空格隔开即可 注意事项 -P 大写的P代表对应host的端口，为了安全考虑，我们一般不会使用22作为ssh的端口 &lt;username&gt;@&lt;hostname&gt; 可以直接使用 ~/.ssh/config 中配置的服务器别名来替代,例如： 12#ce-001 代表root@101.0.1.1 服务器scp -P 30010 ToolsetIdeaPlugin-1.0.0.zip ce-001:/data","raw":null,"content":null,"categories":[{"name":"Linux","slug":"Linux","permalink":"https://blog.bosong.online/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://blog.bosong.online/tags/Linux/"},{"name":"SCP","slug":"SCP","permalink":"https://blog.bosong.online/tags/SCP/"}]},{"title":"Linux安装mongodb","slug":"Linux安装mongodb","date":"2021-04-28T07:40:17.000Z","updated":"2022-06-02T01:05:59.613Z","comments":true,"path":"Linux安装mongodb.html","link":"","permalink":"https://blog.bosong.online/Linux%E5%AE%89%E8%A3%85mongodb.html","excerpt":"","text":"前言因为需要部署蚂蚁笔记，就想着将数据库放在云上，后来发现基本上所有的云厂商对Mongodb收费都比较高昂，所以就选择了便宜的方案，在公有云服务器上自建mongodb服务。mongodb服务构建主要是使用的docker，数据挂载在磁盘固定的位置，并且定时进行同步 步骤 使用docker最新版的mongodb镜像 1docker pull mongo 给mongodb创建对应的本地数据存储空间以及数据备份空间 12mkdir -p /data/mongo-datamkdir -p /data/mongo-backup 写docker容器创建命令 1234#创建mongo容器并且指定对外Port为20011 挂载数据内容以及备份内容，`--auth` 开启mongo认证，不建议在公网环境暴露docker run -d -p 20011:27017 --name mongo -v /data/mongo-data:/data/db -v /data/mongo-backup:/data/backup mongo --auth 启动mongo后创建对应账号 123456docker exec -it mongo /bin/bashmongouse admindb.createUser(&#123;user:&quot;root&quot;,pwd:&quot;password&quot;,roles:[&#123;role:&#x27;root&#x27;,db:&#x27;admin&#x27;&#125;]&#125;)exit 定时进行数据备份 123#备份脚本docker exec mongo sh -c &#x27;exec var=`date +%Y%m%d%H%M` &amp;&amp; mongodump -h localhost --port 27017 -u root -p password -d dbname -o /data/backup/$var_db.dat&#x27; 结语使用docker部署mongo比较简单，需要注意的就是需要在启动时添加--auth开启认证，否则mongo就是在公网环境中暴露，很容易被攻击，备份恢复需要关注对应的mongodb版本是否兼容","raw":null,"content":null,"categories":[{"name":"Linux","slug":"Linux","permalink":"https://blog.bosong.online/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://blog.bosong.online/tags/Linux/"},{"name":"Docker","slug":"Docker","permalink":"https://blog.bosong.online/tags/Docker/"},{"name":"mongodb","slug":"mongodb","permalink":"https://blog.bosong.online/tags/mongodb/"}]},{"title":"Git常用命令","slug":"Git常用命令","date":"2021-04-09T10:19:18.000Z","updated":"2022-06-02T01:05:59.612Z","comments":true,"path":"Git常用命令.html","link":"","permalink":"https://blog.bosong.online/Git%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4.html","excerpt":"仓库12345678# 在当前目录新建一个Git代码库$ git init# 新建一个目录，将其初始化为Git代码库$ git init [project-name]# 下载一个项目和它的整个代码历史$ git clone [url]","text":"仓库12345678# 在当前目录新建一个Git代码库$ git init# 新建一个目录，将其初始化为Git代码库$ git init [project-name]# 下载一个项目和它的整个代码历史$ git clone [url] 配置123456789# 显示当前的Git配置$ git config --list# 编辑Git配置文件$ git config -e [--global]# 设置提交代码时的用户信息$ git config [--global] user.name &quot;[name]&quot;$ git config [--global] user.email &quot;[email address]&quot; 增加、删除文件123456789101112131415161718192021# 添加指定文件到暂存区$ git add [file1] [file2] ...# 添加指定目录到暂存区，包括子目录$ git add [dir]# 添加当前目录的所有文件到暂存区$ git add .# 添加每个变化前，都会要求确认# 对于同一个文件的多处变化，可以实现分次提交$ git add -p# 删除工作区文件，并且将这次删除放入暂存区$ git rm [file1] [file2] ...# 停止追踪指定文件，但该文件会保留在工作区$ git rm --cached [file]# 改名文件，并且将这个改名放入暂存区$ git mv [file-original] [file-renamed] 代码提交123456789101112131415161718# 提交暂存区到仓库区$ git commit -m [message]# 提交暂存区的指定文件到仓库区$ git commit [file1] [file2] ... -m [message]# 提交工作区自上次commit之后的变化，直接到仓库区$ git commit -a# 提交时显示所有diff信息$ git commit -v# 使用一次新的commit，替代上一次提交# 如果代码没有任何新变化，则用来改写上一次commit的提交信息$ git commit --amend -m [message]# 重做上一次commit，并包括指定文件的新变化$ git commit --amend [file1] [file2] ... 分支123456789101112131415161718192021222324252627282930313233343536373839404142# 列出所有本地分支$ git branch# 列出所有远程分支$ git branch -r# 列出所有本地分支和远程分支$ git branch -a# 新建一个分支，但依然停留在当前分支$ git branch [branch-name]# 新建一个分支，并切换到该分支$ git checkout -b [branch]# 新建一个分支，指向指定commit$ git branch [branch] [commit]# 新建一个分支，与指定的远程分支建立追踪关系$ git branch --track [branch] [remote-branch]# 切换到指定分支，并更新工作区$ git checkout [branch-name]# 切换到上一个分支$ git checkout -# 建立追踪关系，在现有分支与指定的远程分支之间$ git branch --set-upstream [branch] [remote-branch]# 合并指定分支到当前分支$ git merge [branch]# 选择一个commit，合并进当前分支$ git cherry-pick [commit]# 删除分支$ git branch -d [branch-name]# 删除远程分支$ git push origin --delete [branch-name]$ git branch -dr [remote/branch] 标签1234567891011121314151617181920212223242526# 列出所有tag$ git tag# 新建一个tag在当前commit$ git tag [tag]# 新建一个tag在指定commit$ git tag [tag] [commit]# 删除本地tag$ git tag -d [tag]# 删除远程tag$ git push origin :refs/tags/[tagName]# 查看tag信息$ git show [tag]# 提交指定tag$ git push [remote] [tag]# 提交所有tag$ git push [remote] --tags# 新建一个分支，指向某个tag$ git checkout -b [branch] [tag] 查看信息123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960# 显示有变更的文件$ git status# 显示当前分支的版本历史$ git log# 显示commit历史，以及每次commit发生变更的文件$ git log --stat# 搜索提交历史，根据关键词$ git log -S [keyword]# 显示某个commit之后的所有变动，每个commit占据一行$ git log [tag] HEAD --pretty=format:%s# 显示某个commit之后的所有变动，其&quot;提交说明&quot;必须符合搜索条件$ git log [tag] HEAD --grep feature# 显示某个文件的版本历史，包括文件改名$ git log --follow [file]$ git whatchanged [file]# 显示指定文件相关的每一次diff$ git log -p [file]# 显示过去5次提交$ git log -5 --pretty --oneline# 显示所有提交过的用户，按提交次数排序$ git shortlog -sn# 显示指定文件是什么人在什么时间修改过$ git blame [file]# 显示暂存区和工作区的差异$ git diff# 显示暂存区和上一个commit的差异$ git diff --cached [file]# 显示工作区与当前分支最新commit之间的差异$ git diff HEAD# 显示两次提交之间的差异$ git diff [first-branch]...[second-branch]# 显示今天你写了多少行代码$ git diff --shortstat &quot;@&#123;0 day ago&#125;&quot;# 显示某次提交的元数据和内容变化$ git show [commit]# 显示某次提交发生变化的文件$ git show --name-only [commit]# 显示某次提交时，某个文件的内容$ git show [commit]:[filename]# 显示当前分支的最近几次提交$ git reflog 远程同步1234567891011121314151617181920212223# 下载远程仓库的所有变动$ git fetch [remote]# 显示所有远程仓库$ git remote -v# 显示某个远程仓库的信息$ git remote show [remote]# 增加一个新的远程仓库，并命名$ git remote add [shortname] [url]# 取回远程仓库的变化，并与本地分支合并$ git pull [remote] [branch]# 上传本地指定分支到远程仓库$ git push [remote] [branch]# 强行推送当前分支到远程仓库，即使有冲突$ git push [remote] --force# 推送所有分支到远程仓库$ git push [remote] --all 撤销12345678910111213141516171819202122232425262728293031# 恢复暂存区的指定文件到工作区$ git checkout [file]# 恢复某个commit的指定文件到暂存区和工作区$ git checkout [commit] [file]# 恢复暂存区的所有文件到工作区$ git checkout .# 重置暂存区的指定文件，与上一次commit保持一致，但工作区不变$ git reset [file]# 重置暂存区与工作区，与上一次commit保持一致$ git reset --hard# 重置当前分支的指针为指定commit，同时重置暂存区，但工作区不变$ git reset [commit]# 重置当前分支的HEAD为指定commit，同时重置暂存区和工作区，与指定commit一致$ git reset --hard [commit]# 重置当前HEAD为指定commit，但保持暂存区和工作区不变$ git reset --keep [commit]# 新建一个commit，用来撤销指定commit# 后者的所有变化都将被前者抵消，并且应用到当前分支$ git revert [commit]暂时将未提交的变化移除，稍后再移入$ git stash$ git stash pop 特殊12# 生成一个可供发布的压缩包$ git archive","raw":null,"content":null,"categories":[{"name":"git","slug":"git","permalink":"https://blog.bosong.online/categories/git/"}],"tags":[{"name":"git","slug":"git","permalink":"https://blog.bosong.online/tags/git/"}]},{"title":"ubuntu配置clash","slug":"ubuntu配置clash","date":"2021-03-25T12:47:45.000Z","updated":"2022-06-02T01:05:59.616Z","comments":true,"path":"ubuntu配置clash.html","link":"","permalink":"https://blog.bosong.online/ubuntu%E9%85%8D%E7%BD%AEclash.html","excerpt":"前言作为一名软件开发攻城狮，日常佛跳墙是有必要的。近期讲win电脑上安装了utuntu系统准备作为开发的主力系统。本次记录一下如何在ubuntu （20.04）安装 clash作为访问google.com的工具。","text":"前言作为一名软件开发攻城狮，日常佛跳墙是有必要的。近期讲win电脑上安装了utuntu系统准备作为开发的主力系统。本次记录一下如何在ubuntu （20.04）安装 clash作为访问google.com的工具。 下载clash访问到 clash的Github地址，发现访问比较慢，别急，有方法： 访问IP地址查询 然后获取到最近的访问github的IP 执行命令sudo vi /etc/hosts 写入2.74.223.119 github.comhost 再次访问github发现速度飙升，然后下载对应系统的包 启动clash 运行sudo gzip -d clash.gz 解压对应文件夹 运行sudo cp clash的解压后的地址 /usr/local/bin/clash 复制可执行文件到bin中 执行clash 生成默认的配置文件 执行cd /home/用户名/.config/clash可以看到对应的配置文件config.yaml 将你自己的配置文件修改为config.yaml 然后再次执行clash 就可以正常的使用路由规则了，如果需要后台运行执行nohup clash &amp; 2&gt;1 即可 clash配置代理执行vi /home/用户名/.config/clash/config.yaml 可以看到代理的端口，如果需要修改可以自行修改 然后配置对应的系统代理，点击设置进入网络然后选择代理手动设置即可，如下图：最后使用浏览器访问本地配置的clash的web 进行配置 结语此处的clash是作为服务启动的，为了方便每次进入系统后自动启动代理，可以将其配置成开机启动，具体的可以google一下。","raw":null,"content":null,"categories":[{"name":"ubuntu","slug":"ubuntu","permalink":"https://blog.bosong.online/categories/ubuntu/"}],"tags":[{"name":"ubuntu","slug":"ubuntu","permalink":"https://blog.bosong.online/tags/ubuntu/"}]},{"title":"ClickHouse常用函数","slug":"ClickHouse常用函数","date":"2021-03-18T12:47:45.000Z","updated":"2022-06-02T01:05:59.611Z","comments":true,"path":"ClickHouse常用函数.html","link":"","permalink":"https://blog.bosong.online/ClickHouse%E5%B8%B8%E7%94%A8%E5%87%BD%E6%95%B0.html","excerpt":"前言近期项目引入了Clickhouse进行数据计算与展示，今天突然我们的PM同学来问我一个问题，怎么快速获取这十个品牌中GMV各自排名前三的SPU数据。当时想了想，一般情况下这种需求都是使用代码实现的，简直So easy，但是一旦写代码的话就没法快速获取并且以后类似的需求也没法快速响应了。\n然后想到了咱们使用的是Clickhouse数据库，它自带很多函数，在经过一段时间的查询以后，发现有一个函数还是比较好用的，正好解决这种典型的分组取TOP的问题，这个函数就是groupArray(x)，可以查看以下sql，看它是怎么使用的：\n12345678910111213select * from  (select b.bid,b.brand as brand, c[1] as top1,c[2] as top2,c[3] as top3,groupArray(3)(b.spu_name) as c,groupArray(10)(b.gmv) as d,d[1]+d[2]+d[3]+d[4]+d[5]+d[6]+d[7]+d[8]+d[9]+d[10] as gmvsum  from (        select spu_id,spu_name,gmv,us,brand,bid    from spu        where platform_id = 2    and c2_id = 3305    and bid in (1234, 5678, 1903, 41313, 3145, 555, 111, 444, 222, 444)          and multiSearchAny(spu_name, [&#x27;精酿啤酒&#x27;,&#x27;啤酒精酿&#x27;])          and not multiSearchAny(spu_name, [&#x27;饮料&#x27;])          and effective_date between &#x27;2020-09-30&#x27; and &#x27;2021-02-28&#x27;    order by gmv desc)      b group by b.bid,b.brand order by bid) c order by c.gmvsum desc;\n\nClickhouse的简单介绍ClickHouse是一个用于联机分析(OLAP)的列式数据库管理系统(DBMS)；\nMysql等数据库是将数据以行的形式来进行存储，它是标准的行式数据库，但是在列式数据库中数据以列的形式来进行存储;以列的形式来存储数据，它还是有不少优点的，主要是：\n\n绝大多数是读请求\n数据以相当大的批次(&gt; 1000行)更新，而不是单行更新;或者根本没有更新。\n已添加到数据库的数据不能修改。\n对于读取，从数据库中提取相当多的行，但只提取列的一小部分。\n宽表，即每个表包含着大量的列\n查询相对较少(通常每台服务器每秒查询数百次或更少)\n对于简单查询，允许延迟大约50毫秒\n列中的数据相对较小：数字和短字符串(例如，每个URL 60个字节)\n处理单个查询时需要高吞吐量(每台服务器每秒可达数十亿行)\n事务不是必须的\n对数据一致性要求低\n每个查询有一个大表。除了他以外，其他的都很小。\n查询结果明显小于源数据。换句话说，数据经过过滤或聚合，因此结果适合于单个服务器的RAM中\n\n可以根据官方文档来看一下OLAP的列式数据库查询为什么比行式数据库查询效率要高：行式数据库\n\n列式数据库\n\n一般情况下，在数据计算时只需要抽取其中一部分列，所以使用列式数据库相比较来说会快速的查找到需要的列，相比行式数据库来说减少了大量的IO。当然还有一些其他方面的优势，可以参考官方的文档。\n","text":"前言近期项目引入了Clickhouse进行数据计算与展示，今天突然我们的PM同学来问我一个问题，怎么快速获取这十个品牌中GMV各自排名前三的SPU数据。当时想了想，一般情况下这种需求都是使用代码实现的，简直So easy，但是一旦写代码的话就没法快速获取并且以后类似的需求也没法快速响应了。 然后想到了咱们使用的是Clickhouse数据库，它自带很多函数，在经过一段时间的查询以后，发现有一个函数还是比较好用的，正好解决这种典型的分组取TOP的问题，这个函数就是groupArray(x)，可以查看以下sql，看它是怎么使用的： 12345678910111213select * from (select b.bid,b.brand as brand, c[1] as top1,c[2] as top2,c[3] as top3,groupArray(3)(b.spu_name) as c,groupArray(10)(b.gmv) as d,d[1]+d[2]+d[3]+d[4]+d[5]+d[6]+d[7]+d[8]+d[9]+d[10] as gmvsum from ( select spu_id,spu_name,gmv,us,brand,bid from spu where platform_id = 2 and c2_id = 3305 and bid in (1234, 5678, 1903, 41313, 3145, 555, 111, 444, 222, 444) and multiSearchAny(spu_name, [&#x27;精酿啤酒&#x27;,&#x27;啤酒精酿&#x27;]) and not multiSearchAny(spu_name, [&#x27;饮料&#x27;]) and effective_date between &#x27;2020-09-30&#x27; and &#x27;2021-02-28&#x27; order by gmv desc) b group by b.bid,b.brand order by bid) c order by c.gmvsum desc; Clickhouse的简单介绍ClickHouse是一个用于联机分析(OLAP)的列式数据库管理系统(DBMS)； Mysql等数据库是将数据以行的形式来进行存储，它是标准的行式数据库，但是在列式数据库中数据以列的形式来进行存储;以列的形式来存储数据，它还是有不少优点的，主要是： 绝大多数是读请求 数据以相当大的批次(&gt; 1000行)更新，而不是单行更新;或者根本没有更新。 已添加到数据库的数据不能修改。 对于读取，从数据库中提取相当多的行，但只提取列的一小部分。 宽表，即每个表包含着大量的列 查询相对较少(通常每台服务器每秒查询数百次或更少) 对于简单查询，允许延迟大约50毫秒 列中的数据相对较小：数字和短字符串(例如，每个URL 60个字节) 处理单个查询时需要高吞吐量(每台服务器每秒可达数十亿行) 事务不是必须的 对数据一致性要求低 每个查询有一个大表。除了他以外，其他的都很小。 查询结果明显小于源数据。换句话说，数据经过过滤或聚合，因此结果适合于单个服务器的RAM中 可以根据官方文档来看一下OLAP的列式数据库查询为什么比行式数据库查询效率要高：行式数据库 列式数据库 一般情况下，在数据计算时只需要抽取其中一部分列，所以使用列式数据库相比较来说会快速的查找到需要的列，相比行式数据库来说减少了大量的IO。当然还有一些其他方面的优势，可以参考官方的文档。 Clickhouse函数指南123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498499500501502503504505506507508509510511512513514515516517518519520521522523524525526527528529530531532533534535536537538539540541542543544545546547548549550551552553554555556557558559560561562563564565566567568569570571572573574575576577578579580581582583584585586587588589590591592593594595596597598599600601602603604605606607608609610611612613614615616617618619620621622623624625626627628629630631632633634635636637638639640641642643644645646647648649650651652653654655656657658659660661662663664665666667668669670671672673674675676677678679680681682683684685686687688689690691692693694695696697698699700701702703704705706707708709710711712713714715716717718719720721722723724725726727728729730731732733734735736737738739740741742743744745746747748749750751752753754755756757758759760761762763764765766767768769770771772773774775776777778779780781782783784785786787788789790791792793794795796797798799800801802803804805806807808809810811812813814815816817818819820821822823824825826827828829830831832833834835836837838839840841842843844845846847848849850851852853854855856857858859860861862863864865866867868869870871872873874875876877878879880881882883884885886887888889890891892893894895896897898899900901902903904905906907908909910911912913914915916917918919920921922923924925926927928929930931932933934935936937938939940941942943944945946947948949950951952953954955956957958959960961962963964965966967968969970971972973974975976977978979980981982983984-- 零、检测函数类型（clickhouse中数据的类型）SELECT toTypeName(0);-- UInt8(三位数为8)SELECT toTypeName(-0);-- Int8SELECT toTypeName(-343);-- Int16SELECT toTypeName(12.43); -- Float64(默认浮点型的数据为64)，所以一般在处理浮点型的数据的时候尽量转成toFloat32(12.43)SELECT toTypeName(12.34343); -- Float64SELECT toTypeName(toDateTime(1502396027)); -- DateTime-- 一、算数函数--&gt;&gt;&gt;&gt;&gt;&gt; 算数函数(数学上的计算)--求和SELECT plus(12, 21), plus(10, -10), plus(-10, -10);--差值SELECT minus(10, 5), minus(10, -10),minus(-10, -10);--积SELECT multiply(12, 2), multiply(12, -2), multiply(-12, -2);--平均值SELECT divide(12, 4), divide(10, 3), divide(2, 4), divide(-4, -2), divide(-4, 2), divide(-4.5, 3);SELECT intDiv(10, 3), divide(10, 3); -- 3, 3.333(保留四位有效数字)SELECT divide(10, 0), divide(-10, 0); -- 出现无穷大字符“ ∞ ”或“ -∞ ”SELECT divide(0, 0); -- 特殊字符（类似乱码）SELECT intDivOrZero(10, 0); -- 0--求余数SELECT modulo(10, 3); --1SELECT modulo(10.5, 3); --1--取反SELECT negate(10), negate(-10); -- -10 10--绝对值SELECT abs(-10), abs(10);--最大公约数SELECT gcd(12, 24), gcd(-12, -24), gcd(-12, 24);--最小公倍数SELECT lcm(12, 24), lcm(-12, -24), lcm(-3, 4);-- 二、比较函数--&gt;&gt;&gt;&gt;&gt;&gt; 比较函数(始终返回0表示false 或 1表示true)SELECT 12 == 12, 12 != 10, 12 == 132, 12 != 12, 12 &lt;&gt; 12;SELECT equals(12, 12), notEquals(12, 10), equals(12, 10), notEquals(12,123);SELECT greater(12, 10), greater(10, 12), greater(12, 12);-- 前者是否大于后者SELECT greaterOrEquals(12,10), greaterOrEquals(12,12);-- 前者是否大于或等于后者SELECT less(12, 21), less(12, 10), less(120, 120);-- 前者是否小于后者SELECT lessOrEquals(12, 120), lessOrEquals(12, 12);-- 前世是否小于或等于或者-- 三、逻辑函数--&gt;&gt;&gt;&gt;&gt;&gt; 逻辑操作符（返回0表示false 或 1表示true）SELECT 12==12 or 12!=10;SELECT 12==12 and 12!=10;SELECT not 12, not 0;SELECT or(equals(12, 12), notEquals(12, 10)); --函数表示法：或SELECT and(equals(12, 12), notEquals(12, 10));--函数表示法：且SELECT not(12), not(0);-- 四、类型转换函数--&gt;&gt;&gt;&gt;&gt;&gt; 类型转换函数部分示例：SELECT toInt8(12.3334343), toFloat32(10.001), toFloat64(1.000040);SELECT toString(now());SELECT now() AS now_local, toString(now(), &#x27;Asia/Yekaterinburg&#x27;) AS now_yekat;SELECT now() AS now_local, toDate(now()), toDateTime(now()), toUnixTimestamp(now());SELECT&#x27;2016-06-15 23:00:00&#x27; AS timestamp,CAST(timestamp AS DateTime) AS datetime,CAST(timestamp AS Date) AS date,CAST(timestamp, &#x27;String&#x27;) AS string,CAST(timestamp, &#x27;FixedString(22)&#x27;) AS fixed_string;WITH toDate(&#x27;2019-01-01&#x27;) AS date, INTERVAL 1 WEEK AS interval_week, toIntervalWeek(1) AS interval_to_week, toIntervalMonth(1) AS interval_to_monthSELECT date + interval_week, date + interval_to_week, date + interval_to_month;WITH toDateTime(&#x27;2019-01-01 12:10:10&#x27;) as datetime, INTERVAL 1 HOUR AS interval_hour, toIntervalHour(1) as invterval_to_hourSELECT plus(datetime, interval_hour), plus(datetime, invterval_to_hour);-- 五、时间日期函数---&gt;&gt;&gt;&gt;&gt;&gt; 时间日期函数SELECT toDateTime(&#x27;2019-07-30 10:10:10&#x27;) AS time, -- 将DateTime转换成Unix时间戳 toUnixTimestamp(time) as unixTimestamp, -- 保留 时-分-秒 toDate(time) as date_local, toTime(time) as date_time,-- 将DateTime中的日期转换为一个固定的日期，同时保留时间部分。 -- 获取年份，月份，季度，小时，分钟，秒钟 toYear(time) as get_year, toMonth(time) as get_month, -- 一年分为四个季度。1（一季度:1-3）,2（二季度:4-6）,3（三季度:7-9）,4（四季度:10-12） toQuarter(time) as get_quarter, toHour(time) as get_hour, toMinute(time) as get_minute, toSecond(time) as get_second, -- 获取 DateTime中的当前日期是当前年份的第几天，当前月份的第几日，当前星期的周几 toDayOfYear(time) as &quot;当前年份中的第几天&quot;, toDayOfMonth(time) as &quot;当前月份的第几天&quot;, toDayOfWeek(time) as &quot;星期&quot;, toDate(time, &#x27;Asia/Shanghai&#x27;) AS date_shanghai, toDateTime(time, &#x27;Asia/Shanghai&#x27;) AS time_shanghai, -- 得到当前年份的第一天,当前月份的第一天，当前季度的第一天，当前日期的开始时刻 toStartOfYear(time), toStartOfMonth(time), toStartOfQuarter(time), toStartOfDay(time) AS cur_start_daytime, toStartOfHour(time) as cur_start_hour, toStartOfMinute(time) AS cur_start_minute, -- 从过去的某个固定的时间开始，以此得到当前指定的日期的编号 toRelativeYearNum(time), toRelativeQuarterNum(time); SELECT toDateTime(&#x27;2019-07-30 14:27:30&#x27;) as time, toISOYear(time) AS iso_year, toISOWeek(time) AS iso_week, now() AS cur_dateTime1, -- 返回当前时间yyyy-MM-dd HH:mm:ss today() AS cur_dateTime2, -- 其功能与&#x27;toDate(now())&#x27;相同 yesterday() AS yesterday, -- 当前日期的上一天 -- timeSlot(1) AS timeSlot_1, -- 出现异常！！将时间向前取整半小时 toDate(time) as getY_M_d;-- 目前只有这三种格式，没有什么toYYYY(),toYYYddmm()之类的函数，不要想当然。SELECT now() as nowTime, -- 将Date或DateTime转换为包含年份和月份编号的UInt32类型的数字（YYYY * 100 + MM） toYYYYMMDDhhmmss(nowTime), toYYYYMMDD(nowTime), toYYYYMM(nowTime);-- formatDateTime(Time, Format[,Timezone])函数引用SELECT now() as now_time, toDateTime(&#x27;2019-07-31 18:20:30&#x27;) AS def_datetime, formatDateTime(now_time, &#x27;%D&#x27;) AS now_time_day_month_year,-- 07/30/19-- toDateTime(&#x27;2019-07-31 18:20:30&#x27;, &#x27;Asia/Shanghai&#x27;) AS def_datetime1, -- 指定时区 formatDateTime(def_datetime, &#x27;%Y&#x27;) AS def_datetime_year, -- 2019（指定日期为2019年） formatDateTime(def_datetime, &#x27;%y&#x27;) AS def_datetime_year_litter, -- 19（指定日期为19年,Year, last two digits (00-99),本世纪的第19年） formatDateTime(def_datetime, &#x27;%H&#x27;) AS hour24, -- 18 下午六点 formatDateTime(def_datetime, &#x27;%I&#x27;) AS hour12, -- 06下午六点 formatDateTime(def_datetime, &#x27;%p&#x27;) AS PMorAM, -- 指定时间是上午还是下午 formatDateTime(def_datetime, &#x27;%w&#x27;) AS def_datetime_get_curWeek,-- 3(指定日期为星期三) formatDateTime(def_datetime, &#x27;%F&#x27;) AS def_datetime_get_date,-- 2019-07-31 formatDateTime(def_datetime, &#x27;%T&#x27;) AS def_datetime_get_time,-- 18:20:30 formatDateTime(def_datetime, &#x27;%M&#x27;) AS def_datetime_get_minute,-- 20(得到指定事件的“分”，minute (00-59)) formatDateTime(def_datetime, &#x27;%S&#x27;) AS def_datetime_get_second;-- 30(得到指定事件的“秒”，second (00-59)) -- 1.跳转到之后的日期函数-- 第一种，日期格式（指定日期，需注意时区的问题）WITH toDate(&#x27;2019-09-09&#x27;) AS date, toDateTime(&#x27;2019-09-09 00:00:00&#x27;) AS date_timeSELECT addYears(date, 1) AS add_years_with_date, addYears(date_time, 0) AS add_years_with_date_time;-- 第二种，日期格式（当前，本地时间）WITH toDate(now()) as date, toDateTime(now()) as date_timeSELECT now() as now_time,-- 当前时间 addYears(date, 1) AS add_years_with_date,-- 之后1年 addYears(date_time, 1) AS add_years_with_date_time, addMonths(date, 1) AS add_months_with_date,-- 之后1月 addMonths(date_time, 1) AS add_months_with_date_time, addWeeks(date, 1) AS add_weeks_with_date,--之后1周 addWeeks(date_time, 1) AS add_weeks_with_date_time, addDays(date, 1) AS add_days_with_date,-- 之后1天 addDays(date_time, 1) AS add_days_with_date_time, addHours(date_time, 1) AS add_hours_with_date_time,--之后1小时 addMinutes(date_time, 1) AS add_minutes_with_date_time,--之后1分中 addSeconds(date_time, 10) AS add_seconds_with_date_time,-- 之后10秒钟 addQuarters(date, 1) AS add_quarters_with_date, -- 之后1个季度 addQuarters(date_time, 1) AS add_quarters_with_date_time; -- 2.跳转到当前日期之前的函数(函数将Date/DateTime减去一段时间间隔，然后返回Date/DateTime)WITH toDate(now()) as date, toDateTime(now()) as date_timeSELECT subtractYears(date, 1) AS subtract_years_with_date, subtractYears(date_time, 1) AS subtract_years_with_date_time, subtractQuarters(date, 1) AS subtract_Quarters_with_date, subtractQuarters(date_time, 1) AS subtract_Quarters_with_date_time, subtractMonths(date, 1) AS subtract_Months_with_date, subtractMonths(date_time, 1) AS subtract_Months_with_date_time, subtractWeeks(date, 1) AS subtract_Weeks_with_date, subtractWeeks(date_time, 1) AS subtract_Weeks_with_date_time, subtractDays(date, 1) AS subtract_Days_with_date, subtractDays(date_time, 1) AS subtract_Days_with_date_time, subtractHours(date_time, 1) AS subtract_Hours_with_date_time, subtractMinutes(date_time, 1) AS subtract_Minutes_with_date_time, subtractSeconds(date_time, 1) AS subtract_Seconds_with_date_time;SELECT toDate(&#x27;2019-07-31&#x27;, &#x27;Asia/GuangZhou&#x27;) as date_guangzhou;SELECT toDate(&#x27;2019-07-31&#x27;), toDate(&#x27;2019-07-31&#x27;, &#x27;Asia/Beijing&#x27;) as date_beijing;-- 亚洲只能加载上海的timezone？？？SELECT toDateTime(&#x27;2019-07-31 10:10:10&#x27;, &#x27;Asia/Shanghai&#x27;) as date_shanghai; -- 计算连个时刻在不同时间单位下的差值-- 第一种：指定时间计算差值示例WITH toDateTime(&#x27;2019-07-30 10:10:10&#x27;, &#x27;Asia/Shanghai&#x27;) as date_shanghai_one, toDateTime(&#x27;2020-10-31 11:20:30&#x27;, &#x27;Asia/Shanghai&#x27;) as date_shanghai_twoSELECT dateDiff(&#x27;year&#x27;, date_shanghai_one, date_shanghai_two) as diff_years, dateDiff(&#x27;month&#x27;, date_shanghai_one, date_shanghai_two) as diff_months, dateDiff(&#x27;week&#x27;, date_shanghai_one, date_shanghai_two) as diff_week, dateDiff(&#x27;day&#x27;, date_shanghai_one, date_shanghai_two) as diff_days, dateDiff(&#x27;hour&#x27;, date_shanghai_one, date_shanghai_two) as diff_hours, dateDiff(&#x27;minute&#x27;, date_shanghai_one, date_shanghai_two) as diff_minutes, dateDiff(&#x27;second&#x27;, date_shanghai_one, date_shanghai_two) as diff_seconds;-- 第二种：本地当前时间示例WITH now() as date_timeSELECT dateDiff(&#x27;year&#x27;, date_time, addYears(date_time, 1)) as diff_years, dateDiff(&#x27;month&#x27;, date_time, addMonths(date_time, 2)) as diff_months, dateDiff(&#x27;week&#x27;, date_time, addWeeks(date_time, 3)) as diff_week, dateDiff(&#x27;day&#x27;, date_time, addDays(date_time, 3)) as diff_days, dateDiff(&#x27;hour&#x27;, date_time, addHours(date_time, 3)) as diff_hours, dateDiff(&#x27;minute&#x27;, date_time, addMinutes(date_time, 30)) as diff_minutes, dateDiff(&#x27;second&#x27;, date_time, addSeconds(date_time, 35)) as diff_seconds; -- timeSlot(StartTime, Duration, [,Size])-- 它返回一个时间数组，其中包括从从“StartTime”开始到“StartTime + Duration 秒”内的所有符合“size”（以秒为单位）步长的时间点-- 作用:搜索在相应会话中综合浏览量是非常有用的。SELECT timeSlots(toDateTime(&#x27;2012-01-01 12:20:00&#x27;), toUInt32(600)) as dateTimeArray, dateTimeArray[0] as arr_index_0, -- no result. dateTimeArray[1] as arr_index_1, -- 2012-01-01 20:00:00 dateTimeArray[2] as arr_index_2, -- 2012-01-01 20:30:00 dateTimeArray[3] as arr_index_3, -- no result. dateTimeArray[4] as arr_index_4; -- no result.-- toUInt32(600) 表示之后间距20秒的时刻SELECT timeSlots(now(), toUInt32(600), 20) as dateTimeArray, -- 类似于：引用地址 dateTimeArray[0] as arr_index_0, -- no result.为什么？ dateTimeArray[1] as arr_index_1, dateTimeArray[2] as arr_index_2, dateTimeArray[3] as arr_index_3, dateTimeArray[4] as arr_index_4, dateTimeArray[5] as arr_index_5;-- 指定时间为基准，之后每个元素增加20秒SELECT timeSlots(toDateTime(&#x27;2012-01-01 12:20:00&#x27;), toUInt32(600), 20) as cur_dateTimeArray, -- 类似于：引用地址 cur_dateTimeArray[0] as arr_index_0, -- no result.为什么？ cur_dateTimeArray[1] as arr_index_1, -- 2012-01-01 20:20:00 cur_dateTimeArray[2] as arr_index_2, -- 2012-01-01 20:20:20 cur_dateTimeArray[3] as arr_index_3, -- 2012-01-01 20:20:40 cur_dateTimeArray[4] as arr_index_4, -- 2012-01-01 20:21:00 cur_dateTimeArray[5] as arr_index_5; -- 2012-01-01 20:21:20 -- 六、字符串函数---&gt;&gt;&gt;&gt;&gt;&gt; 字符串函数：SELECT length(&#x27;hello world&#x27;) as str_length, -- 按照Unicode编码计算长度“你好”的长度为6 empty(&#x27;hello world&#x27;),-- 判断字符串是否为空，空为1，非空为0 notEmpty(&#x27;hello world&#x27;), lengthUTF8(&#x27;hello world&#x27;), -- 按照实际字符计算长度“你好”为2 char_length(&#x27;hello world&#x27;), -- 同 lengthUTF8() character_length(&#x27;hello world&#x27;), -- 同 lengthUTF8(), lower(&#x27;abcd123--&#x27;),--字母全部小写（将字符串中的ASCII转换为小写。） upper(&#x27;abcd123--&#x27;),--字母全部大写（将字符串中的ASCII转换为大写。） lowerUTF8(&#x27;abcd123-/*\\8asd-\\\\&#x27;), -- abcd123-/*8asd-\\ upperUTF8(&#x27;abcd123--&#x27;), -- ABCD123-- isValidUTF8(&#x27;abcd123--/*\\*&#x27;); --检查字符串是否为有效的UTF-8编码，是则返回1，否则返回0。SELECT notEmpty(&#x27;&#x27;), notEmpty(NULL), notEmpty(&#x27;he&#x27;); -- 0,空,1SELECT toValidUTF8(&#x27;\\x61\\xF0\\x80\\x80\\x80b&#x27;);-- reverseUTF8():以Unicode字符为单位反转UTF-8编码的字符串。如果字符串不是UTF-8编码，则可能获取到一个非预期的结果（不会抛出异常）SELECT reverse(&#x27;abcdefg&#x27;), reverseUTF8(&#x27;abcdefg&#x27;);-- 2.字符串维度自定义安排SELECT format(&#x27;&#123;1&#125; &#123;0&#125; &#123;1&#125;&#x27;, &#x27;World&#x27;, &#x27;Hello&#x27;); -- 输出：Hello World HelloSELECT format(&#x27;&#123;0&#125; &#123;0&#125; &#123;1&#125; &#123;1&#125;&#x27;, &#x27;one&#x27;, &#x27;two&#x27;); -- 输出：one one two twoSELECT format(&#x27;&#123;&#125; &#123;&#125;&#x27;, &#x27;Hello&#x27;, &#x27;World&#x27;); -- 输出：Hello World-- 3.字符串拼接 concat(s1,s2,s3,...)SELECT concat(&#x27;Hello&#x27;,&#x27; &#x27;,&#x27;World&#x27;, &#x27;!&#x27;);-- Hello World!-- 与concat相同，区别在于，你需要保证concat(s1, s2, s3) -&gt; s4是单射的，它将用于GROUP BY的优化。SELECT concatAssumeInjective(&#x27;Hello&#x27;,&#x27; &#x27;,&#x27;World&#x27;, &#x27;!&#x27;);-- Hello World!-- 4.字符串截取：substring(s, offset, length), mid(s, offset, length), substr(s, offset, length)-- 以字节为单位截取指定位置字符串，返回以‘offset’位置为开头，长度为‘length’的子串。‘offset’从1开始（与标准SQL相同）。‘offset’和‘length’参数必须是常量。SELECT substring(&#x27;abcdefg&#x27;, 1, 3),-- abc substring(&#x27;你好，世界&#x27;, 1, 3),-- 你 substringUTF8(&#x27;你好，世界&#x27;, 1, 3); -- 你好，-- 5.字符串拼接：appendTrailingCharIfAbsent(s, c)-- 如果‘s’字符串非空并且末尾不包含‘c’字符，则将‘c’字符附加到末尾。SELECT appendTrailingCharIfAbsent(&#x27;good&#x27;,&#x27;c&#x27;), -- goodc appendTrailingCharIfAbsent(&#x27;goodccc&#x27;,&#x27;c&#x27;); -- goodccc-- 6.字符串编码转换：convertCharset(s, from, to) 返回从‘from’中的编码转换为‘to’中的编码的字符串‘s’。SELECT convertCharset(&#x27;hello&#x27;, &#x27;UTF8&#x27;,&#x27;Unicode&#x27;),-- ��h convertCharset(&#x27;hello&#x27;, &#x27;Unicode&#x27;, &#x27;UTF8&#x27;),-- 桥汬� convertCharset(&#x27;hello&#x27;, &#x27;Unicode&#x27;, &#x27;ASCII&#x27;),-- convertCharset(&#x27;hello&#x27;, &#x27;ascii&#x27;, &#x27;ascii&#x27;),--hello convertCharset(&#x27;hello&#x27;, &#x27;UTF8&#x27;,&#x27;UTF8&#x27;);-- helloSELECT base64Encode(&#x27;username+password&#x27;),-- dXNlcm5hbWUrcGFzc3dvcmQ= base64Decode(&#x27;dXNlcm5hbWUrcGFzc3dvcmQ=&#x27;), -- username+password -- 使用base64将字符串解码成原始字符串。但如果出现错误，将返回空字符串。 tryBase64Decode(&#x27;dXNlcm5hbWUrcGFzc3dvcmQ=&#x27;);-- 7.判断字符串是否已什么结尾或结束，返回1：true，0：flase-- endsWith(s, suffix) 返回是否以指定的后缀结尾。如果字符串以指定的后缀结束，则返回1，否则返回0-- startWith(s, prefix) 返回是否以指定的前缀开头。如果字符串以指定的前缀开头，则返回1，否则返回0。SELECT endsWith(&#x27;string&#x27;,&#x27;g&#x27;), startsWith(&#x27;string&#x27;, &#x27;str&#x27;); -- 1 true-- 8.删除左侧空白字符-- trimLeft(s) 返回一个字符串，用于删除左侧的空白字符-- trimRight(s) 返回一个字符串，用于删除右侧的空白字符-- trimBoth(s) 返回一个字符串，用于删除左侧和右侧的空白字符SELECT trimLeft(&#x27; sdfdgs&#x27;), -- sdfdgs trimRight(&#x27;abcd &#x27;), -- abcd trimBoth(&#x27; abcd &#x27;); -- abcd-- 七、字符串搜索函数---&gt;&gt;&gt;&gt;&gt;&gt; 字符串搜索函数-- pasition(haystack, needle), 显示needle在haystack的第一个出现的位置。SELECT POSITION(&#x27;2121stringstrstrstrstr&#x27;,&#x27;str&#x27;) AS positionSearch, -- 5 POSITION(&#x27;你好，hello,12323-你好，你，好sdfd*dg&#x27;, &#x27;你，好&#x27;),-- 31 positionUTF8(&#x27;n12你好&#x27;,&#x27;你好&#x27;) AS positionUTF8,-- 4 positionCaseInsensitive(&#x27;ABCDCDEFABCD&#x27;,&#x27;bc&#x27;) AS positionCaseInsensitive, --2 locate(&#x27;hellohellohellohello&#x27;,&#x27;ello&#x27;); -- 2-- multiSearchAllPositions(haystack, [needle1, needle2, ..., needlen])-- 注意：在所有multiSearch*函数中，由于实现规范，needles的数量应小于2^8。-- 函数返回一个数组，其中包含所有匹配needlei的位置SELECT multiSearchAllPositions(&#x27;goodnamegoodnamegoodhellohihihi&#x27;, [&#x27;dn&#x27;, &#x27;good&#x27;]) as multiSearch,-- [4,1] multiSearchAllPositionsCaseInsensitive(&#x27;nameSsdfagpSSDFDFetgfderef&#x27;, [&#x27;SS&#x27;,&#x27;fa&#x27;]) as multiCaseInsensitive, multiSearchAllPositionsUTF8(&#x27;nameSsdfazz轴功率gpSSDFDFetgfderef&#x27;, [&#x27;Ss&#x27;,&#x27;fa&#x27;, &#x27;zz轴&#x27;]) AS multiSearchUTF8, multiSearchAllPositionsCaseInsensitiveUTF8(&#x27;nameSsdfazz轴功率gpSSDFDFetgfderef&#x27;, [&#x27;Ss&#x27;,&#x27;fa&#x27;, &#x27;zz轴&#x27;]) AS multiCaseInsensitiveUTF8;-- 检查字符串是否与pattern正则表达式匹配。pattern可以是一个任意的re2正则表达式。 re2正则表达式的语法比Perl正则表达式的语法存在更多限制。-- match(haystack, pattern) 匹配到了则返回1，否则返回0SELECT match(&#x27;1232434sadgaDDFSrefds&#x27;, &#x27;[0-9a-zA-Z]&#x27;), -- 存在匹配的字符，返回1 match(&#x27;1232321&#x27;, &#x27;[a-z]&#x27;); -- 不存在匹配的字符，返回0-- 与match相同，但如果所有正则表达式都不匹配，则返回0；如果任何模式匹配，则返回1。它使用hyperscan库。对于在字符串中搜索子字符串的模式，最好使用“multisearchany”，因为它更高效。-- multiMatchAny(haystack, [pattern1, pattern2, ..., patternn]) -- 注意：任何haystack字符串的长度必须小于232字节，否则抛出异常。这种限制是因为hyperscan API而产生的。-- 多个正则表达式对原始字符进行匹配，如若只有一个正则表达式匹配上了则返回1，否则返回0SELECT multiMatchAny(&#x27;abcABC&#x27;,[&#x27;[0-9]&#x27;,&#x27;[a-zA-Z]&#x27;]) AS multiMatchAnyOne, -- 1 multiMatchAny(&#x27;123abcABC&#x27;,[&#x27;[0-9]&#x27;,&#x27;[a-zA-Z]&#x27;]) AS multiMatchAnyTwo, --1 -- 与multiMatchAny相同，但返回与haystack匹配的任何内容的索引位置。 multiMatchAnyIndex(&#x27;123abcABC&#x27;, [&#x27;[0-9]&#x27;,&#x27;[a-zA-Z]&#x27;]) as multiMatchAnyIndex; --2-- 模糊匹配：like()函数，注意大写敏感。-- % 表示任何字节数（包括零字符）-- _ 表示任何一个字节SELECT &#x27;hello&#x27; LIKE &#x27;%h%&#x27; as LIKE_UP, -- 1 &#x27;hello&#x27; like &#x27;he&#x27; AS like_low, -- 0 &#x27;hello&#x27; not like &#x27;he&#x27; AS not_like, -- 1 &#x27;hello&#x27; like &#x27;%he%&#x27; AS like_litter, -- 1 like(&#x27;adgadgadfa1232&#x27;, &#x27;_12_&#x27;) AS like_func, like(&#x27;sdfasdfasd&#x27;, &#x27;[a-z]&#x27;) AS like_func2, -- 0 notLike(&#x27;1232423&#x27;, &#x27;[a-zA-Z]&#x27;) AS not_like_func; -- 1-- 使用字符串截取字符串：extract(haystack, pattern)-- 使用正则表达式截取字符串。如果‘haystack’与‘pattern’不匹配，则返回空字符串。如果正则表达式中不包含子模式，它将获取与整个正则表达式匹配的子串。否则，它将获取与第一个子模式匹配的子串。SELECT extractAll(&#x27;hellogoodaimantIdeaIDEAfasd123232&#x27;, &#x27;[0-9]&#x27;), -- [&#x27;1&#x27;,&#x27;2&#x27;,&#x27;3&#x27;,&#x27;2&#x27;,&#x27;3&#x27;,&#x27;2&#x27;] extractAll(&#x27;12323dSDFRE&#x27;, &#x27;[A-Z]&#x27;),-- [&#x27;S&#x27;,&#x27;D&#x27;,&#x27;F&#x27;,&#x27;R&#x27;,&#x27;E&#x27;] extract(&#x27;helloclickhouse&#x27;, &#x27;[a-z]&#x27;);-- h-- ngramSearch(haystack, needle)-- 基于4-gram计算haystack和needle之间的距离：计算两个4-gram集合之间的对称差异，并用它们的基数和对其进行归一化。-- 返回0到1之间的任何浮点数 -- 越接近0则表示越多的字符串彼此相似。-- 如果常量的needle或haystack超过32KB，函数将抛出异常。如果非常量的haystack或needle字符串超过32Kb，则距离始终为1。SELECT ngramDistance(&#x27;hello123456789&#x27;,&#x27;123&#x27;) AS ngramDistance, ngramDistanceCaseInsensitive(&#x27;hello123456789&#x27;,&#x27;123&#x27;) AS ngramDistanceCaseInsensitive, ngramDistanceUTF8(&#x27;hello123456789&#x27;,&#x27;123&#x27;) AS ngramDistanceUTF8, ngramDistanceCaseInsensitiveUTF8(&#x27;hello123456789&#x27;,&#x27;123&#x27;) AS ngramDistanceCaseInsensitiveUTF8;-- 注意：对于UTF-8，我们使用3-gram。所有这些都不是完全公平的n-gram距离。-- 我们使用2字节哈希来散列n-gram，然后计算这些哈希表之间的（非）对称差异 - 可能会发生冲突。-- 对于UTF-8不区分大小写的格式，我们不使用公平的tolower函数 -- 我们将每个Unicode字符字节的第5位（从零开始）和字节的第一位归零 -- 这适用于拉丁语，主要用于所有西里尔字母。--八、字符串替换函数---&gt;&gt;&gt;&gt;&gt;&gt; 字符串替换函数-- 替换匹配到的字符串-- replaceOne(haystack, pattern, replacement)-- 用‘replacement’子串替换‘haystack’中与‘pattern’子串第一个匹配的匹配项（如果存在）。 ‘pattern’和‘replacement’必须是常量。-- replaceAll(haystack, pattern, replacement), replace(haystack, pattern, replacement)-- 用‘replacement’子串替换‘haystack’中出现的所有‘pattern’子串。SELECT replaceOne(&#x27;hed1234544&#x27;, &#x27;4&#x27;, &#x27;*&#x27;) AS replaceOne,-- hed123*544 replaceRegexpOne(&#x27;hed1234544&#x27;, &#x27;4&#x27;, &#x27;*&#x27;) AS replaceRegexpOne,-- hed123*544 replace(&#x27;hed1234544&#x27;, &#x27;4&#x27;, &#x27;*&#x27;) AS replace, -- hed123*5** replaceAll(&#x27;hed1234544&#x27;, &#x27;4&#x27;, &#x27;*&#x27;) AS replaceAll;-- hed123*5**-- 实例：2019-07-31 改变成 07/31/2019SELECT toDate(now()) AS now_date, replaceRegexpOne(toString(now_date), &#x27;(\\\\d&#123;4&#125;)-(\\\\d&#123;2&#125;)-(\\\\d&#123;2&#125;)&#x27;, &#x27;\\\\2/\\\\3/\\\\1&#x27;) AS format_date;-- 示例：赋值字符串10次SELECT replaceRegexpOne(&#x27;Hello, World!&#x27;, &#x27;.*&#x27;, &#x27;\\\\0\\\\0\\\\0\\\\0\\\\0\\\\0\\\\0\\\\0\\\\0\\\\0&#x27;) AS res;-- replaceRegexpAll(haystack, pattern, replacement)-- 与replaceRegexpOne相同，但会替换所有出现的匹配项。例如：SELECT replaceRegexpAll(&#x27;hello,world!&#x27;, &#x27;.&#x27;, &#x27;\\\\0\\\\0&#x27;) as res; -- hheelllloo,,wwoorrlldd!!SELECT replaceRegexpAll(&#x27;hello o o, world.&#x27;, &#x27; &#x27;, &#x27;*&#x27;) as res; -- hello*o*o,*world.-- 函数：regexpQuoteMeta(s) 该函数用于在字符串中的某些预定义字符之前添加反斜杠。-- 预定义字符：&#x27;0&#x27;，&#x27;\\&#x27;，&#x27;|&#x27;，&#x27;(&#x27;，&#x27;)&#x27;，&#x27;^&#x27;，&#x27;$&#x27;，&#x27;。&#x27;，&#x27;[&#x27;，&#x27;]&#x27;，&#x27;？&#x27;，&#x27;* &#x27;，&#x27;+&#x27;，&#x27;&#123;&#x27;，&#x27;：&#x27;，&#x27; - &#x27;。 -- 这个实现与re2 :: RE2 :: QuoteMeta略有不同。它以\\0而不是\\x00转义零字节，它只转义所需的字符---- 简言之，就是不处理转义字符，一般如果没有用的这个函数，都会有转义的情况出现。SELECT regexpQuoteMeta(&#x27;\\\\\\\\|[]&#123;&#125;+_-=@!~`&amp;^*%$#&#x27;); -- \\\\\\\\\\|\\[\\]\\&#123;&#125;\\+_\\-=@!~`&amp;\\^\\*%\\$#SELECT toString(&#x27;\\\\\\\\&#x27;); -- \\\\ --九、条件函数---&gt;&gt;&gt;&gt;&gt;&gt; 条件函数-- 1. if(cond, then, else)函数：类似于三元操作符。-- 中文字符使用双引号，英文字符可不使用引号也可使用当引号或双引号，根据具体情况而定。-- 如果cond ！= 0则返回then，如果cond = 0则返回else。 cond必须是UInt8类型，then和else必须存在最低的共同类型。-- 注意：then和else可以是NULLSELECT &gt; 10 ? &#x27;desc&#x27; : &#x27;asc&#x27; AS &quot;三元操作符&quot;, if(12 &gt; 10, &#x27;desc&#x27; , &#x27;asc&#x27;) AS &quot;if()函数&quot;, if(12 &gt; 10, NULL, NULL);-- 2. multiIf(cond_1, then_1, cond_2, then_2...else)-- 允许您在查询中更紧凑地编写CASE运算符。类似于java中的switch语法（可以接受2n+1个参数）SELECT multiIf(1,&#x27;one&#x27;,2,&#x27;two&#x27;,3,&#x27;three&#x27;,&#x27;not this index&#x27;);-- 关联case条件表达式--十、数学函数---&gt;&gt;&gt;&gt;&gt;&gt; 数学函数SELECT* e() AS E,* pi() AS PI, sqrt(25) AS sqrt_25, --接受一个数值类型的参数并返回它的平方根。 cbrt(27) AS cbrt_27, --接受一个数值类型的参数并返回它的立方根。 exp(10), --接受一个数值类型的参数并返回它的指数 exp10(10), --接受一个数值类型的参数并返回它的10的x次幂。 log(10) AS LOG, log2(10) AS LOG2, --接受一个数值类型的参数并返回它的底2对数。 ln(e()) AS LOG10; --接受一个数值类型的参数并返回它的自然对数-- 示例：三西格玛准则SELECT erf(3 / sqrt(2)); -- 0.997SELECT sin(90), -- 返回x的三角正弦值。 cos(90), -- 返回x的三角余弦值。 tan(90), -- 返回x的三角正切值 acos(0), -- 返回x的反三角余弦值。 asin(1), -- 返回x的反三角正弦值。 atan(45); -- 返回x的反三角正切值。-- pow(x, y), power(x, y) 接受x和y两个参数。返回x的y次方。SELECT pow(2, 3), -- 2的三次方 pow(3, 2); -- 3的平方SELECT intExp2(4), --2^4 接受一个数值类型的参数并返回它的2的x次幂（UInt64）。 intExp10(2);--10^2 接受一个数值类型的参数并返回它的10的x次幂（UInt64）。 -- 十一、取整函数---&gt;&gt;&gt;&gt;&gt;&gt; 取整函数-- 1.向下取整：floor(x[,N])SELECT floor(toFloat32(12.08098), 2), -- 12.08 floor(toFloat32(12.2323), 2), -- 12.23 floor(toFloat32(12.89788), -1), -- 10 floor(toFloat32(12.09590), 3), -- 12.095 (注意：如果按照正常的四舍五入，则应该是12.096，为什么呢？) floor(toFloat32(12.0987), 3),-- 12.098 floor(10, 2); -- 10-- 2.四舍五入：round(expression [, decimal_places])-- 如果decimal_places=0,则取整数；-- 如果&gt;0,则将值舍入小数点右侧；-- 如果&lt;0,则将小数点左侧的值四舍五入。SELECT round(toFloat32(12.1234), 3), round(toFloat32(12.0025), 3), -- 12.002(注意：为什么不是12.003呢？) -- round函数只会最多保留三位有效数字 round(toFloat32(12.0025), 4), -- 12.002 round(toFloat32(12.0025002323), 100); -- 12.003-- 示例：SELECT round(toFloat32(10 / 3)), -- 3 round(toFloat32(10 / 3), 2), -- 3.33 round(toFloat32(10.000/3), 3), -- 3.333 round(toFloat32(10.000/3), 6); -- 3.333-- roundToExp2() 接受一个数字。如果数字小于1，则返回0。否则，它将数字向下舍入到最接近的（整个非负）2的x次幂。SELECT roundToExp2(12.0129), -- 8 = 2^3 roundToExp2(toFloat32(0.01)); -- 0.008-- 3.向上取整：ceil(x[, N]) 或者 ceiling(x[, N])SELECT ceil(12.34343, 3), -- 12.344 ceil(toFloat64(12.34343), 3), -- 12.344 ceil(toFloat32(12.34343), 3), -- 12.344 ceil(12.0011, 3); -- 12.002 ---十二、数组函数---&gt;&gt;&gt;&gt;&gt;&gt; 数组函数-- 1.数组非空判断相关函数（真为1，假为0）SELECT empty([]), empty([1,2,3]), notEmpty([1,2,3]), notEmpty([]);-- 2.数组长度 length() 返回数组中的元素个数。 结果类型是UInt64。 该函数也适用于字符串。SELECT-- length(), -- 出现异常-- length([true, false]), -- 异常-- length([1,2,,4]), --出现异常！ length([]), -- 0 length([&#x27;a&#x27;,&#x27;b&#x27;,&#x27;c&#x27;]), -- 3 length([1,2,3]); -- 3-- 3.扩展判断非空的部分函数如下：不接受任何参数并返回适当类型的空数组SELECT emptyArrayUInt8(), -- UInt8的空数组 emptyArrayUInt16(), emptyArrayUInt32(), emptyArrayUInt64(), emptyArrayDate(), emptyArrayDateTime(), emptyArrayInt8(), emptyArrayInt16(), emptyArrayInt32(), emptyArrayInt64();-- 接受一个空数组并返回一个仅包含一个默认值元素的数组。(以下是部分示例)SELECT emptyArrayToSingle(emptyArrayInt32()), -- 0 emptyArrayToSingle(emptyArrayUInt32()), -- 0 emptyArrayToSingle(emptyArrayDate()), -- 0002-11-30 emptyArrayToSingle(emptyArrayDateTime()); --0002-11-30 08:00:00-- 4.生成一个含有N个元素的数组,元素从0开始增长，步长尾1.-- range(N) 返回从0到N-1的数字数组。 以防万一，如果在数据块中创建总长度超过100,000,000个元素的数组，则抛出异常SELECT range(10), -- [0,1,2,3,4,5,6,7,8,9] range(2), -- [0,1]-- range(5.5), -- 出现异常，N为Int8的数据类型，正整数-- range(-10), -- 出现异常，DB::Exception: Illegal type Int8 of argument of function range range(1); -- 0-- 5.新建一个数组的函数：array(x1,……) 类似于 直接[x1,……]-- 注意：新建数组的每个元素的数据类型需保持一致性。SELECT array(1,2,2,3,4) AS &quot;array()函数&quot;,-- [1,&#x27;hello&#x27;,3], -- 出现异常，DB::Exception: There is no supertype for types UInt8, String, UInt8 because some of them are String/FixedString and some of them are not (version 19.10.1.5 (official build)) [1,2,3,4] AS &quot;[ ]&quot;;-- 6.合并N个数组 arrayConcat(arrays) 合并参数中传递的所有数组。跟java的数组差不多的合并，不会自动去重，不会自动排序SELECT arrayConcat(array(1,2),array(2,3),array(4,5)), -- [1,2,2,3,4,5]（第一种情况） arrayConcat(array(1,1),array(2,2),array(3,3)), -- [1,1,2,2,3,3]-- arrayConcat(array(1,2),[&#x27;a&#x27;,&#x27;c&#x27;],array(3,3)), -- 出现异常，不能将不同类型的数组进行合并 arrayConcat(array(1,1),[2,3],array(4,5)); -- [1,1,2,3,4,5]-- 7.从数组arr中获取索引为“n”的元素。-- n必须是任何整数类型。 数组中的索引从一开始。 支持负索引。在这种情况下，它选择从末尾开始编号的相应元素。例如，arr [-1]是数组中的最后一项。-- 如果索引超出数组的边界，则返回默认值（数字为0，字符串为空字符串等）.SELECT arrayElement(array(10,20,3), 1), -- 10 arrayElement(array(1,20,3), 2), -- 20 arrayElement(array(1,2,30), 3), -- 30 arrayElement(array(10,20,3), 0), -- 0 arrayElement(array(10,20,3), -3), -- 10 arrayElement(array(10,20,3), -2), -- 20 arrayElement(array(10,20,3), -1);-- 3-- 8.检查在数组中是否含有此元素。has(arr, elem) 包含此元素则返回1，否则返回0-- has() 检查&#x27;arr&#x27;数组是否具有&#x27;elem&#x27;元素。 如果元素不在数组中，则返回0;如果在，则返回1。-- hasAny(arr1, arr2) 返回1表示arr1和arr2存在交集。否则返回0. --注意：特殊的定义：-- ① “NULL”作为数组中的元素值进行处理。-- ② 忽略两个数组中的元素值的顺序-- hasAll(set, subset) 检查一个数组是否是另一个数组的子集。返回1，表示set包含subset中所有的元素-- set – 具有一组元素的任何类型的数组。-- subset – 任何类型的数组，其元素应该被测试为set的子集。-- 注意：特殊的定义：-- ① 空数组是任何数组的子集。-- ② “NULL”作为数组中的元素值进行处理。-- ③ 忽略两个数组中的元素值的顺序。SELECT has([1,2,3], 2), -- 1 has(array(1,2,3),2), -- 1 has([1,2,NULL], NULL), -- 1 (注意：null值的处理)-- has([], 2), -- 出现异常，DB::Exception: Types of array and 2nd argument of function has must be identical up to nullability or numeric types or Enum and numeric type. Passed: Array(Nothing) and UInt8 has([1,2], 3); -- 0SELECT hasAll([], []), -- 1 hasAll([1,NULL,NULL], [NULL]), -- 1 hasAll([1,2,3], [1,2]), -- 1 hasAll([1,2,2,3], [2]), -- 1 hasAll(array(1,2,2,3), [2]), -- 1 hasAll([1,2,3], [4,5]); -- 0-- 多重数组（如下的二维数组）。SELECT hasAll([[1, 2], [3, 4]], [[1, 2], [3, 5]]); -- 0SELECT hasAny(array(1,2,3), array(1)), -- 1 hasAny(array(1,2,3), array(1,4,56,80)), -- 1 -- []与array()是一样的含义，本质上是一直的。只不过[]更加简便而已。 hasAny(array(), array()), -- 0 hasAny([],[]), -- 0 hasAny([1],[]), -- 0 -- 空数组跟null不是一样的对象 hasAny([1,NULL],[]), -- 0 hasAny([1,NULL],[NULL,2]); -- 1 -- 9.返回数组指定元素的索引-- indexOf(arr, x) 返回数组中第一个‘x’元素的索引（从1开始），如果‘x’元素不存在在数组中，则返回0。SELECT indexOf([&#x27;one&#x27;,&#x27;two&#x27;,&#x27;three&#x27;], &#x27;one&#x27;); -- 1SELECT indexOf([1, 2, 4], 4); -- 3SELECT indexOf([&#x27;one&#x27;,&#x27;two&#x27;,&#x27;three&#x27;], &#x27;one&#x27;), -- 1 indexOf([&#x27;one&#x27;,NULL,NULL], NULL),-- 1返回第一个找到的元素的索引位置 indexOf([1, 2, 4], 4); -- 3-- 数组元素的以第一个和最后一个元素。SELECT length([12,3,4,4,4]);SELECT array(12,22,31)[1];WITH [23,43,565,2,32,34] AS arrSELECT arr[1], -- 去除数组中的第一个元素 arr[length(arr)]; -- 提取元素中的最后一个元素 -- 10.计算数组中包含指定元素的个数-- countEqual(arr, x) 返回数组中等于x的元素的个数。相当于arrayCount（elem - &gt; elem = x，arr）。-- 注意：null值将作为单独的元素值处理。SELECT countEqual([1, 2, 2, 2, 3, 4], 2), -- 3 countEqual([1, 2, NULL, NULL], NULL); -- 2 -- 11.arrayEnumerate(arr) 返回 Array [1, 2, 3, ..., length (arr) ] 此功能通常与ARRAY JOIN一起使用。它允许在应用ARRAY JOIN后为每个数组计算一次。SELECT arrayEnumerate([1,20,20,3]); -- [1,2,3,4]SELECT arrayEnumerate(array(11,20,13)); -- [1,2,3]SELECT arrayEnumerate(array(11,20,13,NULL)); -- [1,2,3,4] 注意：null也算是一个元素。--arrayEnumerateUniq(arr) 返回与源数组大小相同的数组，其中每个元素表示与其下标对应的源数组元素在源数组中出现的次数SELECT arrayEnumerateUniq([1,1,2,2]); -- [1,2]-- 12.删除数组的元素-- arrayPopBack(array) 删除数组array的最后一项SELECT arrayPopBack(array(1,2,3,0)) AS res; -- [1,2,3]-- arrayPopFront(array) 从数组中删除第一项SELECT arrayPopFront(array(0,1,2,3)) AS res; -- [1,2,3]-- 13.添加数组的元素 arrayPushFront(array, single_value) single_value是单个值SELECT arrayPushBack([1,2,3], 0) AS res; -- [1,2,3,0]SELECT arrayPushFront([1,2,3], 0) AS res; -- [0,1,2,3]-- 14.更改数组的长度 arrayResize(arr, size[, extender])-- 如果arr的长度 &gt; size,则会对arr截取size的长度；-- 如果arr的长度 &lt; size，则其余位置用对应数据类型的默认值填充。-- 注意：extender含义是扩展元素的值。如果没有指定extender，则默认按照对应的数据类型的默认值进行赋值。否则按照extender进行填充。SELECT arrayResize([1,2,3], 5); -- [1,2,3,0,0]SELECT arrayResize([1,2,3], 2); -- [1,2]SELECT arrayResize([1,2,3], 3); -- [1,2,3]--↓↓↓ RuntimeException: Parse exception: ByteFragment&#123;[[[1,2],[3,4],[5,6],[],[]]], start=0, len=25&#125;SELECT arrayResize([array(1,2),array(3,4),array(5,6)], 5);SELECT arrayResize([1,2,3], 5, 12); -- [1,2,3,12,12]SELECT arrayResize([&#x27;one&#x27;,&#x27;two&#x27;,&#x27;three&#x27;], 5); -- [&#x27;one&#x27;,&#x27;two&#x27;,&#x27;three&#x27;,&#x27;&#x27;,&#x27;&#x27;]SELECT arrayResize([&#x27;one&#x27;,&#x27;two&#x27;,&#x27;three&#x27;], 5, &#x27;default&#x27;); -- [&#x27;one&#x27;,&#x27;two&#x27;,&#x27;three&#x27;,&#x27;default&#x27;,&#x27;default&#x27;]-- 15.截取数组的部分元素，得到一个新的子数组-- arraySlice(array, offset[, length])-- 解释：-- array: 数组，-- offset – 数组的偏移。正值表示左侧的偏移量，负值表示右侧的缩进值。数组下标从1开始。-- length - 子数组的长度。如果指定负值，则该函数返回[offset，array_length - length。如果省略该值，则该函数返回[offset，the_end_of_array]。SELECT arraySlice([1,2,3,4,5,6], 0, 3), -- 无返回值 arraySlice([1,2,NULL,5,6], 1, 3), -- [1,2,0] arraySlice([&#x27;one&#x27;,&#x27;two&#x27;,NULL], 1, 3), -- [&#x27;one&#x27;,&#x27;two&#x27;,&#x27;&#x27;] arraySlice([1,2,3,4,5,6], 1, 3); -- [1,2,3] -- 16.数组排序：arraySort([func,] arr, ……)-- 注意：如果在字符串数组中，&#x27;&#x27;和NULL是需要特别对待的，&#x27;&#x27;需要放在最前面，而NULL则是按顺序存放到最后的。-- arraySort是高阶函数。您可以将lambda函数作为第一个参数传递给它。在这种情况下，排序顺序由lambda函数的调用结果决定。SELECT arraySort([&#x27;a&#x27;,&#x27;&#x27;,NULL,&#x27;c&#x27;,&#x27;b&#x27;]) AS hasNullempty1, --[&#x27;&#x27;,&#x27;a&#x27;,&#x27;b&#x27;,&#x27;c&#x27;,&#x27;&#x27;] (第一个是&#x27;&#x27;,最后一个&#x27;&#x27;起始是NULL) arraySort(array(&#x27;ac&#x27;,&#x27;ab&#x27;,&#x27;bc&#x27;,&#x27;ad&#x27;,NULL)) AS hasNull, -- [&#x27;ab&#x27;,&#x27;ac&#x27;,&#x27;ad&#x27;,&#x27;bc&#x27;,&#x27;&#x27;] arraySort(array(&#x27;ac&#x27;,&#x27;&#x27;,&#x27;ab&#x27;,NULL,&#x27;bc&#x27;,&#x27;ad&#x27;,NULL)) AS hasNullempty2, -- [&#x27;&#x27;,&#x27;ab&#x27;,&#x27;ac&#x27;,&#x27;ad&#x27;,&#x27;bc&#x27;,&#x27;&#x27;,&#x27;&#x27;] arraySort([5,4,3,2,1]) AS numSorted,-- [1,2,3,4,5] (数字排序) arraySort([&#x27;ca&#x27;,&#x27;bb&#x27;,&#x27;ac&#x27;]) AS strSorted;-- [&#x27;ac&#x27;,&#x27;bb&#x27;,&#x27;ca&#x27;] (字符串排序)SELECT arraySort([NULL, 1, 3, NULL, 2]) AS sortedArr, -- [1,2,3,0,0] arrayReverse(sortedArr) AS reverseSortdArr;-- [0,0,3,2,1]-- 下面这种排序的实质，正数转成负数，再在数学上比较升序排序。SELECT arraySort(x -&gt; -x, [1,2,3]) as res; -- [3,2,1] 降序：（高阶函数用法）SELECT arraySort((x) -&gt; -x, [1,2,3]) as res; -- [3,2,1] 降序：（高阶函数用法）SELECT arraySort(x -&gt; x, [5,4,3,1,2,3]) as res; -- [1,2,3,3,4,5] 升序：（高阶函数用法）SELECT arraySort((x) -&gt; x, [5,4,3,1,2,3]) as res; -- [1,2,3,3,4,5] 升序：（高阶函数用法）-- arraySort(lambda, arr1, arr2) SELECT arraySort((x, y) -&gt; y, [&#x27;hello&#x27;, &#x27;world&#x27;], [2, 1]) as res; -- [&#x27;world&#x27;,&#x27;hello&#x27;]SELECT arraySort((x, y) -&gt; -y, [0, 1, 2], [1, 2, 3]) as res; -- [2,1,0]-- 再次提醒：NULL, NaN, Inf的排序顺序：-- 含义：-- -Inf 是数组中的第一个。-- NULL 是数组中的最后一个。-- NaN 在NULL的前面。-- Inf 在NaN的前面。-- 出现异常：RuntimeException: Parse exception: -- ByteFragment&#123;[[-inf,-4,1,2,3,inf,nan,nan,NULL,NULL]], start=0, len=37&#125;SELECT arraySort([1, nan, 2, NULL, 3, nan, -4, NULL, inf, -inf]);-- 17.数组翻转：arrayReverse([func,] arr, ……)-- 如果是NULL的话在排序的过程中，根据数组的数据类型进行默认值填充。SELECT arrayReverse(array(&#x27;a&#x27;,&#x27;b&#x27;,&#x27;c&#x27;,NULL)) AS hasOneNull, -- [&#x27;&#x27;,&#x27;c&#x27;,&#x27;b&#x27;,&#x27;a&#x27;] arrayReverse(array(&#x27;ac&#x27;,&#x27;ab&#x27;,&#x27;bc&#x27;,&#x27;ad&#x27;,NULL)) AS hasNull, -- [&#x27;&#x27;,&#x27;ad&#x27;,&#x27;bc&#x27;,&#x27;ab&#x27;,&#x27;ac&#x27;] --网格视图： [&#x27;[NULL]&#x27;,&#x27;ad&#x27;,&#x27;bc&#x27;,&#x27;&#x27;,&#x27;ab&#x27;,&#x27;[NULL]&#x27;,&#x27;&#x27;,&#x27;ac&#x27;]；文本视图 ：[&#x27;&#x27;,&#x27;ad&#x27;,&#x27;bc&#x27;,&#x27;&#x27;,&#x27;ab&#x27;,&#x27;&#x27;,&#x27;&#x27;,&#x27;ac&#x27;] arrayReverse(array(&#x27;ac&#x27;,&#x27;&#x27;,NULL,&#x27;ab&#x27;,&#x27;&#x27;,&#x27;bc&#x27;,&#x27;ad&#x27;,NULL)) AS hasNullEmpty, arrayReverse(array(NULL, 3, NULL, 2, 1)),-- [1,2,0,3,0] arrayReverse([1,2,3,4]);-- [4,3,2,1]-- 18.数组排序并翻转：arraySort([func,] arr, ...)SELECT arrayReverseSort([1, 3, 3, 0]); -- [3,3,1,0]SELECT arrayReverseSort([&#x27;hello&#x27;, &#x27;world&#x27;, &#x27;!&#x27;]); -- [&#x27;world&#x27;,&#x27;hello&#x27;,&#x27;!&#x27;]--RuntimeException: Parse exception: ByteFragment&#123;[[inf,3,2,1,-4,-inf,nan,nan,NULL,NULL]], start=0, len=37&#125;SELECT arrayReverseSort([1, nan, 2, NULL, 3, nan, -4, NULL, inf, -inf]) as res;-- [inf,3,2,1,-4,-inf,nan,nan,NULL,NULL]-- 下面的执行顺序为：-- 1.首先，根据lambda函数的调用结果对源数组（[1, 2, 3]）进行排序。 结果是[3, 2, 1]。-- 2.反转上一步获得的数组。 所以，最终的结果是[1, 2, 3]。SELECT arrayReverseSort((x) -&gt; -x, [1, 2, 3]) as res; -- [1,2,3]SELECT arrayReverseSort((x) -&gt; x, [1, 2, 3]) as res; -- [1,2,3]-- 下面的执行顺序为：-- 1.首先，根据lambda函数的调用结果对源数组（[&#x27;hello&#x27;，&#x27;world&#x27;]）进行排序。 其中，在第二个数组（[2,1]）中定义了源数组中相应元素的排序键。 所以，排序结果[&#x27;world&#x27;，&#x27;hello&#x27;]。-- 2.反转上一步骤中获得的排序数组。 所以，最终的结果是[&#x27;hello&#x27;，&#x27;world&#x27;]。SELECT arrayReverseSort((x, y) -&gt; y, [&#x27;hello&#x27;, &#x27;world&#x27;], [2, 1]) as res;-- [&#x27;hello&#x27;,&#x27;world&#x27;]SELECT arrayReverseSort((x, y) -&gt; -y, [&#x27;hello&#x27;, &#x27;world&#x27;], [2, 1]) as res;-- [&#x27;world&#x27;,&#x27;hello&#x27;]SELECT arrayReverseSort((x, y) -&gt; x, [&#x27;hello&#x27;, &#x27;world&#x27;], [2, 1]) as res;-- [&#x27;world&#x27;,&#x27;hello&#x27;]--出现异常：Illegal type String of argument --SELECT arrayReverseSort((x, y) -&gt; -x, [&#x27;hello&#x27;, &#x27;world&#x27;], [2, 1]) as res;SELECT arrayReverseSort((x, y) -&gt; x, [&#x27;hello&#x27;, &#x27;world&#x27;], [1, 2]) as res;-- [&#x27;world&#x27;,&#x27;hello&#x27;]-- 19.统计数组中不重复元素的个数。arrayUniq(arr,……)-- ① 如果传递一个参数，则计算数组中不同元素的数量。-- ② 如果传递了多个参数，则它计算多个数组中相应位置的不同元素元组的数量SELECT arrayUniq([1,2,3]), -- 3 arrayUniq([1,2,2,2,3]); -- 3SELECT arrayUniq([1,2,3],[2,3,4]), arrayUniq([1,2,2],[1,3,3]);-- 20.数组的特殊功能：arrayJoin(arr) 这是一个非常有用的函数。-- 解释：此函数将数组作为参数，并将该行在结果集中复制数组元素个数SELECT arrayJoin([1, 2, 3] AS src) AS dst, &#x27;Hello&#x27;, src; -- 每个元素扩大两倍；SELECT arrayJoin([1,2,3]) * 2;SELECT arrayJoin([-1,-2,0,1,2]) * 2;--出现异常： Illegal types Array(UInt8) and Array(UInt8) of arguments of function multiply--SELECT multiply(array(1,2,3), 2); SELECT multiply(arrayJoin([-1,-2,0,1,2]), 2); -- 每个元素缩小两倍SELECT arrayJoin([-4,-2,0,2,4]) / 2;SELECT divide(arrayJoin([-4,-2,0,2,4]) , 2); -- 21.arrayDifference(arr)-- 返回一个数组，其中包含所有相邻元素对之间的差值SELECT arrayDifference([1,2,3,4]);-- [0,1,1,1]SELECT arrayDifference([1,3,10,50]);-- [0,2,7,40] -- 22. arrayDistinct(arr)返回一个包含所有数组中不同元素的数组.-- 类似于java的Set集合，对list集合进行去重。SELECT arrayDistinct(array(1,2,3,4,4,4)); -- [1,2,3,4]SELECT arrayDistinct([1,2,2,3,4,2,2,5,4,5]); -- [1,2,3,4,5]SELECT arrayDistinct(array(0,1,NULL,3,4,4,4)); -- [0,1,3,4]-- 数组去重统计元素个数SELECT uniq(arrayJoin([1,2,3,6,3])); -- 4 表示数组去重后元素的个数SELECT uniqArray([1,2,3,4,1,2,3,4]); -- 4 表示数组去重后元素的个数-- 数组元素累计SELECT sumArray([1,2,3,4,5]);-- 15SELECT sum(arraySum([1,2,3,4,5])); -- 15 -- 23. arrayEnumerateDense(arr) 返回与源数组大小相同的数组，指示每个元素首次出现在源数组中的位置SELECT arrayEnumerateDense([10,20,20,10,30]) AS numArrEnumDense,-- [1,2,2,1,3] -- [1,1,2,3,4,1,3,5,5] arrayEnumerateDense([10,10,2,12,3,10,12,NULL,NULL]) as arrEnumDenseHasNull, -- [1,2,1,1,2,3] arrayEnumerateDense([10,20,10,10,20,30]) AS arrEnumDese2;-- 24. arrayIntersect(arr,……) 返回所有数组元素的交集。-- 如果arr的数目只有一个，则返回它本身；如果有多个数组,则返回所有数组中元素的交集。SELECT -- 注意：最后得到的数组元素的顺序。（有什么影响吗？） arrayIntersect([&#x27;one&#x27;,&#x27;two&#x27;],[&#x27;one&#x27;,&#x27;two&#x27;,&#x27;three&#x27;]) as uniStrArr1, -- [&#x27;two&#x27;,&#x27;one&#x27;] arrayIntersect([&#x27;aaa&#x27;,&#x27;bbb&#x27;],[&#x27;bbb&#x27;,&#x27;aaa&#x27;,&#x27;three&#x27;]) as uniStrArr2, -- [&#x27;bbb&#x27;,&#x27;aaa&#x27;] arrayIntersect([1,2],[1,2,3]) as uniArr1, -- [1,2] arrayIntersect([1,2],[1,2,3],[2,3,4],[2,3,4]) as uniArr2; -- 2SELECT arrayIntersect([1,2], [3,4]), -- [] arrayIntersect([1,2]);-- [1,2]-- 25.arrayReduce(agg_func, arr1, ...)-- agg_func 为聚合函数，传入到数组当中。-- 将聚合函数应用于数组并返回其结果.如果聚合函数具有多个参数，则此函数可应用于相同大小的多个数组。SELECT arrayReduce(&#x27;max&#x27;, [1,2,3]) AS minNum,--最大值 3 arrayReduce(&#x27;min&#x27;, [1,2,3]) AS maxNum,--最小值 1 arrayReduce(&#x27;sum&#x27;, [1,2,3]) AS sumNum;--求和 6-- 十三、 字符串查分合并函数---&gt;&gt;&gt;&gt;&gt;&gt; 字符串拆分合并函数-- 1.splitByChar(separator, s) 将字符串以‘separator’拆分成多个子串。-- ‘separator’必须为仅包含一个字符的字符串常量。 返回拆分后的子串的数组。-- 如果分隔符出现在字符串的开头或结尾，或者如果有多个连续的分隔符，则将在对应位置填充空的子串。SELECT splitByChar(&#x27;,&#x27;, &#x27;hello,world!&#x27;); -- [&#x27;hello&#x27;,&#x27;world!&#x27;]--下面异常：Illegal separator for function splitByChar. Must be exactly one byte.--SELECT splitByChar(&#x27;or&#x27;, &#x27;hello,world!&#x27;);-- 2.splitByString(separator, s)-- 与上面相同，但它使用多个字符的字符串作为分隔符。 该字符串必须为非空SELECT splitByString(&#x27;or&#x27;,&#x27;goodorniceorgreat&#x27;); -- [&#x27;good&#x27;,&#x27;nice&#x27;,&#x27;great&#x27;]-- 3.alphaTokens(s) 从范围a-z和A-Z中选择连续字节的子字符串。返回子字符串数组SELECT alphaTokens(&#x27;abca1abc&#x27;); -- [&#x27;abca&#x27;,&#x27;abc&#x27;]SELECT alphaTokens(&#x27;abc1232abc2wer3rtty&#x27;); -- [&#x27;abc&#x27;,&#x27;abc&#x27;,&#x27;wer&#x27;,&#x27;rtty&#x27;]-- 4.数组元素合并函数：arrayStringConcat(arr[, sparator])-- 使用separator将数组中列出的字符串拼接起来。-- ‘separator’是一个可选参数：一个常量字符串，默认情况下设置为空字符串。 返回拼接后的字符串SELECT arrayStringConcat([1,2,3], &#x27;-&#x27;); -- 出现异常，要求数组必须是字符串string类型的元素SELECT arrayStringConcat([&#x27;one&#x27;,&#x27;two&#x27;,&#x27;three&#x27;]); -- onetwothreeSELECT arrayStringConcat([&#x27;one&#x27;,&#x27;two&#x27;,&#x27;three&#x27;], &#x27;-&#x27;); -- one-two-threeSELECT arrayStringConcat([&#x27;one&#x27;,&#x27;two&#x27;,&#x27;three&#x27;,&#x27;&#x27;], &#x27;-&#x27;);-- one-two-three- 注意：NULL不能存在arr中 --十四、位操作符---&gt;&gt;&gt;&gt;&gt;&gt; 位操作符--位操作函数适用于UInt8，UInt16，UInt32，UInt64，Int8，Int16，Int32，Int64，Float32或Float64中的任何类型。--结果类型是一个整数，其位数等于其参数的最大位。--如果至少有一个参数为有符数字，则结果为有符数字。如果参数是浮点数，则将其强制转换为Int64。SELECT bitAnd(1,0), -- 0 bitAnd(1,1), -- 1 bitAnd(1,2), -- 0 bitAnd(-1,0), -- 0 bitAnd(-1,-2), -- -2 bitAnd(-10,-1), -- -10 bitOr(1,2), -- 3 bitOr(1,0), -- 1 bitOr(2,0), -- 2 bitOr(0,2); -- 2SELECT bitXor(1, 2), bitXor(20, 15), bitNot(2);-- 3 27 253 --十五、Hash函数：可以用于将元素不可逆的伪随机打乱。-- 注意：伪随机！SELECT -- 计算字符串的MD5值。（ 如果您不需要一定使用MD5，请使用‘sipHash64’函数。） halfMD5(&#x27;HELLO WORLD!&#x27;), halfMD5(12);SELECT MD5(&#x27;drew-zero,78967&#x27;);SELECT -- 为任何类型的整数计算32位的哈希。 这是相对高效的非加密Hash函数 intHash32(1221232132132) AS intHash32, -- 推荐：从任何类型的整数计算64位哈希码。 它的工作速度比intHash32函数快。 intHash64(1221232132132) AS intHash64, -- 计算任意数量字符串的CityHash64或使用特定实现的Hash函数计算任意数量其他类型的Hash。 cityHash64(&#x27;username&#x27;) AS cityHash64, -- 1.使用sha1或者sha224加密的话，只能用于字符串 -- 2.字符串 需使用单引号。 SHA1(&#x27;1232131&#x27;) AS sha1, SHA224(&#x27;1232131&#x27;) AS sha224, SHA256(&#x27;DREW-ZERO&#x27;) AS sha256;-- URLHash(url[, N]) 一种快速的非加密哈希函数，用于规范化的从URL获得的字符串-- 从一个字符串计算一个哈希，如果结尾存在尾随符号/，？或#则忽略。 URLHash（s，N） -- 计算URL层次结构中字符串到N级别的哈希值，如果末尾存在尾随符号/，？或#则忽略。 URL的层级与URLHierarchy中的层级相同-- 用处：此函数被用于Yandex.Metrica。SELECT URLHash(&#x27;www.baidu.com&#x27;), -- 11390370829909720855 URLHash(&#x27;www.baidu.com&#x27;, 0), -- 11390370829909720855 -- URLHash(&#x27;www.baidu.com&#x27;, 1); -- 11160318154034397263-- farmHash64(s) 计算字符串的FarmHash64。 接受一个String类型的参数。返回UInt64。SELECT farmHash64(&#x27;www.runoob.com&#x27;); -- 6668483584160323388-- javaHash(s) 计算字符串的JavaHash。 接受一个String类型的参数。返回Int32。SELECT javaHash(&#x27;www.baidu.com&#x27;); -- 270263191-- hiveHash(s) 计算字符串的HiveHash。 接受一个String类型的参数。返回Int32。 与JavaHash相同，但不会返回负数SELECT hiveHash(&#x27;www.baidu.com&#x27;); -- 270263191 --十六、随机函数---&gt;&gt;&gt;&gt;&gt;&gt; 随机函数-- 解释：随机函数使用非加密方式生成【伪随机】数字。-- ① 所有随机函数都只接受一个参数或不接受任何参数。-- ② 您可以向它传递任何类型的参数，但传递的参数将不会使用在任何随机数生成过程中。-- ③ 此参数的唯一目的是防止公共子表达式消除，以便在相同的查询中使用相同的随机函数生成不同的随机数-- rand() 函数：返回一个UInt32类型的随机数字，所有UInt32类型的数字被生成的概率均相等。-- rand64() 函数：返回一个UInt64类型的随机数字，所有UInt64类型的数字被生成的概率均相等。-- randConstant() 函数：返回一个UInt32类型的随机数字，该函数不同之处在于仅为每个数据块参数一个随机数。SELECT rand(), -- 1751687411 rand(10), -- 1124981728 rand64(), rand64(10), randConstant(), randConstant(); -- 十七、编码函数：-- hex(), unhex(), UUIDStringToNum(str), UUIDNumToString(str),bitmaskToList(num) ...-- 1.hex函数编码SELECT -- 68656C6C6F20776F726C64212C68656C6C6F20636C69636B686F757365 hex(&#x27;hello world!,hello clickhouse&#x27;) AS hexStr, hex(now()) AS hexDatetime, -- 5D414BA2 hex(toDate(now())) AS hexDate; --46BC -- 2.接受包含36个字符的字符串，格式为“123e4567-e89b-12d3-a456-426655440000”，并将其转化为FixedString（16）返回SELECT UUIDStringToNum(&#x27;123e4567-e89b-12d3-a456-426655440000&#x27;);-- 3. 接受一个整数。返回一个UInt64类型数组，其中包含一组2的幂列表，其列表中的所有值相加等于这个整数。数组中的数字按升序排列。-- bitmaskToArray(num)SELECT bitmaskToArray(10); -- [2,8]SELECT bitmaskToArray(100); -- [4,32,64]-- 4.接受一个整数。返回一个字符串，其中包含一组2的幂列表，其列表中的所有值相加等于这个整数。列表使用逗号分割，按升序排列。-- bitmaskToList(num) SELECT bitmaskToList(10); -- 2,8SELECT bitmaskToList(100); -- 4,32,64SELECT bitmaskToList(0); -- &#x27;&#x27; 空字符串 --十八、UUID函数---&gt;&gt;&gt;&gt;&gt;&gt; UUID函数-- 1.generateUUIDv4() 返回 UUID类型的值。SELECT generateUUIDv4() as randomUUID; -- 随机生成一个UUIDv4的字符串（b6940dfe-0dc9-4788-bac7-319d13235a2e）SELECT replaceAll(toString(generateUUIDv4()), &#x27;-&#x27;, &#x27;&#x27;) AS replaceUUID; -- 9d1947ea4fcf450da5391feb6142cab6-- 2.toUUID(s) 将string类型的值 转换成UUID类型的值SELECT toUUID(&#x27;61f0c404-5cb3-11e7-907b-a6006ad3dba0&#x27;) AS uuid;-- 3.接受一个String类型的值，其中包含36个字符且格式为xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx，-- 将其转换为UUID的数值并以FixedString(16)将其返回。SELECT &#x27;612f3c40-5d3b-217e-707b-6a546a3d7b29&#x27; AS uuid, -- 612f3c40-5d3b-217e-707b-6a546a3d7b29 UUIDStringToNum(uuid) AS bytes; --a/&lt;@];!~p&#123;jTj=&#123;) -- 4. UUIDNumToString() 接受一个FixedString(16)类型的值，返回其对应的String表现形式。SELECT &#x27;a/&lt;@];!~p&#123;jTj=&#123;)&#x27; AS bytes, UUIDNumToString(toFixedString(bytes, 16)) AS uuid;--- 二十、 URL函数：所有这些功能都不遵循RFC。它们被最大程度简化以提高性能。--- 什么事RFC？---- Request For Comments（RFC），是一系列以编号排定的文件。文件收集了有关互联网相关信息，以及UNIX和互联网社区的软件文件。-- 1. 截取函数：如果URL中没有要截取的内容则返回空字符串。SELECT protocol(&#x27;http://www.baidu.com&#x27;);-- httpSELECT protocol(&#x27;https://www.baidu.com&#x27;);-- httpsSELECT protocol(&#x27;www.baidu.com&#x27;);-- &#x27;&#x27;-- 获取域名。SELECT domain(&#x27;http://www.baidu.com&#x27;); -- www.baidu.comSELECT domain(&#x27;https://www.google.com.cn&#x27;); -- www.google.com.cn-- 返回域名并删除第一个‘www.’SELECT domainWithoutWWW(&#x27;http://www.baidu.com&#x27;);-- baidu.comSELECT domainWithoutWWW(&#x27;www.baidu.com&#x27;);-- &#x27;&#x27;-- 返回顶级域名。例如：.ruSELECT topLevelDomain(&#x27;http://www.runoob.com.cn&#x27;); -- cnSELECT topLevelDomain(&#x27;https://www.huse.edn&#x27;); -- edu-- 返回“第一个有效子域名”-- 如果顶级域名为‘com’，‘net’，‘org’或者‘co’则第一个有效子域名为二级域名。否则则返回三级域名SELECT firstSignificantSubdomain(&#x27;https://news.yandex.com.tr/&#x27;); -- yandex-- 返回包含顶级域名与第一个有效子域名之间的内容(参阅上面内容)SELECT cutToFirstSignificantSubdomain(&#x27;https://news.yandex.com.tr/&#x27;); -- yandex.com.tr-- 返回URL路径SELECT path(&#x27;https://blog.csdn.net/u012111465/article/details/85250030&#x27;);-- /u012111465/article/details/85250030-- 与上面相同，但包括请求参数和fragment。SELECT pathFull(&#x27;https://clickhouse.yandex/#quick-start&#x27;); -- /#quick-start-- 返回请求参数。例如：page=1&amp;lr=213。请求参数不包含问号已经# 以及# 之后所有的内容。SELECT queryString(&#x27;http://www.baidu.com/?page=1&amp;lr=234&#x27;); -- page=1&amp;lr=234 (根据？确定)SELECT queryString(&#x27;http://www.baidu.com/page=1&amp;lr=234&#x27;); -- &#x27;&#x27;-- 返回URL的fragment标识。fragment不包含#。SELECT fragment(&#x27;https://clickhouse.yandex/#quick-start&#x27;); -- quick-start-- 返回请求参数和fragment标识。例如：page=1#29390。SELECT queryStringAndFragment(&#x27;https://www.baidu.com/s?ie=utf-8&amp;rsv_sug7=100#ei-ai&#x27;); -- ie=utf-8&amp;rsv_sug7=100#ei-ai -- 2. 删除URL中的部分内容 (如果URL中不包含指定的部分，则URL不变。)SELECT cutWWW(&#x27;www.baidu.com&#x27;);-- www.baidu.comSELECT cutWWW(&#x27;https://www.baidu.com&#x27;);-- www.baidu.comSELECT cutWWW(&#x27;https://www.baidu.com&#x27;);-- www.baidu.com-- 删除请求参数SELECT cutQueryString(&#x27;http://www.baidu.com/1?page=1&#x27;); -- http://www.baidu.com/1-- 删除fragment标识。#同样也会被删除。SELECT cutFragment(&#x27;http://www.baidu.com/#quick-demo&#x27;); -- http://www.baidu.com/-- 删除请求参数以及fragment标识。问号以及#也会被删除。SELECT cutQueryStringAndFragment(&#x27;http://www.baidu.com/1?page=23#we&#x27;); -- http://www.baidu.com/1-- cutURLParameter(URL, name) 删除URL中名称为‘name’的参数。下面例子中的参数是：&amp;之后，resv,nameSELECT cutURLParameter(&#x27;http://www.baidu.com/1?page=1#erre&amp;resv=23&amp;name=user&#x27;,&#x27;resv&#x27;); --二十一、IP函数 --二十二、条件函数SELECT IF(12 &gt; 10 , 12, 20);SELECT 12 &gt; 10 ? 12 : 10;SELECT if(greater(12, 10), 12, 10); --二十三、操作符函数替换-- clickhouse自带的计算操作符函数（对接mybatis的时候不用将“&lt;”之类的符号转换成 “age1 &lt;![CDATA[ &lt; ]] 2&gt;”）-- 1.等于(注意函数名称的大小，严格区分大小写)SELECT equals(&#x27;hello&#x27;,&#x27;hello&#x27;), -- 1 equals(&#x27;ab&#x27;,&#x27;ba&#x27;); -- 0-- 2.不等于SELECT notEquals(&#x27;a&#x27;,&#x27;b&#x27;), -- 1 notEquals(&#x27;a&#x27;,&#x27;a&#x27;), -- 0 notEquals(12, 12), -- 1 notEquals(12, 1010); -- 0-- 3.大于( 如果前者大于后者，则返回1；否则返回0)SELECT greater(12, 10), -- 1 greater(10, 12), -- 0 greater(12, 12), -- 0 greater(&#x27;b&#x27;,&#x27;a&#x27;), -- 1 greater(&#x27;a&#x27;,&#x27;b&#x27;); -- 0-- 3.1 扩展：提取两者中最大的值SELECT greatest(12,11); -- 12-- 4.小于（如果前者小于后者，则返回1；否则返回0）SELECT less(12,23); -- 1SELECT less(120,23); -- 0-- 5.大于或等于SELECT greaterOrEquals(12,12); -- 1SELECT greaterOrEquals(120,12); -- 1-- 6.小于或等于SELECT lessOrEquals(12,12); -- 1SELECT lessOrEquals(12,129); -- 1-- ===== String操作-- *. a LIKE sSELECT like(&#x27;a&#x27;, &#x27;abcd&#x27;); -- 0SELECT like(&#x27;a&#x27;, &#x27;a&#x27;); -- 1","raw":null,"content":null,"categories":[{"name":"ClickHouse","slug":"ClickHouse","permalink":"https://blog.bosong.online/categories/ClickHouse/"}],"tags":[{"name":"ClickHouse","slug":"ClickHouse","permalink":"https://blog.bosong.online/tags/ClickHouse/"}]},{"title":"MBP外接键盘设置","slug":"MBP外接键盘设置","date":"2021-03-16T05:52:26.000Z","updated":"2022-06-02T01:05:59.613Z","comments":true,"path":"MBP外接键盘设置.html","link":"","permalink":"https://blog.bosong.online/MBP%E5%A4%96%E6%8E%A5%E9%94%AE%E7%9B%98%E8%AE%BE%E7%BD%AE.html","excerpt":"","text":"","raw":null,"content":null,"categories":[{"name":"Macos","slug":"Macos","permalink":"https://blog.bosong.online/categories/Macos/"}],"tags":[{"name":"Macos","slug":"Macos","permalink":"https://blog.bosong.online/tags/Macos/"}]},{"title":"Github进行fork后如何与原仓库同步","slug":"Github进行fork后如何与原仓库同步","date":"2021-03-09T11:33:23.000Z","updated":"2022-06-02T01:05:59.612Z","comments":true,"path":"Github进行fork后如何与原仓库同步.html","link":"","permalink":"https://blog.bosong.online/Github%E8%BF%9B%E8%A1%8Cfork%E5%90%8E%E5%A6%82%E4%BD%95%E4%B8%8E%E5%8E%9F%E4%BB%93%E5%BA%93%E5%90%8C%E6%AD%A5.html","excerpt":"前言  近期使用github给baidu&#x2F;brcc提交pr，然后发现提完pr以后我如果再次修改并且baidu&#x2F;brcc有其他人的更新，我的fork仓库无法同步，所以找了一些最佳实践，在此进行总结。\n实现方案一般情况下，这种情况有两种做法：\n\n将fork的仓库在你的github上删除掉，然后重新fork\n通过git命令将原代码进行同步到你的代码中\n\n实际上在github的操作中都是merge 与 merge的操作，在你只需要和原代码保持一致的情况下，可以采用第二种方案进行同步\n","text":"前言 近期使用github给baidu&#x2F;brcc提交pr，然后发现提完pr以后我如果再次修改并且baidu&#x2F;brcc有其他人的更新，我的fork仓库无法同步，所以找了一些最佳实践，在此进行总结。 实现方案一般情况下，这种情况有两种做法： 将fork的仓库在你的github上删除掉，然后重新fork 通过git命令将原代码进行同步到你的代码中 实际上在github的操作中都是merge 与 merge的操作，在你只需要和原代码保持一致的情况下，可以采用第二种方案进行同步 实践步骤通过git命令将原代码同步到我fork的代码仓库中，使用merge的方法来进行操作。下面是具体的操作命令，以brcc仓库为例. 1、进入到我的本地仓库中： 1cd ~/github-me/brcc/ 2、执行命令 git remote -v 查看远程仓库的地址初始情况下，执行完命令只会存在如下两条记录 123➜ brcc git:(main) git remote -v origin git@github.com:dislazy/brcc.git (fetch)origin git@github.com:dislazy/brcc.git (push) 3、执行命令 git remote add upstream git@github.com:baidu/brcc.git 给当前仓库添加 上游仓库(upstream)添加完上游仓库之后再次执行git remote -v ，就可以看到当前的代码仓库出现了四条记录 12345➜ brcc git:(main) git remote -v origin git@github.com:dislazy/brcc.git (fetch)origin git@github.com:dislazy/brcc.git (push)upstream git@github.com:baidu/brcc.git (fetch)upstream git@github.com:baidu/brcc.git (push) 4、执行命令 git status 查看自己存不存在当前分支下已修改未提交的，如果有的话可以提交到你的当前分支去(前提是你的代码不是主分支) 12345➜ brcc git:(main) git statusOn branch mainYour branch is up to date with &#x27;origin/main&#x27;.nothing to commit, working tree clean 5、执行命令 git fetch upstream 抓取 baidu&#x2F;brcc 原仓库的更新 12345678➜ brcc git:(main) git fetch upstream remote: Enumerating objects: 136, done.remote: Counting objects: 100% (110/110), done.remote: Compressing objects: 100% (45/45), done.remote: Total 82 (delta 32), reused 63 (delta 14), pack-reused 0Unpacking objects: 100% (82/82), 7.48 KiB | 134.00 KiB/s, done.From github.com:baidu/brcc * [new branch] main -&gt; upstream/main 6、如果你的代码不是主分支，那么执行命令 git checkout main 切换到代码主分支 123➜ brcc git:(main) git checkout mainAlready on &#x27;main&#x27;Your branch is up to date with &#x27;origin/main&#x27;. 7、最关键命令 git merge upstream/main，将原代码的主分支代码merge到你的fork仓库主分支上 123456789101112131415161718➜ brcc git:(main) git merge upstream/main Updating f8099cb..a5d4533Fast-forward .codecov.yml | 6 +- README.md | 178 ++++++++++++++++++++++++++++---------------------------- brcc-cache/src/test/java/com/baidu/brcc/SampleTest.java | 41 ------------- brcc-example/src/test/java/com/baidu/brcc/example/ApplicationTest.java | 31 ---------- brcc-sdk-starter/pom.xml | 2 +- brcc-sdk/pom.xml | 2 +- brcc-sdk/src/test/java/com/baidu/brcc/ConfigChangedListenerTest.java | 2 +- brcc-sdk/src/test/java/com/baidu/brcc/spring/ConfigCenterPropertyPlaceholderConfigurerTest.java | 2 +- brcc-server/src/test/java/com/baidu/brcc/RccApplicationTest.java | 30 ---------- doc/java-sdk-guide.md | 11 +++- 10 files changed, 106 insertions(+), 199 deletions(-) delete mode 100644 brcc-cache/src/test/java/com/baidu/brcc/SampleTest.java delete mode 100644 brcc-example/src/test/java/com/baidu/brcc/example/ApplicationTest.java delete mode 100644 brcc-server/src/test/java/com/baidu/brcc/RccApplicationTest.java 8、经过上面一步，已经将对应的原仓库代码同步到你的fork仓库中了，此时执行git push即可完成操作 1234➜ brcc git:(main) git push Total 0 (delta 0), reused 0 (delta 0), pack-reused 0To github.com:dislazy/brcc.git f8099cb..a5d4533 main -&gt; main 经过以上8个步骤，已经成功的将fork仓库的代码和原代码保持一致了，如果需要再次提pr，后期按照此步骤操作即可。","raw":null,"content":null,"categories":[{"name":"Github","slug":"Github","permalink":"https://blog.bosong.online/categories/Github/"}],"tags":[{"name":"git","slug":"git","permalink":"https://blog.bosong.online/tags/git/"},{"name":"Github","slug":"Github","permalink":"https://blog.bosong.online/tags/Github/"}]},{"title":"Github-pr最佳实践","slug":"Github-pr最佳实践","date":"2021-03-09T11:32:25.000Z","updated":"2022-06-02T01:05:59.612Z","comments":true,"path":"Github-pr最佳实践.html","link":"","permalink":"https://blog.bosong.online/Github-pr%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5.html","excerpt":"Pull Request在github中的作用\n主要是用来做代码reivew\n从开发分支合并到环境分支\n控制不同级别人员对于分支内容的提交\n\nPull Request在github中的三种合并分支的方法一、merge 合并1、特点\n\nmerge是指将开发分支的代码merge到目标分支\nmerge会产生一条对应的merge记录\nmerge会存在代码覆盖情况，如果产生冲突需要手动解决2、适用场景\n适用于不同分支向不同目标分支合并代码的所有场景\n\n二、squashing 压缩合并1、特点\n\nsquashing 会将开发分支中的代码commit合并为一个综合的commit\nsquashing 会将综合的commit作为一次commitmerge到目标分支中\nsquashing 如果存在多分支之间切换的情况，会出现多次综合性的commit中出现重复的提交2、适用场景\n适用于不同开发分支向同一目标分支合并代码的场景\n\n三、rebase 变基合并1、特点\n\nrebase 变基是将用户的commit插入到目标分支合适的位置\nrebase和merge是不同的合并方式，它类似于cherry pick2、适用场景\n适用于多人在同一分支各自进行本地开发场景\n不适用与分支间merge\n\n","text":"Pull Request在github中的作用 主要是用来做代码reivew 从开发分支合并到环境分支 控制不同级别人员对于分支内容的提交 Pull Request在github中的三种合并分支的方法一、merge 合并1、特点 merge是指将开发分支的代码merge到目标分支 merge会产生一条对应的merge记录 merge会存在代码覆盖情况，如果产生冲突需要手动解决2、适用场景 适用于不同分支向不同目标分支合并代码的所有场景 二、squashing 压缩合并1、特点 squashing 会将开发分支中的代码commit合并为一个综合的commit squashing 会将综合的commit作为一次commitmerge到目标分支中 squashing 如果存在多分支之间切换的情况，会出现多次综合性的commit中出现重复的提交2、适用场景 适用于不同开发分支向同一目标分支合并代码的场景 三、rebase 变基合并1、特点 rebase 变基是将用户的commit插入到目标分支合适的位置 rebase和merge是不同的合并方式，它类似于cherry pick2、适用场景 适用于多人在同一分支各自进行本地开发场景 不适用与分支间merge pull Request在github上pr的实践没有最好的实践，只有最合适的实践。在不同分支向不同目标分支合并代码的场景实际是merge合并方法比较适用，在代码review时不会将已有的代码进行提交","raw":null,"content":null,"categories":[{"name":"Github","slug":"Github","permalink":"https://blog.bosong.online/categories/Github/"}],"tags":[{"name":"git","slug":"git","permalink":"https://blog.bosong.online/tags/git/"},{"name":"Github","slug":"Github","permalink":"https://blog.bosong.online/tags/Github/"}]},{"title":"Mac使用Vim快捷键","slug":"mac使用Vim快捷键","date":"2021-02-07T10:43:17.000Z","updated":"2022-06-02T01:05:59.615Z","comments":true,"path":"mac使用Vim快捷键.html","link":"","permalink":"https://blog.bosong.online/mac%E4%BD%BF%E7%94%A8Vim%E5%BF%AB%E6%8D%B7%E9%94%AE.html","excerpt":"一、移动光标\n移动到行尾”$”，移动到行首”0”(数字)，移动到行首第一个字符处”^”\n\n移动到段首”{“，移动到段尾”}”\n\n移动到下一个词”w”，移动到上一个词”b”\n\n移动到文档开始”gg”，移动到文档结束”G”\n\n跳到第n行”ngg” 或 “nG” 或 “:n”\n\n移动光标到屏幕顶端”H”，移动到屏幕中间”M”，移动到底部”L”\n\n\n二、编辑操作\n光标后插入”a”, 行尾插入”A”\n\n后插一行插入”o”，前插一行插入”O”\n\n删除字符插入”s”， 删除正行插入”S”\n\n光标前插入”i”，行首插入”I”\n\n删除一行”dd”，删除后进入插入模式”cc”或者”S”\n\n删除一个单词”dw”，删除一个单词进入插入模式”cw”\n\n删除一个字符”x”或者”dl”，删除一个字符进入插入模式”s”或者”cl”\n\n粘贴”p”，交换两个字符”xp”\n\n交换两行”ddp”\n\n复制”y”，复制一行”yy”\n\n拷贝当前行 “yy”或者”Y”\n\n撤销”u”，重做”ctrl + r”\n\n删除到行尾可以使用”D”或”C”\n\n删除当前字符 “x”\n\n“ &gt;&gt;”缩进所有选择的代码\n\n“&lt;&lt;” 反缩进所有选择的代码\n\n合并两行” J”\n\n若不想保存文件，而重新打开”:e!”\n\n若想打开新文件 “:e filename”，然后使用”ctrl + ^”进行文件切换\n\n\n","text":"一、移动光标 移动到行尾”$”，移动到行首”0”(数字)，移动到行首第一个字符处”^” 移动到段首”{“，移动到段尾”}” 移动到下一个词”w”，移动到上一个词”b” 移动到文档开始”gg”，移动到文档结束”G” 跳到第n行”ngg” 或 “nG” 或 “:n” 移动光标到屏幕顶端”H”，移动到屏幕中间”M”，移动到底部”L” 二、编辑操作 光标后插入”a”, 行尾插入”A” 后插一行插入”o”，前插一行插入”O” 删除字符插入”s”， 删除正行插入”S” 光标前插入”i”，行首插入”I” 删除一行”dd”，删除后进入插入模式”cc”或者”S” 删除一个单词”dw”，删除一个单词进入插入模式”cw” 删除一个字符”x”或者”dl”，删除一个字符进入插入模式”s”或者”cl” 粘贴”p”，交换两个字符”xp” 交换两行”ddp” 复制”y”，复制一行”yy” 拷贝当前行 “yy”或者”Y” 撤销”u”，重做”ctrl + r” 删除到行尾可以使用”D”或”C” 删除当前字符 “x” “ &gt;&gt;”缩进所有选择的代码 “&lt;&lt;” 反缩进所有选择的代码 合并两行” J” 若不想保存文件，而重新打开”:e!” 若想打开新文件 “:e filename”，然后使用”ctrl + ^”进行文件切换 三、简单配置到用户目录下新建文件为 .vimrc，然后在其中写下如下配置 1234567syntax enable //语法高亮 set number //显示行号set cursorline //突出显示当前行set ruler //打开状态栏标尺set shiftwidth=4 //设定 &lt;&lt; 和 &gt;&gt; 命令移动时的宽度为 4set softtabstop=4 //使得按退格键时可以一次删掉 4 个空格set tabstop=4 //设定 tab 长度为 4","raw":null,"content":null,"categories":[{"name":"Macos","slug":"Macos","permalink":"https://blog.bosong.online/categories/Macos/"}],"tags":[{"name":"Macos","slug":"Macos","permalink":"https://blog.bosong.online/tags/Macos/"}]},{"title":"好看又好用并且安全的密码管理工具","slug":"好看又好用并且安全的密码管理工具","date":"2020-10-09T15:51:10.000Z","updated":"2022-06-02T01:05:59.617Z","comments":true,"path":"好看又好用并且安全的密码管理工具.html","link":"","permalink":"https://blog.bosong.online/%E5%A5%BD%E7%9C%8B%E5%8F%88%E5%A5%BD%E7%94%A8%E5%B9%B6%E4%B8%94%E5%AE%89%E5%85%A8%E7%9A%84%E5%AF%86%E7%A0%81%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7.html","excerpt":"为什么要使用密码管理工具在日常的生活中，尤其是现在发达的网络环境下，每个人都在大量的网站注册了大量的账号，除却QQ登录、微信登录等登录方式之外，绝大部分网站都支持使用账号密码登录，一旦账号多了,密码多了，发现记录密码是一件非常麻烦的事，又不敢明文保存，还经常需要用到，此时密码管理工具的作用就凸显出来了。","text":"为什么要使用密码管理工具在日常的生活中，尤其是现在发达的网络环境下，每个人都在大量的网站注册了大量的账号，除却QQ登录、微信登录等登录方式之外，绝大部分网站都支持使用账号密码登录，一旦账号多了,密码多了，发现记录密码是一件非常麻烦的事，又不敢明文保存，还经常需要用到，此时密码管理工具的作用就凸显出来了。 什么密码管理工具好用之前自己使用过keepPass的开源版，它的理念是把账号密码的数据存储在本地，起到了安全性的作用，但是这样就造成了自己有多台电脑的时候，同步密码就成了一件非常费力的事情。 在百度上搜索好用的密码管理工具，基本上无外乎KeepPass、LastPass、1Password等，好评比较高的有LastPass，但是它数据是存储在云端，但是我们知道网络上别人的数据库是不可靠的，但是那个时候没有找到能取代它的好用的工具。 直到有一天搜到了一款密码管理工具：bitwarden，相信很多人没有听说过它，一旦使用之后才发现它的强大。 为什么好用bitwarden我比较喜欢的点有三个： 界面简洁，全中文 自己搭建服务，数据完全存储在自建数据库中 有完备的设备支持：win、macos、移动端还包括网页插件，全终端数据可同步 如何搭建一个自己的bitwarden服务官方有提供的bitwarden服务，可以参照官方链接进行下载并且安装，然后使用域名进行反向代理，最快最方便的方式是使用docker容器启动一个服务，然后使用反向代理进行绑定域名对外提供服务即可。 还可以使用开源的使用rust实现的bitwarden服务，查看 WIKI，它支持多种数据库存储：Mysql、PostgreSql，并且支持企业LDAP登录等等功能，真的是给人太多惊喜，不仅适合个人使用并且企业用起来也会非常的合适。 docker搭建bitwarden脚本我自己搭建的bitwarden服务是基于最新的版本，依赖于自建的Mysql数据库做数据存储，脚本如下： 1234567docker run -d --name bitwarden \\-e SIGNUPS_ALLOWED=false \\-v /data/bw:/data/ \\-p 2230:80 \\-e DATABASE_URL=&#x27;mysql://root:密码@地址：端口/bitwarden&#x27; \\-e ENABLE_DB_WAL=&#x27;false&#x27; \\bitwardenrs/server-mysql:latest 1SIGNUPS_ALLOWED 这个参数比较特殊,当你第一次部署的时候可以将其设置为true,代表允许用户注册，当注册完用户之后，不想对外公开，可以将该参数设置为false再次启动即可 搭建服务完成之后如何使用搭建完bitwarden服务之后，直接访问到对应的服务地址，注册一个账号，即可使用网页版的bitwarden密码管理工具，但是这不是我们最终的目的哦，最终的目的是为了让它充分发挥作用，在我们需要输入账号密码的时候直接就能帮助我们输入对应的账号密码。 以chrome举例，有条件翻墙的可以直接到Chrome应用商店搜索bitwarden，安装对应插件之后，点开插件，在左上角有对应图片设置对应的服务地址，然后使用在网页端注册的账号之后就可以了，它可以存储密码，也可以存储TOTP密钥，用来获取动态密码 结语经过一段的时间的使用确实爱上了这款密码管理工具，方便并且数据存储相对安全。更多好用的功能点，等待你来get哦。","raw":null,"content":null,"categories":[{"name":"技术手册","slug":"技术手册","permalink":"https://blog.bosong.online/categories/%E6%8A%80%E6%9C%AF%E6%89%8B%E5%86%8C/"}],"tags":[{"name":"docker","slug":"docker","permalink":"https://blog.bosong.online/tags/docker/"},{"name":"密码管理工具","slug":"密码管理工具","permalink":"https://blog.bosong.online/tags/%E5%AF%86%E7%A0%81%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/"}]},{"title":"HashMap浅谈-基本方法","slug":"HashMap浅谈-基本方法","date":"2020-06-24T12:30:36.000Z","updated":"2022-06-02T01:05:59.613Z","comments":true,"path":"HashMap浅谈-基本方法.html","link":"","permalink":"https://blog.bosong.online/HashMap%E6%B5%85%E8%B0%88-%E5%9F%BA%E6%9C%AC%E6%96%B9%E6%B3%95.html","excerpt":"HashMap的初始化过程HashMap的初始化有两种方法：","text":"HashMap的初始化过程HashMap的初始化有两种方法： 直接使用HashMap的无参构造方法，此时初始化的容量为：DEFAULT_LOAD_FACTOR 也就是16 1234567/** * Constructs an empty &lt;tt&gt;HashMap&lt;/tt&gt; with the default initial capacity * (16) and the default load factor (0.75). */ public HashMap() &#123; this.loadFactor = DEFAULT_LOAD_FACTOR; // all other fields defaulted &#125; 传入容量参数的有参构造方法，此时的初始化容量需要进行计算 12345678910/** * Constructs an empty &lt;tt&gt;HashMap&lt;/tt&gt; with the specified initial * capacity and the default load factor (0.75). * * @param initialCapacity the initial capacity. * @throws IllegalArgumentException if the initial capacity is negative. */public HashMap(int initialCapacity) &#123; this(initialCapacity, DEFAULT_LOAD_FACTOR);&#125; ​ 上一文中提到，HashMap的容量必须为2的幂次方，但是不是所有的同学在创建Map的时候都会遵守这个规则，在这种情况下，HashMap也会对传入的参数进行校准，规则是将 参数值转换为最接近、且大于等于指定参数的 2 的 幂次方的值，它确保了HashMap不管是在初始化时，或者在扩容时，它的容量一直保持的是2的幂次方的值，具体方法可以参考： 123456789101112/** * Returns a power of two size for the given target capacity. */static final int tableSizeFor(int cap) &#123; int n = cap - 1; n |= n &gt;&gt;&gt; 1; n |= n &gt;&gt;&gt; 2; n |= n &gt;&gt;&gt; 4; n |= n &gt;&gt;&gt; 8; n |= n &gt;&gt;&gt; 16; return (n &lt; 0) ? 1 : (n &gt;= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1;&#125; HashMap的基本方法及原理put方法 put方法是HashMap的一个基本方法，它的算法也是非常的复杂的，涉及到了单个节点、链表节点、红黑树节点，容量达到阈值时的自动扩容等。 它的原理主要包括下面几个方面： HashMap的扩容阈值，以及扩容过程 扩容阈值 &#x3D; 当前容量 * 扩容因子 扩容基本上分为几步： 1、创建一个为原来两倍大的数组 2、复制原有数组的数据，该转化为链表的转化为链表，该转化为红黑树的转化为红黑树 插入键值对时如何确定落在哪个桶中（它虽然是个数组，但不是纯粹的数组） 1234567891011121314151617181920 /** * Computes key.hashCode() and spreads (XORs) higher bits of hash * to lower. Because the table uses power-of-two masking, sets of * hashes that vary only in bits above the current mask will * always collide. (Among known examples are sets of Float keys * holding consecutive whole numbers in small tables.) So we * apply a transform that spreads the impact of higher bits * downward. There is a tradeoff between speed, utility, and * quality of bit-spreading. Because many common sets of hashes * are already reasonably distributed (so don&#x27;t benefit from * spreading), and because we use trees to handle large sets of * collisions in bins, we just XOR some shifted bits in the * cheapest possible way to reduce systematic lossage, as well as * to incorporate impact of the highest bits that would otherwise * never be used in index calculations because of table bounds. */static final int hash(Object key) &#123; int h; return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16); &#125; ​ HashMap在计算hash值时，会将 hashCode 做一次16位右位移，然后将右移的结果和 hashCode 做异或运算，减少Hash碰撞的次数，然后将获取的值存储到对应的hash值的桶中 键值的唯一性的保证机制 12if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) ​ 在java.util.HashMap#putVal中存在这样一段代码，当key的hash值相同并且key的内存位置相同或者key的值相同时，可以确认是同一个key，此时会根据条件来判断是直接将原来的key对应的value替换还是做其他的操作，以此来保证键值的唯一性。 ​ 此处也有一定的坑，因为有一个 &#x3D;&#x3D; 当传入的键值为引用对象时，如果没有重写引用对象的hashCode()方法，会导致同样参数的对象被认为是不同的键值，因为如果不重写hashCode()方法时，那么它就继承的是Object的hashCode()方法，Object的hashCode方法获取到的hashCode对每个对象来说都是唯一的， 可以查看下面的例子 1234567891011121314151617181920static class HashKey &#123; /** * Id */ private Integer id; /** * hashKey */ private String hashKey; ... &#125; public static void main(String[] args) &#123; Map&lt;HashKey,String&gt; map = new HashMap&lt;&gt;(); HashKey a = new HashKey(1,&quot;10086&quot;); HashKey b = new HashKey(1,&quot;10086&quot;); map.put(a,&quot;1&quot;); map.put(b,&quot;1&quot;); System.out.println(JSON.toJSONString(map)); &#125; 输出结果：&#123;&#123;&quot;hashKey&quot;:&quot;10086&quot;,&quot;id&quot;:1&#125;:&quot;1&quot;,&#123;&quot;hashKey&quot;:&quot;10086&quot;,&quot;id&quot;:1&#125;:&quot;1&quot;&#125; 所以，如果使用对象做键值对的键值的话，一定记得重写HashCode()方法 12345@Override public int hashCode() &#123; return Objects.hash(id, hashKey); &#125; 输出结果：&#123;&#123;&quot;hashKey&quot;:&quot;10086&quot;,&quot;id&quot;:1&#125;:&quot;1&quot;&#125; 发生hash碰撞（不同的键值hash值相同）时的处理机制 虽然在hash值的计算上都是在极力避免出现hash碰撞的情况，但是hash碰撞还是有可能会发生，那么当hash值相同但是键值不同的键值对该如何存放呢，分为两种情况： 1、在当前的hash对应的bin下面会创建成一个长度不超过8的链表 2、当链表长度大于等于8的时候，会转化红黑树，因为红黑树的查询效率是非常高的，但是占用空间会比链表大，典型的使用空间换时间，但是换的物超所值 单节点拉链法的实现过程 123456static class Node&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; &#123; final int hash; final K key; V value; Node&lt;K,V&gt; next; &#125; ​ 代码中的next就是下一个节点，当最后一个节点next为null时，代表着这个链表结束了。 值得注意的是在JDK7之前链表使用的是头插法（不是使用的Node),当两个线程在执行resize()方法的时候可能会产生环形链表，在调用get()方法会死循环，导致OOM 链表转化为红黑树的方法过程 ​ 当链表的长度达到8时，已经是一个相对比较长的结构了，这时候查询的效率会随着链表的数量增长而降低，此时为了追求性能最大化，就会将链表转化为红黑树，这时候会产生一个问题：红黑树既然查询效率足够的高，为什么不直接采用红黑树的结构而使用链表达到8时才转变呢？ 这个其实也是有原因的，在一定的范围内，用空间换取时间效率是可取的，当链表长度比较短时，转变成红黑树，空间结构变大了，但是此时查询效率并没有因此而提高，反而得不偿失了，所以当链表达到阈值时来使用红黑树是相对比较划算的一种方案。 get方法 ​HashMap设计的最主要原因就是为了提高查询效率，get方法是使用的最频繁的一个方法之一，它主要就是靠hash算法获取的值来快速定位到索引，然后返回对应的索引对应值。 1234567891011121314151617181920212223242526/** * Implements Map.get and related methods. * * @param hash hash for key * @param key the key * @return the node, or null if none */ final Node&lt;K,V&gt; getNode(int hash, Object key) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; first, e; int n; K k; if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (first = tab[(n - 1) &amp; hash]) != null) &#123; if (first.hash == hash &amp;&amp; // always check first node ((k = first.key) == key || (key != null &amp;&amp; key.equals(k)))) return first; if ((e = first.next) != null) &#123; if (first instanceof TreeNode) return ((TreeNode&lt;K,V&gt;)first).getTreeNode(hash, key); do &#123; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) return e; &#125; while ((e = e.next) != null); &#125; &#125; return null; &#125; ​ get方法主要包含以下几个过程 ​ 1、获取key的hash计算参数 ​ 2、查找对应索引位置 ​ 3、如果是单节点Node直接返回Node,如果是链表Node在链表中获取Node节点，如果是红黑树节点，那么调用红黑树的查询方法快速找到Node并且返回 remove方法12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152```java /** * Implements Map.remove and related methods. * * @param hash hash for key * @param key the key * @param value the value to match if matchValue, else ignored * @param matchValue if true only remove if value is equal * @param movable if false do not move other nodes while removing * @return the node, or null if none */ final Node&lt;K,V&gt; removeNode(int hash, Object key, Object value, boolean matchValue, boolean movable) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, index; if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (p = tab[index = (n - 1) &amp; hash]) != null) &#123; Node&lt;K,V&gt; node = null, e; K k; V v; if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) node = p; else if ((e = p.next) != null) &#123; if (p instanceof TreeNode) node = ((TreeNode&lt;K,V&gt;)p).getTreeNode(hash, key); else &#123; do &#123; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) &#123; node = e; break; &#125; p = e; &#125; while ((e = e.next) != null); &#125; &#125; if (node != null &amp;&amp; (!matchValue || (v = node.value) == value || (value != null &amp;&amp; value.equals(v)))) &#123; if (node instanceof TreeNode) ((TreeNode&lt;K,V&gt;)node).removeTreeNode(this, tab, movable); else if (node == p) tab[index] = node.next; else p.next = node.next; ++modCount; --size; afterNodeRemoval(node); return node; &#125; &#125; return null; &#125;``` remove()方法也是个比较特殊的方法，它的作用和put()是完全相反的，基本也分为以下几个过程： 1、如果是单节点Node，那么直接将对应的Node设置为Null 2、如果是链表Node，那么将该Node删除的同时，将它前一个Node的next替换为后一个Node，保证链表的连续性 3、如果是红黑树Node，那么就需要调用红黑树的删除节点方法进行删除了，此时如果红黑树的Node值为2-6个时，会调方法转化为链表结构的Node 总结HashMap是一个数组，但它是一个特殊的数组，包含了多种结构单元：单节点Node、Node链表、红黑树，根据实际情况互相转化，因为它的特殊性，造就了它超高的查询效率，O(1) 级别的查询效率，直接根据对应索引的位置找到对象并返回 HashMap的容量也是有规律的，为了结构的稳定性以及保障索引的散列计算更加均匀，它的容量必须是2的幂次方，即使是没有传正确的容量参数，也是会进行校准的 HashMap的扩容是达到一定阈值后会进行两倍放大，创建一个新的数组，将原来对象进行复制，并且会对单节点类型的元素重新计算他们的索引位置，如果是红黑树的话，会根据红黑树特有的方法进行扩容，在红黑树与链表之间进行动态转化 HashMap和List、Set等集合一样，不是线程安全的，它在多线程情况是不具备线程安全特性的，如果同时有多个put或者多个remove会对它的数据造成比较大的影响，多线程环境下不推荐使用HashMap，它在多线程环境的替代是ConcurrentHashMap,关于ConcurrentHashMap有时间的还可以深入了解一下。","raw":null,"content":null,"categories":[{"name":"Java","slug":"Java","permalink":"https://blog.bosong.online/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://blog.bosong.online/tags/Java/"}]},{"title":"HashMap浅谈-基本原理","slug":"HashMap浅谈-基本原理","date":"2020-06-22T14:27:40.000Z","updated":"2022-06-02T01:05:59.612Z","comments":true,"path":"HashMap浅谈-基本原理.html","link":"","permalink":"https://blog.bosong.online/HashMap%E6%B5%85%E8%B0%88-%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86.html","excerpt":"HashMap的组成HashMap的内部实现是一个数组，但是它是一个特殊的数组。如下图所示：","text":"HashMap的组成HashMap的内部实现是一个数组，但是它是一个特殊的数组。如下图所示： HashMap的内部结构HashMap是一个特殊的数组实现，它的数据插入并不是按照顺序逐个写入的，而是按照一种特定算法来确定写入的位置， 然后将对象进行写入，它就是散列计算，就是计算出当前key的hash值，然后对hash值做一定的操作，再计算出当前的hash对应的是哪个桶，然后再将对应的输入写入到桶内（栗子：上图中的Node1节点） 当存在同hash值时，同一个桶内的数据会采用拉链法来使桶内的数据形成一个链表结构，这样同hash的值都会保存并且不会覆盖。 当链表长度达到一定的阈值时（阈值：8），为了提高它的性能，此时会将链表转化为红黑树进行存储（栗子:上图中的Node2节点） HashMap的核心概念 HashMap的存储结构 HashMap的底层实现是一个数组,源码如下： 1234567/** * The table, initialized on first use, and resized as * necessary. When allocated, length is always a power of two. * (We also tolerate length zero in some operations to allow * bootstrapping mechanics that are currently not needed.) */ transient Node&lt;K,V&gt;[] table; HashMap的存储节点 HashMap在存储时是一个table,它在正常情况下的基础元素组成是一个Node 12345678910/** * Basic hash bin node, used for most entries. (See below for * TreeNode subclass, and in LinkedHashMap for its Entry subclass.) */ static class Node&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; &#123; final int hash; final K key; V value; Node&lt;K,V&gt; next; &#125; table在链表长度达到8或者8以上时，会转化为红黑树，变成了一个TreeNode 123456789101112/** * Entry for Tree bins. Extends LinkedHashMap.Entry (which in turn * extends Node) so can be used as extension of either regular or * linked node. */static final class TreeNode&lt;K,V&gt; extends LinkedHashMap.Entry&lt;K,V&gt; &#123; TreeNode&lt;K,V&gt; parent; // red-black tree links TreeNode&lt;K,V&gt; left; TreeNode&lt;K,V&gt; right; TreeNode&lt;K,V&gt; prev; // needed to unlink next upon deletion boolean red; &#125; HashMap的容量 HashMap的容量指的是它的table长度，也就是bin(桶)的数量，当桶的数量达到阈值时，它会扩充容量。 容量值的初始化数值必须是2的幂次方，它的最大容量是2的30次方。当传入的容量值不为2的幂次方时，它会自动转化为大于当前数值的最近的2的幂次方。 table长度定义： 12345678910/** * The next size value at which to resize (capacity * load factor). * * @serial */// (The javadoc description is true upon serialization.// Additionally, if the table array has not been allocated, this// field holds the initial array capacity, or zero signifying// DEFAULT_INITIAL_CAPACITY.)int threshold; 负载因子定义： 负载因子是一个系数，它与容量参数结合使用，一般不会进行改动，它的默认值是： 1234/** * The load factor used when none specified in constructor. */static final float DEFAULT_LOAD_FACTOR = 0.75f; 阈值计算公式： 1阈值 = threshold * DEFAULT_LOAD_FACTOR; 如果当前的容量是1024，那么它的阈值就是1024*0.75&#x3D;768,当当前HashMap的实际使用容量达到了768时，它会触发扩容操作，扩容的大小为当前容量的两倍大小：2048。 扩容计算公式： 容量 &#x3D; 当前容量 * 2 扩容原理： 扩容时，会创建一个2当前容量2倍大数组，然后将原来的数组内容copy进新的数组中，将table替换为新的数组，此时就达到了扩容的目的。4. HashMap的元素个数 在HaspMap中，它的容量不等同于元素个数，它的元素个数定义是： 1234/** * The number of key-value mappings contained in this map. */transient int size; 注意的点Java7之前和Java8之后的扩容机制是不一致的Java7之前，扩容的因素需要满足两个条件： 1、当前的键值对数量大于当前阈值 2、新增加的键值对发送了hash碰撞 此时会出现两种情况（默认的容量为16） 1、当键值对数量在16时，才会触发扩容机制，此时的情况是前16个元素都没有发生hash碰撞，全部都放置在不同的桶中，到第17个元素插入时，才会完全满足以上两个条件，触发扩容 2、键值对可能在达到26个时，才会触发扩容机制，此时的情况是前11个元素全部发送了hash碰撞，存储在同一个桶中，后面的15个元素全部都没有发生hash碰撞，到第27个元素插入时才会满足以上两个条件，触发扩容 Java8之后，扩容的因素只需要满足一个条件 1、当前插入的元素为新值（不包括同键值，但是值不同的情况），并且已有键值对个数达到阈值时 Node的引入是在Java8之后Java7之前的节点是Entry,它的结构桶结构除了单节点就是链表，没有红黑树 在Java8之后的节点发生了改变，使用Node节点，在Node节点数为8以下的形成链表，当到达8时，会转变成红黑树结构，提高查询效率 HashMap的查询效率HashMap的查询效率是O(1)，查询非常快","raw":null,"content":null,"categories":[{"name":"Java","slug":"Java","permalink":"https://blog.bosong.online/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://blog.bosong.online/tags/Java/"}]},{"title":"nginx配置https和跨域设置","slug":"Nginx配置https和跨域设置","date":"2020-04-19T00:11:53.000Z","updated":"2022-06-02T01:05:59.614Z","comments":true,"path":"Nginx配置https和跨域设置.html","link":"","permalink":"https://blog.bosong.online/Nginx%E9%85%8D%E7%BD%AEhttps%E5%92%8C%E8%B7%A8%E5%9F%9F%E8%AE%BE%E7%BD%AE.html","excerpt":"为了网站快速响应，经常需要将前端页面放在cdn上，此时就需要后端服务支持跨域访问，所以\n记录一下在tengine上的配置，用于集中管理多个服务和支持服务的跨域访问设置。关于nginx的安装可以参照 https://blog.bosong.online/Linux%E5%AE%89%E8%A3%85Nginx.html","text":"为了网站快速响应，经常需要将前端页面放在cdn上，此时就需要后端服务支持跨域访问，所以 记录一下在tengine上的配置，用于集中管理多个服务和支持服务的跨域访问设置。关于nginx的安装可以参照 https://blog.bosong.online/Linux%E5%AE%89%E8%A3%85Nginx.html 第一步 将配置文件进行分离使用vi nginx.conf编辑nginx的配置文件，改成如下配置 12345678910111213141516171819202122232425262728293031323334353637#user nobody;worker_processes 1;error_log logs/error.log;error_log logs/error.log notice;error_log logs/error.log info;error_log &quot;pipe:rollback logs/error_log interval=1d baknum=7 maxsize=2G&quot;;pid logs/nginx.pid;events &#123; worker_connections 1024; #根据实际情况进行修改&#125;http &#123; include mime.types; default_type application/octet-stream; #设置日志格式 log_format main &#x27;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &#x27; &#x27;$status $body_bytes_sent &quot;$http_referer&quot; &#x27; &#x27;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&#x27;; //对日志进行设置 access_log &quot;pipe:rollback logs/access_log interval=1d baknum=7 maxsize=2G&quot; main; sendfile on; keepalive_timeout 65; server_names_hash_bucket_size 128; client_header_buffer_size 32k; large_client_header_buffers 4 32k; client_max_body_size 8m; tcp_nopush on; gzip on; //将所有的后端服务的配置都放在domain文件夹中管理 include domain/*.conf;&#125; 第二步 创建单独的配置文件，以nacos.conf为例在nginx/conf文件夹下创建domain 和 cert文件夹，然后将nacos.conf放入domain&#96;文件夹中 domain 存放单个服务的配置文件 cert 如果网站是https，将相关证书放入cert文件夹中 nacos.conf配置如下 1234567891011121314151617181920212223242526272829303132333435363738394041upstream nacos_server &#123; server 127.0.0.1:8448 weight=1; server 127.0.0.1:8449 weight=2;&#125;# http 强制跳转httpsserver &#123; listen 80; server_name nacos.bosong.online; rewrite ^ https://$http_host$request_uri? permanent; &#125;server &#123; listen 443 ssl; server_name nacos.bosong.online; charset utf-8; #单独的域名访问日志 access_log logs/config.access.log main; #放置证书文件 ssl_certificate cert/config.pem; ssl_certificate_key cert/config.key; ssl_session_timeout 5m; ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:HIGH:!aNULL:!MD5:!RC4:!DHE; ssl_protocols TLSv1 TLSv1.1 TLSv1.2; ssl_prefer_server_ciphers on; location / &#123; #跨域配置-允许当前的域名访问 add_header Access-Control-Allow-Origin &#x27;$http_origin&#x27;; #允许携带凭证 add_header Access-Control-Allow-Credentials &#x27;true&#x27;; #允许请求类型-根据实际情况自定义 add_header Access-Control-Allow-Methods &#x27;GET, POST, OPTIONS, PUT, DELETE&#x27;; #允许携带的请求头，根据网站实际情况修改 add_header Access-Control-Allow-Headers &#x27;Cookie,Set-Cookie,x-requested-with,content-type,Authorization,accessToken,authorization,accesstoken&#x27;; #需要代理的后端服务，可负载均衡 proxy_pass http://nacos_server; #OPTIONS请求直接返回200或者204即可 if ($request_method = &#x27;OPTIONS&#x27;) &#123; return 200; &#125; &#125;&#125; 更加深入的探索在这里没有对安全性方面进行加强，如果网站需要更高安全性，可以根据实际需要在配置中增加安全性的相关配置。","raw":null,"content":null,"categories":[{"name":"Linux","slug":"Linux","permalink":"https://blog.bosong.online/categories/Linux/"}],"tags":[{"name":"nginx","slug":"nginx","permalink":"https://blog.bosong.online/tags/nginx/"}]},{"title":"线上事故记录-docker与Java的恩怨情仇","slug":"线上事故记录-docker与Java的恩怨情仇","date":"2020-04-01T13:30:30.000Z","updated":"2022-06-02T01:05:59.618Z","comments":true,"path":"线上事故记录-docker与Java的恩怨情仇.html","link":"","permalink":"https://blog.bosong.online/%E7%BA%BF%E4%B8%8A%E4%BA%8B%E6%95%85%E8%AE%B0%E5%BD%95-docker%E4%B8%8EJava%E7%9A%84%E6%81%A9%E6%80%A8%E6%83%85%E4%BB%87.html","excerpt":"起因上周五新建了一个项目，在开发完成后，和运维沟通准备上到生产环境中，套用了现有服务的通用启动命名行：","text":"起因上周五新建了一个项目，在开发完成后，和运维沟通准备上到生产环境中，套用了现有服务的通用启动命名行： 1java -jar Xms3072m -Xmx8192m app.jar &amp; 2&gt;1 然后一切准备就绪，jenkins打包一切顺利，然后顺利部署到生产环境，由于前端项目暂未部署，k8s使用的内网集群通信，暂时没有办法调用接口进行服务部署成功验证，但是在测试环境进行了充分测试，一切OK 。 在周五即将下班的时候，运维给我这边发消息，说我的服务没有部署成功,然后把日志给我发了过来，内容大致如下： 服务启动日志并没有出现JVM的字样，日志一直没有打下去 经过经过排查，发现服务没启动完成，突然想起来前几天碰到一个问题，就是当内存不足时，docker会自动kill掉容器。最终确认是服务的相关资源配置没给到位，被docker给强制关闭了。 询问运维给的相关配置内存为1G,但是我启动时设置的最小初始化内存为3G，此时被k8s认为资源不足，给kill掉，导致服务无限重启 结果调整了启动参数为1G，服务顺利启动。 反思该问题其实是一个非常简单的启动参数设置不合理导致的服务无法启动问题，也引申到了docker容器当内存不足时会自动kill掉相关容器的坑，所以需要记住合理配置服务的启动参数，另外尽量合理分配资源，让服务平稳安全运行。","raw":null,"content":null,"categories":[{"name":"Java","slug":"Java","permalink":"https://blog.bosong.online/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://blog.bosong.online/tags/Java/"}]},{"title":"对Java异常的理解","slug":"对Java异常的理解","date":"2020-03-18T13:58:02.000Z","updated":"2022-06-02T01:05:59.617Z","comments":true,"path":"对Java异常的理解.html","link":"","permalink":"https://blog.bosong.online/%E5%AF%B9Java%E5%BC%82%E5%B8%B8%E7%9A%84%E7%90%86%E8%A7%A3.html","excerpt":"开篇异常是因为异常在我们的代码开发中是无法避免的一个问题，也是最常见到的问题，简单了解一下异常的组成，对Java的异常有一个初步的了解，最重要的是在实践中遵守几个处理异常的原则，尽量减少处理异常过多而带来的资源消耗和减少因为异常处理不当引起的生产事故。","text":"开篇异常是因为异常在我们的代码开发中是无法避免的一个问题，也是最常见到的问题，简单了解一下异常的组成，对Java的异常有一个初步的了解，最重要的是在实践中遵守几个处理异常的原则，尽量减少处理异常过多而带来的资源消耗和减少因为异常处理不当引起的生产事故。 Exception与Error的区别都继承了Throwable类，在Java中，只有Throwable类型的实例才能被抛出（throw）或者捕获（catch）,Throwable是异常处理机制的基本组成类型。 Error是程序性的错误状态，绝大多数的Error会导致程序处理不可用状态，所以基本不需要对Error进行捕获，常见的Error类型有OutOfMemoryError等。 Exception种类： 可检查异常，需要在程序编译时就进行检查 不检查异常，也是运行时异常，有NullPointerException等，是一般程序在运行中抛出的错误异常，一般在编码中可以尽量避免此类异常。 异常实践 try-catch-finally,finally中关闭需要关闭的对象 try(resource)-catch，可以自动关闭实现了Closeable或者AutoCloseable的资源: InputStream等。 不建议直接捕获Exception,最好针对性捕获特定异常 尽量不要使用e.printStackTrace();当日志数量众多的时候，该堆栈信息基本查看不到 如果非必要情况下，不能生吞异常(catch后不做处理) 添加异常日志时，尽量避免将敏感信息暴露在日志中，可能会造成数据泄露 try-catch有性能开销，如非必要不要使用，使用时只将必要代码包住。 给用户侧展示的服务，最好有一个全局异常，进行log日志记录，并不将不必要的信息返回给用户，提高用户体验 总结关于异常貌似没有太多要说的点，基本上就是对异常和错误进行区分，和理解一些异常的基本实现，实现自定义异常等，最最重要的是异常实践需要多花心思。","raw":null,"content":null,"categories":[{"name":"Java","slug":"Java","permalink":"https://blog.bosong.online/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://blog.bosong.online/tags/Java/"}]},{"title":"对Java的基础理解","slug":"对Java的基础理解","date":"2020-03-15T10:38:15.000Z","updated":"2022-06-02T01:05:59.617Z","comments":true,"path":"对Java的基础理解.html","link":"","permalink":"https://blog.bosong.online/%E5%AF%B9Java%E7%9A%84%E5%9F%BA%E7%A1%80%E7%90%86%E8%A7%A3.html","excerpt":"文章的由来从大学学习到使用Java开发时间快超过三年，发现自己的系统化学习还是缺乏很多知识点，在此重新系统化的整理一下自己对于Java学习的一些理解， 我相信走的更远不仅仅有聪明人，还有不聪明但是认真并努力的人。","text":"文章的由来从大学学习到使用Java开发时间快超过三年，发现自己的系统化学习还是缺乏很多知识点，在此重新系统化的整理一下自己对于Java学习的一些理解， 我相信走的更远不仅仅有聪明人，还有不聪明但是认真并努力的人。 对Java的理解Java是一种跨平台的，面向对象的，自动化程度高的编程语言。 为什么这样说呢？因为Java的特性有俩，其中一个是一次编译，到处运行，此处充分表达了Java的跨平台特性，Java的虚拟机（JVM）在win、linux都有相同效果的不同实现，为Java成为跨平台语言提供了强大的支持。Java程序的成功运行过程可以分为四步：编码-&gt;编译-&gt;运行-&gt;调试，编码的过程自然不用赘叙，编译指的是将.java文件编译成为.class文件，.class文件就是可以在各个平台运行的文件,在不同的平台中，.class被转化为不同的机器码（机器码指的是计算机的运行指令），但是实现的是相同的功能。 另外一个特性是Java有着日渐成熟的垃圾收集，分配、释放内存的处理机制(gc-&gt;Garbage Collection)，垃圾收集功能由JVM提供响应的垃圾收集器，大部分情况下，我们不需要去过多的关注内存的分配与回收。 对Java是解释执行的理解Java不完全是解释执行的。 1、Java源代码经过Javac编译成.class文件 2、.class文件会被JVM解析或者编译运行 解析：.class文件经过JVM自带的解析器解析执行，此时是解释执行。 编译：存在 即时编译器(JIT-&gt; just in time compile)将热代码（经常运行的代码）编译成为该平台的机器码，并且可以分层进行相关优化，来提高代码的执行效率，此时是编译执行。 在Java9中，存在AOT编译器，将所有的代码直接编译成机器码执行。栗子：ART Android Runtime JIT和AOT的不同：JIT占用内存稍大，但是可以分层次对进行优化，但是相对启动速度稍慢，并且需要一定时间和调用频率来触发JIT的分层优化机制。AOT 占用内存少低，启动速度更快，但是没有运行时的性能加成，没法根据实际请求情况进行优化。 简单来说： 程序直接指向字节码就是解释执行。 程序在运行时将高频使用的字节码动态编译成机器码就是JIT。 程序直接全部翻译为机器码就是AOT。 对于Java平台的理解Java平台是Java代码从编写到运行的一系列过程，它分为以下几个步骤 1、开发 按照Java平台的语法规范，使用各种类库和框架开发程序。 2、编译 代码实现后使用Javac工具将程序编译成.class文件 3、加载 使用classload类加载编译成功.class文件到JVM中 4、运行 在运行时，JVM使用JIT将.class文件中的二进制字节码解释或编译（根据使用频率来判断使用解释或者编译）成机器码执行 5、内存回收 Java程序运行期间，通过JVM的垃圾回收，根据参数使用不同的回收方法，将不再使用的内存地址中的数据进行清空 6、性能监控、性能调优 自动化的运行方式可能会存在着各种各样的问题，在必要的情况下我们需要通过各种工具实现对程序进行运行时的状态监控，进行程序的诊断和调休工作。 JDK和JRE的区别 JRE为Java运行项目的运行提供基础支持。 JDK为编写JAVA程序提供基础支持以及其他的一些能力，它包括JRE和其他的工具包。 总结Java本身是一种语言，Java语言强大的特性来源于强大的解释编译器-JVM。随着时代的发展，Java也在不断的进步当中，从JDK1.1到现在的JDK14,Java从传统的解释型语言特性，通过JIT、AOT也具有了编译型语言的特性。从面向对象编程到函数式编程，从命令式编程到响应式编程，Java在不停的进步，不停的强大自身，让更多的开发者开发程序更加便利与运行程序更加高效。 岁月的车轮滚滚而来，我们也不能停下我们学习的脚步，愿未来更加美好。","raw":null,"content":null,"categories":[{"name":"Java","slug":"Java","permalink":"https://blog.bosong.online/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://blog.bosong.online/tags/Java/"}]},{"title":"关于Spring中@transactional的一些理解","slug":"关于Spring中@transactional的一些理解","date":"2020-01-19T08:59:56.000Z","updated":"2022-06-02T01:05:59.617Z","comments":true,"path":"关于Spring中@transactional的一些理解.html","link":"","permalink":"https://blog.bosong.online/%E5%85%B3%E4%BA%8ESpring%E4%B8%AD@transactional%E7%9A%84%E4%B8%80%E4%BA%9B%E7%90%86%E8%A7%A3.html","excerpt":"在我们的数据库开发的过程中，很多关键性的操作都需要使用到事务，保证数据的一致性和安全性。Spring为事务管理提供了非常丰富的支持，主要分为编码式(通过编码方式实现事务)、声明式(基于AOP，将具体业务逻辑与事务处理逻辑进行解耦)。编码式的事务使用起来较为繁琐，会对代码造成侵入，破坏整体的协调性。声明式则不然，在日常使用中声明式的使用相对比较频繁，它可以在xml中做相关事务规则配置，还有一种则是@Transactional 注解的方式。今天就@Transactional 的注解使用来简单的谈一谈我的理解。\n@Transactional 注解管理事务的实现步骤使用@Transactional 注解管理事务的实现步骤分为两步。\n第一步，在 xml 配置文件中添加事务配置信息。除了用配置文件的方式，@EnableTransactionManagement 注解也可以启用事务管理功能。这里以简单的 DataSourceTransactionManager 为例。\n一、 在 xml 配置中的事务配置信息12345&lt;tx:annotation-driven /&gt;&lt;bean id=&quot;transactionManager&quot;class=&quot;org.springframework.jdbc.datasource.DataSourceTransactionManager&quot;&gt;&lt;property name=&quot;dataSource&quot; ref=&quot;dataSource&quot; /&gt;&lt;/bean&gt;\n\n第二步，将@Transactional 注解添加到合适的方法上，并设置合适的属性信息。@Transactional 注解的属性信息如表 1 展示。\n表 1. @Transactional 注解的属性信息\n\n\n属性名\n说明\n\n\n\nname\n当在配置文件中有多个 TransactionManager , 可以用该属性指定选择哪个事务管理器。\n\n\npropagation\n事务的传播行为，默认值为 REQUIRED，具体见：propagation解释\n\n\nisolation\n事务的隔离度，默认值采用 DEFAULT，具体见：isolation解释\n\n\ntimeout\n事务的超时时间，默认值为-1。如果超过该时间限制但事务还没有完成，则自动回滚事务。\n\n\nread-only\n指定事务是否为只读事务，默认值为 false；为了忽略那些不需要事务的方法，比如读取数据，可以设置 read-only 为 true。\n\n\nrollback-for\n用于指定能够触发事务回滚的异常类型，如果有多个异常类型需要指定，各类型之间可以通过逗号分隔。\n\n\nno-rollback- for\n抛出 no-rollback-for 指定的异常类型，不回滚事务。\n\n\npropagation解释\n\n\n属性\n表现\n\n\n\nREQUIRED\n支持当前事务，若没有就新建-默认模式\n\n\nSUPPORTS\n支持当前事务，若没有就以非事务方式进行\n\n\nMANDATORY\n支持当前事务，若没有就抛异常\n\n\nREQUIRES_NEW\n新建事务，若存在当前事务，则挂起当前事务\n\n\nNOT_SUPPORTED\n以非事务方式执行操作，若存在当前事务，则挂起当前事务\n\n\nNEVER\n以非事务方式执行操作，若存在当前事务则抛异常\n\n\nNESTED\n支持当前事务，若当前事务存在，则嵌套一个事务，如果不存在，则新建\n\n\nisolation解释\n\n\n属性\n表现\n\n\n\nDEFAULT\n使用数据库默认的隔离级别\n\n\nREAD_UNCOMMITTED\n允许读取未提交的更改。可能导致脏读、幻读、不可重复读\n\n\nREAD_COMMITTED\n允许从已经提交的并发事务读取，可防止脏读，但幻读、不可重复仍可能发生\n\n\nREPEATABLE_READ\n对相同字段的多次读取的结果是一致的，除非数据被当前事务本身改变。可防止脏读和不可重复读，但幻影读仍可能发生。\n\n\nSERIALIZABLE\n完全服从ACID的隔离级别，确保不发生脏读、不可重复读和幻影读。这在所有隔离级别中也是最慢的，因为它通常是通过完全锁定当前事务所涉及的数据表来完成的。\n\n\n除此以外，@Transactional 注解也可以添加到类级别上。\n当把@Transactional 注解放在类级别时，表示所有该类的公共方法都配置相同的事务属性信息。见清单 2，EmployeeService 的所有方法都支持事务并且是只读。当类级别配置了@Transactional，方法级别也配置了@Transactional，应用程序会以方法级别的事务属性信息来管理事务，换言之，方法级别的事务属性信息会覆盖类级别的相关配置信息。\n二、 @Transactional 注解的类级别支持123@Transactional(propagation= Propagation.SUPPORTS,readOnly=true)@Service(value =&quot;employeeService&quot;)public class EmployeeService\n\n到此，发现使用@Transactional 注解管理事务的实现步骤其实很简单。\n但是如果对 Spring 中的 @Transactional 注解的事务管理理解的不够透彻，就很容易出现错误，比如事务应该回滚（rollback）而没有回滚事务的问题。\n下面看一看注册的事务实现的机制和常见的问题及解决方案。\n","text":"在我们的数据库开发的过程中，很多关键性的操作都需要使用到事务，保证数据的一致性和安全性。Spring为事务管理提供了非常丰富的支持，主要分为编码式(通过编码方式实现事务)、声明式(基于AOP，将具体业务逻辑与事务处理逻辑进行解耦)。编码式的事务使用起来较为繁琐，会对代码造成侵入，破坏整体的协调性。声明式则不然，在日常使用中声明式的使用相对比较频繁，它可以在xml中做相关事务规则配置，还有一种则是@Transactional 注解的方式。今天就@Transactional 的注解使用来简单的谈一谈我的理解。 @Transactional 注解管理事务的实现步骤使用@Transactional 注解管理事务的实现步骤分为两步。 第一步，在 xml 配置文件中添加事务配置信息。除了用配置文件的方式，@EnableTransactionManagement 注解也可以启用事务管理功能。这里以简单的 DataSourceTransactionManager 为例。 一、 在 xml 配置中的事务配置信息12345&lt;tx:annotation-driven /&gt;&lt;bean id=&quot;transactionManager&quot;class=&quot;org.springframework.jdbc.datasource.DataSourceTransactionManager&quot;&gt;&lt;property name=&quot;dataSource&quot; ref=&quot;dataSource&quot; /&gt;&lt;/bean&gt; 第二步，将@Transactional 注解添加到合适的方法上，并设置合适的属性信息。@Transactional 注解的属性信息如表 1 展示。 表 1. @Transactional 注解的属性信息 属性名 说明 name 当在配置文件中有多个 TransactionManager , 可以用该属性指定选择哪个事务管理器。 propagation 事务的传播行为，默认值为 REQUIRED，具体见：propagation解释 isolation 事务的隔离度，默认值采用 DEFAULT，具体见：isolation解释 timeout 事务的超时时间，默认值为-1。如果超过该时间限制但事务还没有完成，则自动回滚事务。 read-only 指定事务是否为只读事务，默认值为 false；为了忽略那些不需要事务的方法，比如读取数据，可以设置 read-only 为 true。 rollback-for 用于指定能够触发事务回滚的异常类型，如果有多个异常类型需要指定，各类型之间可以通过逗号分隔。 no-rollback- for 抛出 no-rollback-for 指定的异常类型，不回滚事务。 propagation解释 属性 表现 REQUIRED 支持当前事务，若没有就新建-默认模式 SUPPORTS 支持当前事务，若没有就以非事务方式进行 MANDATORY 支持当前事务，若没有就抛异常 REQUIRES_NEW 新建事务，若存在当前事务，则挂起当前事务 NOT_SUPPORTED 以非事务方式执行操作，若存在当前事务，则挂起当前事务 NEVER 以非事务方式执行操作，若存在当前事务则抛异常 NESTED 支持当前事务，若当前事务存在，则嵌套一个事务，如果不存在，则新建 isolation解释 属性 表现 DEFAULT 使用数据库默认的隔离级别 READ_UNCOMMITTED 允许读取未提交的更改。可能导致脏读、幻读、不可重复读 READ_COMMITTED 允许从已经提交的并发事务读取，可防止脏读，但幻读、不可重复仍可能发生 REPEATABLE_READ 对相同字段的多次读取的结果是一致的，除非数据被当前事务本身改变。可防止脏读和不可重复读，但幻影读仍可能发生。 SERIALIZABLE 完全服从ACID的隔离级别，确保不发生脏读、不可重复读和幻影读。这在所有隔离级别中也是最慢的，因为它通常是通过完全锁定当前事务所涉及的数据表来完成的。 除此以外，@Transactional 注解也可以添加到类级别上。 当把@Transactional 注解放在类级别时，表示所有该类的公共方法都配置相同的事务属性信息。见清单 2，EmployeeService 的所有方法都支持事务并且是只读。当类级别配置了@Transactional，方法级别也配置了@Transactional，应用程序会以方法级别的事务属性信息来管理事务，换言之，方法级别的事务属性信息会覆盖类级别的相关配置信息。 二、 @Transactional 注解的类级别支持123@Transactional(propagation= Propagation.SUPPORTS,readOnly=true)@Service(value =&quot;employeeService&quot;)public class EmployeeService 到此，发现使用@Transactional 注解管理事务的实现步骤其实很简单。 但是如果对 Spring 中的 @Transactional 注解的事务管理理解的不够透彻，就很容易出现错误，比如事务应该回滚（rollback）而没有回滚事务的问题。 下面看一看注册的事务实现的机制和常见的问题及解决方案。 Spring 的注解方式的事务实现机制在应用系统调用声明@Transactional 的目标方法时，Spring Framework 默认使用 AOP 代理，在代码运行时生成一个代理对象，根据@Transactional 的属性配置信息，这个代理对象决定该声明@Transactional 的目标方法是否由拦截器 TransactionInterceptor 来使用拦截，在 TransactionInterceptor 拦截时，会在在目标方法开始执行之前创建并加入事务，并执行目标方法的逻辑, 最后根据执行情况是否出现异常，利用抽象事务管理器(图 2 有相关介绍)AbstractPlatformTransactionManager 操作数据源 DataSource 提交或回滚事务, 如图 1 所示。 图 1. Spring 事务实现机制 Spring AOP 代理有 CglibAopProxy 和 JdkDynamicAopProxy 两种，图 1 是以CglibAopProxy为例，对于 CglibAopProxy，需要调用其内部类的 DynamicAdvisedInterceptor 的 intercept 方法。对于 JdkDynamicAopProxy，需要调用其 invoke 方法。 正如上文提到的，事务管理的框架是由抽象事务管理器 AbstractPlatformTransactionManager 来提供的，而具体的底层事务处理实现，由 PlatformTransactionManager 的具体实现类来实现，如事务管理器 DataSourceTransactionManager。不同的事务管理器管理不同的数据资源 DataSource，比如 DataSourceTransactionManager 管理 JDBC 的 Connection。 PlatformTransactionManager，AbstractPlatformTransactionManager 及具体实现类关系如图 2 所示。 图 2. TransactionManager 类结构 注解方式的事务使用注意事项当您对 Spring 的基于注解方式的实现步骤和事务内在实现机制有较好的理解之后，就会更好的使用注解方式的事务管理，避免当系统抛出异常，数据不能回滚的问题。 正确的设置@Transactional 的 propagation 属性需要注意下面三种 propagation 可以不启动事务。本来期望目标方法进行事务管理，但若是错误的配置这三种 propagation，事务将不会发生回滚。 SUPPORTS：如果当前存在事务，则加入该事务；如果当前没有事务，则以非事务的方式继续运行。 NOT_SUPPORTED：以非事务方式运行，如果当前存在事务，则把当前事务挂起。 NEVER：以非事务方式运行，如果当前存在事务，则抛出异常。 正确的设置@Transactional 的 rollbackFor 属性默认情况下，如果在事务中抛出了未检查异常（继承自 RuntimeException 的异常）或者 Error，则 Spring 将回滚事务；除此之外，Spring 不会回滚事务。 如果在事务中抛出其他类型的异常，并期望 Spring 能够回滚事务，可以指定 rollbackFor。例： 1@Transactional(propagation= Propagation.REQUIRED,rollbackFor= MyException.class) 通过分析 Spring 源码可以知道，若在目标方法中抛出的异常是 rollbackFor 指定的异常的子类，事务同样会回滚。 三、 RollbackRuleAttribute 的 getDepth 方法1234567891011private int getDepth(Class&lt;?&gt; exceptionClass, int depth) &#123; if (exceptionClass.getName().contains(this.exceptionName)) &#123; // Found it! return depth; &#125; // If we&#x27;ve gone as far as we can go and haven&#x27;t found it... if (exceptionClass == Throwable.class) &#123; return -1; &#125; return getDepth(exceptionClass.getSuperclass(), depth + 1);&#125; @Transactional 只能应用到 public 方法才有效只有@Transactional 注解应用到 public 方法，才能进行事务管理。这是因为在使用 Spring AOP 代理时，Spring 在调用在图 1 中的 TransactionInterceptor 在目标方法执行前后进行拦截之前，DynamicAdvisedInterceptor（CglibAopProxy 的内部类）的的 intercept 方法或 JdkDynamicAopProxy 的 invoke 方法会间接调用 AbstractFallbackTransactionAttributeSource（Spring 通过这个类获取表 1. @Transactional 注解的事务属性配置属性信息）的 computeTransactionAttribute 方法。 四、 AbstractFallbackTransactionAttributeSource123456protected TransactionAttribute computeTransactionAttribute(Method method, Class&lt;?&gt; targetClass) &#123; // Don&#x27;t allow no-public methods as required. if (allowPublicMethodsOnly() &amp;&amp; !Modifier.isPublic(method.getModifiers())) &#123; return null; &#125; 这个方法会检查目标方法的修饰符是不是 public，若不是 public，就不会获取@Transactional 的属性配置信息，最终会造成不会用 TransactionInterceptor 来拦截该目标方法进行事务管理。 避免 Spring 的 AOP 的自调用问题在 Spring 的 AOP 代理下，只有目标方法由外部调用，目标方法才由 Spring 生成的代理对象来管理，这会造成自调用问题。若同一类中的其他没有@Transactional 注解的方法内部调用有@Transactional 注解的方法，有@Transactional 注解的方法的事务被忽略，不会发生回滚。见下面代码展示。 五、自调用问题举例123456789101112131415161718@Servicepublic class OrderService &#123; @Transactional public void insertOrder() &#123; System.out.println(&quot;insert&quot;); &#125; //一、调用时@Transactional不生效 private void insert() &#123; insertOrder(); &#125; //二、调用时@Transactional生效 private void insert() &#123; ((OrderService) AopContext.currentProxy()).insertOrder(); &#125;&#125; insertOrder 尽管有@Transactional 注解，但它被内部方法 insert 调用（一、调用时@Transactional不生效），事务被忽略，出现异常事务不会发生回滚。 上面的两个问题@Transactional 注解只应用到 public 方法和自调用问题，是由于使用 Spring AOP 代理造成的。为解决这两个问题，使用 AspectJ 取代 Spring AOP 代理(二、调用时@Transactional生效)。 需要将下面的AspectJ信息添加到 xml 配置信息中。 六、 AspectJ 的 xml 配置信息12345678910&lt;tx:annotation-driven mode=&quot;aspectj&quot; /&gt;&lt;bean id=&quot;transactionManager&quot;class=&quot;org.springframework.jdbc.datasource.DataSourceTransactionManager&quot;&gt;&lt;property name=&quot;dataSource&quot; ref=&quot;dataSource&quot; /&gt;&lt;/bean&gt;&lt;/bean class=&quot;org.springframework.transaction.aspectj.AnnotationTransactionAspect&quot; factory-method=&quot;aspectOf&quot;&gt;&lt;property name=&quot;transactionManager&quot; ref=&quot;transactionManager&quot; /&gt;&lt;/bean&gt; 总结关于Spring的事务主要使用的是声明式的方法，事务使用前需要进行配置相关的事务并且如果需要使用到AOP还需要进行AOP的相关配置，然后需要根据具体的需求选用不同的传播行为与隔离级别，还需要注意如果在内部类中调用方法，需要注意@Transactional 不会生效的问题，避开了这些问题，使用起事务来就更加如鱼得水。 参考： https://www.ibm.com/","raw":null,"content":null,"categories":[{"name":"Java","slug":"Java","permalink":"https://blog.bosong.online/categories/Java/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"https://blog.bosong.online/tags/Spring/"}]},{"title":"更好用的日期工具","slug":"更好用的日期工具","date":"2019-11-17T10:30:03.000Z","updated":"2022-06-02T01:05:59.618Z","comments":true,"path":"更好用的日期工具.html","link":"","permalink":"https://blog.bosong.online/%E6%9B%B4%E5%A5%BD%E7%94%A8%E7%9A%84%E6%97%A5%E6%9C%9F%E5%B7%A5%E5%85%B7.html","excerpt":"介绍在以往的JAVA开发中，我们只能使用Date作为日期开发的常用工具，但是随着时代的发展，对日期的操作有了更高的需求，Date无法满足，并且使用起来代码比较繁琐，在此情景下，JAVA8引入了新的日期类-LocalDate以及LocalDateTime,新的时间类都是不可变并且线程安全的，下面我们来学一学它的用法。","text":"介绍在以往的JAVA开发中，我们只能使用Date作为日期开发的常用工具，但是随着时代的发展，对日期的操作有了更高的需求，Date无法满足，并且使用起来代码比较繁琐，在此情景下，JAVA8引入了新的日期类-LocalDate以及LocalDateTime,新的时间类都是不可变并且线程安全的，下面我们来学一学它的用法。 获取当前时间1234567891011121314151617181920212223242526272829public static void main(String[] args) &#123; /** * 获取当前时间戳 */ Instant instant = Instant.now(); System.out.println(instant); /** * 获取当前日期 */ LocalDate localDate = LocalDate.now(); System.out.println(localDate); /** * 获取当前时刻 */ LocalTime localTime = LocalTime.now(); System.out.println(localTime); /** * 获取当前具体时间 */ LocalDateTime localDateTime = LocalDateTime.now(); System.out.println(localDateTime); /** * 获取带有时区的时间 */ ZonedDateTime zonedDateTime = ZonedDateTime.now(); System.out.println(zonedDateTime);&#125; LocalDate与Date及String的相互转化1234567891011121314151617181920212223242526272829303132333435363738394041public static void main(String[] args) &#123; /** * 将日期字符串转化为LocalDate */ String str = &quot;2019-11-17&quot;; DateTimeFormatter formatter = DateTimeFormatter.ofPattern(&quot;yyyy-MM-dd&quot;); LocalDate localDate = LocalDate.parse(str, formatter); System.out.println(localDate); /** * Date转为LocalDate */ Date date = new Date(); Instant instant = date.toInstant(); ZoneId zoneId = ZoneId.systemDefault(); localDate = instant.atZone(zoneId).toLocalDate(); System.out.println(localDate); /** * LocalDate转成Date */ localDate = LocalDate.now(); ZonedDateTime zdt = localDate.atStartOfDay(zoneId); date = Date.from(zdt.toInstant()); System.out.println(date); /** * 时间戳转化为LocalDateTime */ instant = Instant.ofEpochMilli(System.currentTimeMillis()); LocalDateTime localDateTime = LocalDateTime.ofInstant(instant, ZoneId.systemDefault()); System.out.println(localDateTime); /** * LocalDateTime转化成时间戳 */ LocalDateTime now = LocalDateTime.now(); long beijing = now.toInstant(ZoneOffset.ofHours(8)).toEpochMilli(); System.out.println(beijing); long nowTime = now.toInstant(ZoneOffset.of(&quot;+08:00&quot;)).toEpochMilli(); System.out.println(nowTime); long normalTime = now.atZone(ZoneId.systemDefault()).toInstant().toEpochMilli(); System.out.println(normalTime); &#125; LocalDate和LocalDateTime的常用方法123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869public static void main(String[] args) &#123; /** * 设置年月日 */ LocalDate date = LocalDate.of(2019, 11, 17); /** * 设置年月日、时间秒 */ LocalDateTime time = LocalDateTime.of(date, LocalTime.of(12, 0, 0)); /** * 获取两个日期间间隔的天数 */ LocalDate dateFrom = LocalDate.of(2018, 11, 11); LocalDate now = LocalDate.now(); long between = ChronoUnit.DAYS.between(dateFrom, now); /** * 判断当前年份是否为闰年 */ boolean leapYear = LocalDate.now().isLeapYear(); /** * 当前日期 + 100 天 */ LocalDate plusDays = now.plusDays(100); /** * 当前日期 -100 天 */ LocalDate minusDays = now.minusDays(100); /** * 当前日期 + 3 个月 */ LocalDate plusMonths = now.plusMonths(3); /** * 当前日期 - 3 个月 */ LocalDate minusMonths = now.minusMonths(3); /** * 当前日期 + 1 周 */ LocalDate plusWeeks = now.plusWeeks(1); /** * 当前日期 - 1 周 */ LocalDate minusWeeks = now.minusWeeks(1); /** * 当前日期 + 1年 */ LocalDate plusYears = now.plusYears(1); /** * 当前日期 - 1年 */ LocalDate minusYears = now.minusYears(1); /** * 替换当前日期为本月的第19天 */ LocalDate withDayOfMonth = now.withDayOfMonth(19); /** * 替换日期为本年的第10天 */ LocalDate withDayOfYear = now.withDayOfYear(10); /** * 替换当前月份为10月 */ LocalDate withMonth = now.withMonth(10); /** * 替换当前年份为 2018年 */ LocalDate withYear = now.withYear(2018); &#125; 结束语更多更好用的，等你来发掘……","raw":null,"content":null,"categories":[{"name":"Java","slug":"Java","permalink":"https://blog.bosong.online/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://blog.bosong.online/tags/Java/"}]},{"title":"Java中关于货币金额的计算","slug":"Java中关于货币金额的计算","date":"2019-10-27T12:53:42.000Z","updated":"2022-06-02T01:05:59.613Z","comments":true,"path":"Java中关于货币金额的计算.html","link":"","permalink":"https://blog.bosong.online/Java%E4%B8%AD%E5%85%B3%E4%BA%8E%E8%B4%A7%E5%B8%81%E9%87%91%E9%A2%9D%E7%9A%84%E8%AE%A1%E7%AE%97.html","excerpt":"BigDecimal的由来由于互联网金额的高发达和高统一性，关于货币的金额基本都是精确到分，因此double在货币计算中可以说用武之地比较小，Java提供了一个非常强大的货币金额计算工具：BigDecimal","text":"BigDecimal的由来由于互联网金额的高发达和高统一性，关于货币的金额基本都是精确到分，因此double在货币计算中可以说用武之地比较小，Java提供了一个非常强大的货币金额计算工具：BigDecimal BigDecimal的基本使用&#x3D;&#x3D;如果需要进行精确计算，务必将对应数字转化为String来构造BigDecimal&#x3D;&#x3D; 123456789101112131415161718192021222324252627282930313233public static void main(String[] args) &#123; double a = 10.1234; double b = 5.3134; BigDecimal bigDecimalA = new BigDecimal(String.valueOf(a)); BigDecimal bigDecimalB = new BigDecimal(String.valueOf(b)); /** * 使用BigDecimal做加法运算 */ double addValue = bigDecimalA.add(bigDecimalB).doubleValue(); /** * 使用BigDecimal做减法运算 */ double subtractValue = bigDecimalA.subtract(bigDecimalB).doubleValue(); /** * 使用BigDecimal做乘法运算 */ double multiplyValue = bigDecimalA.multiply(bigDecimalB).doubleValue(); /** * 使用BigDecimal做除法运算 */ int scale = 2;//保留2位小数 double divideValue = bigDecimalA.divide(bigDecimalB, scale, BigDecimal.ROUND_HALF_UP).doubleValue(); /** * 使用BigDecimal的加减乘除进行复杂运算 */ int num = new BigDecimal(&quot;2019.1027&quot;) .divide(new BigDecimal(&quot;4.10&quot;), scale, BigDecimal.ROUND_HALF_UP) .multiply(new BigDecimal(&quot;1024&quot;)) .add(new BigDecimal(&quot;1234&quot;)).intValue();&#125; BigDecimal计算结果精度的控制 ROUND_UP 舍入远离零的舍入模式：在丢弃非零部分之前始终增加数字(始终对非零舍弃部分前面的数字加1)。 ROUND_DOWN 接近零的舍入模式：在丢弃某部分之前始终不增加数字(从不对舍弃部分前面的数字加1，即截短)。 ROUND_CEILING 接近正无穷大的舍入模式：如果 BigDecimal 为正，则舍入行为与 ROUND_UP 相同;如果为负，则舍入模式与ROUND_DOWN相同。 ROUND_FLOOR 接近负无穷大的舍入模式：如果BigDecimal 为负，则舍入行为ROUND_DOWN相同；反之亦然。 ROUND_HALF_UP 四舍五入：向最接近的数字舍入，如果为5及以上则同样进一；5以下舍弃。 ROUND_HALF_DOWN 五舍六入：向最接近的数字舍入，如果为6及以上则进一，6以下舍弃。 ROUND_HALF_EVEN 向“最接近的”数字舍入：如果与两个相邻数字的距离相等，则向相邻的偶数舍入： 如果舍弃部分左边的数字为奇数，则舍入行为与 ROUND_HALF_UP 相同;如果为偶数，则舍入行为与 ROUND_HALF_DOWN 相同。示例: 保留小数点后1位，则：1.15 -&gt; 1.2；1.25 -&gt;1.2 ROUND_UNNECESSARY 断言请求的操作具有精确的结果，因此不需要舍入：如果对获得精确结果的操作指定此舍入模式，则抛出ArithmeticException。 在以上的精确控制中，比较常用的是ROUND_HALF_UP和 ROUND_HALF_EVEN ；互联网计算精度最最常用的是ROUND_HALF_EVEN。 double数据的常用格式化123456789101112131415161718192021222324252627282930313233public static void main(String[] args) &#123; //格式化 double num = 1834234847.2345; /** * 将dobule数据进行正常的转化为String */ String value = NumberFormat.getNumberInstance().format(num); /** * 将dobule数据进行正常的转化为int，小数会进行四舍五入，然后转化为String */ value = NumberFormat.getIntegerInstance().format(num); /** * 设置小数部分的范围后然后转化为String-可使用于转化格式为货币 */ NumberFormat currency = NumberFormat.getCurrencyInstance(); //设置数的小数部分所允许的最小位数(如果不足后面补0) currency.setMinimumFractionDigits(2); //设置数的小数部分所允许的最大位数(如果超过会四舍五入) currency.setMaximumFractionDigits(4); value = currency.format(num); /** * 设置格式为%分比格式 */ NumberFormat percent = NumberFormat.getPercentInstance(); //设置数的小数部分所允许的最小位数(如果不足后面补0) percent.setMinimumFractionDigits(2); //设置数的小数部分所允许的最大位数(如果超过会四舍五入) percent.setMaximumFractionDigits(3); value = percent.format(num);&#125;","raw":null,"content":null,"categories":[{"name":"Java","slug":"Java","permalink":"https://blog.bosong.online/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://blog.bosong.online/tags/Java/"}]},{"title":"Linux远程拒绝服务漏洞","slug":"Linux远程拒绝服务漏洞","date":"2019-06-21T13:58:01.000Z","updated":"2022-06-02T01:05:59.613Z","comments":true,"path":"Linux远程拒绝服务漏洞.html","link":"","permalink":"https://blog.bosong.online/Linux%E8%BF%9C%E7%A8%8B%E6%8B%92%E7%BB%9D%E6%9C%8D%E5%8A%A1%E6%BC%8F%E6%B4%9E.html","excerpt":"漏洞详情 Linux 以及 FreeBSD 等系统内核上存在严重远程DoS漏洞，攻击者可利用该漏洞构造并发送特定的 SACK 序列请求到目标服务器导致服务器崩溃或拒绝服务。","text":"漏洞详情 Linux 以及 FreeBSD 等系统内核上存在严重远程DoS漏洞，攻击者可利用该漏洞构造并发送特定的 SACK 序列请求到目标服务器导致服务器崩溃或拒绝服务。 风险等级高风险-&gt;远程发送特殊构造的攻击包，导致目标 Linux 或 FreeBSD 服务器崩溃或服务不可用。 影响版本 目前已知受影响版本如下： FreeBSD 12（使用到 RACK TCP 协议栈） CentOS 5（Redhat 官方已停止支持，不再提供补丁） CentOS 6 CentOS 7 Ubuntu 18.04 LTS Ubuntu 16.04 LTS Ubuntu 19.04 Ubuntu 18.10 安全版本 各大Linux发行厂商已发布内核修复补丁，详细内核修复版本如下： CentOS 6 ：2.6.32-754.15.3 CentOS 7 ：3.10.0-957.21.3 Ubuntu 18.04 LTS：4.15.0-52.56 Ubuntu 16.04 LTS：4.4.0-151.178 修复建议 请参照上述安全版本升级 Linux 服务器内核，参考操作如下： 推荐方案：【CentOS 6&#x2F;7 系列用户】 1）yum clean all &amp;&amp; yum makecache，进行软件源更新； 2）yum update kernel -y，更新当前内核版本; 3）reboot，更新后重启系统生效; 4）uname -a，检查当前版本是否为上述【安全版本】，如果是，则说明修复成功。 推荐方案：【Ubuntu 16.04&#x2F;18.04 LTS 系列用户】 1）sudo apt-get update &amp;&amp; sudo apt-get install linux-image-generic，进行软件源更新并安装最新内核版本； 2）sudo reboot，更新后重启系统生效； 3）uname -a，检查当前版本是否为【安全版本】，如果是，则说明修复成功。 临时缓解方案： 如不方便重启进行内核补丁更新，可选择如下方式禁用内核 SACK配置防范漏洞利用（可能会对网络性能产生一定影响），运行如下命令即可： 1）echo ‘net.ipv4.tcp_sack &#x3D; 0’ &gt;&gt; &#x2F;etc&#x2F;sysctl.conf ，禁用 SACK 配置； 2）sysctl -p ，重载配置，使其生效。 漏洞参考 1）官方通告：https://github.com/Netflix/security-bulletins/blob/master/advisories/third-party/2019-001.md 2）社区参考：https://www.openwall.com/lists/oss-security/2019/06/17/5 3）红帽公告：https://access.redhat.com/security/vulnerabilities/tcpsack 4）腾讯云公告：https://cloud.tencent.com/announce/detail/622","raw":null,"content":null,"categories":[{"name":"Linux","slug":"Linux","permalink":"https://blog.bosong.online/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://blog.bosong.online/tags/Linux/"}]},{"title":"线上问题-long型数据复现","slug":"线上问题-long型数据复现","date":"2019-01-17T09:17:28.000Z","updated":"2022-06-02T01:05:59.618Z","comments":true,"path":"线上问题-long型数据复现.html","link":"","permalink":"https://blog.bosong.online/%E7%BA%BF%E4%B8%8A%E9%97%AE%E9%A2%98-long%E5%9E%8B%E6%95%B0%E6%8D%AE%E5%A4%8D%E7%8E%B0.html","excerpt":"起因因线上long型数据丢失精度问题未解决彻底，本地线上app端出现了该问题，探索新一步的解决方案。","text":"起因因线上long型数据丢失精度问题未解决彻底，本地线上app端出现了该问题，探索新一步的解决方案。 经过因线上获取该字段的接口数量较多，改动起来代价比较高，所以经过多方验证，讨论除了一套解决方案，因框架为Spring boot，所以新建了以下方法注入，来解决该问题，初见成效。 123456789101112131415161718192021222324252627282930313233import com.fasterxml.jackson.databind.ObjectMapper;import com.fasterxml.jackson.databind.module.SimpleModule;import com.fasterxml.jackson.databind.ser.std.ToStringSerializer;import org.springframework.context.annotation.Configuration;import org.springframework.http.converter.HttpMessageConverter;import org.springframework.http.converter.json.MappingJackson2HttpMessageConverter;import org.springframework.web.servlet.config.annotation.WebMvcConfigurationSupport;import java.util.List;/** * * @author jack * @version v 0.1 2019-01-17 14:56 * @apiNote 该类用于转换long型数据为String类型 */@Configurationpublic class JsonConfig extends WebMvcConfigurationSupport &#123; /** * 解决long、bigint转json丢失精度 */ @Override public void configureMessageConverters(List&lt;HttpMessageConverter&lt;?&gt;&gt; converters) &#123; MappingJackson2HttpMessageConverter jackson2HttpMessageConverter = new MappingJackson2HttpMessageConverter(); ObjectMapper objectMapper = new ObjectMapper(); SimpleModule simpleModule = new SimpleModule(); simpleModule.addSerializer(Long.class, ToStringSerializer.instance); simpleModule.addSerializer(Long.TYPE, ToStringSerializer.instance); objectMapper.registerModule(simpleModule); jackson2HttpMessageConverter.setObjectMapper(objectMapper); converters.add(jackson2HttpMessageConverter); &#125;&#125; 结果使用了上面的方法后，问题初步得到解决，先观察一段时间，以观后效。","raw":null,"content":null,"categories":[{"name":"Java","slug":"Java","permalink":"https://blog.bosong.online/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://blog.bosong.online/tags/Java/"}]},{"title":"使用 SCF 自动刷新被 CDN 缓存的 COS 资源","slug":"使用SCF自动刷新被CDN缓存的COS资源","date":"2019-01-16T10:45:26.000Z","updated":"2022-06-02T01:05:59.617Z","comments":true,"path":"使用SCF自动刷新被CDN缓存的COS资源.html","link":"","permalink":"https://blog.bosong.online/%E4%BD%BF%E7%94%A8SCF%E8%87%AA%E5%8A%A8%E5%88%B7%E6%96%B0%E8%A2%ABCDN%E7%BC%93%E5%AD%98%E7%9A%84COS%E8%B5%84%E6%BA%90.html","excerpt":"背景当静态内容需要更新时，通常会往 COS 覆盖上传一个更新版本的资源或删除该资源。当重新部署时，则 CDN 的某些边缘节点可能会仍然缓存旧资源。缓存过期时间太短，则会影响到加速的效果。","text":"背景当静态内容需要更新时，通常会往 COS 覆盖上传一个更新版本的资源或删除该资源。当重新部署时，则 CDN 的某些边缘节点可能会仍然缓存旧资源。缓存过期时间太短，则会影响到加速的效果。 根据上述情况，需要使用 CDN 控制台上的 缓存刷新 功能，对指定 URL 进行手动刷新操作，实现删除无效缓存文件或者更新资源。 在此将结合 COS 和 SCF 的功能特性，在 COS 文件更新时，实现自动刷新 CDN 缓存的效果。 准备工作 腾讯云账户，需具备 COS、CDN、SCF 等产品的访问权限。 创建存储桶，并在该存储桶上绑定了 CDN 加速域名。 确保 COS 的存储桶的所属地域支持 SCF 产品功能，暂不支持跨地域调用。 准备好可调用 CDN 刷新接口的云 API 密钥，以及下载 SCF 刷新 CDN 示例代码。 工作步骤创建SCF函数 登录 SCF 控制台，单击函数服务，选择与静态内容相同的地域并创建函数。如下图所示： 在 “新建函数” 页面，选择 “空白函数”，输入函数名称（如 refresh_cdn），设置运行环境（示例代码使用 Node.js 语言，因此运行环境设置为 Nodejs 6.10）。确认配置无误后单击【完成】即可。如下图所示：配置函数空白函数创建完成后，需添加对应的函数代码，并设定触发方式，使函数可以正常工作。 配置函数代码 下载 SCF 刷新 CDN 示例代码。 解压所有文件，找到其中的 index.js 文件并打开。 在代码里修改替换成您的具备调用 CDN 刷新接口权限的 SecretId、SecretKey 和需要刷新的域名。如下图所示： 如需调用刷新绑定在腾讯云海外 CDN 上的域名，请将代码中的 RefreshCdnUrl 修改为 RefreshCdnOverSeaUrl。上传函数代码 将修改好的代码和其他文件重新压缩打包为 zip 格式文件。zip结构如下所示： 在 SCF 控制台中，选择 “函数代码” 页签，将 “提交方法” 设置为 “本地上传 zip 包”，并选择刚压缩的 zip 格式文件，单击【上传】。如下图所示： 添加触发方式 在 SCF 控制台中，选择 “触发方式” 页签，单击【添加触发方式】。 将 “触发方式” 设置为 “COS 触发”，并选择需刷新 COS 资源的存储桶。如下图所示： 根据实际需求，设置事件类型。 如果仅需要自动刷新 CDN 访问覆盖上传到 COS 的对象，则需将 “事件类型” 设置为 “文件上传”。 如果同时需要对删除行为也进行自动刷新，则需再添加一种触发方式，并将 “事件类型” 设置为 “文件删除” 勾选立即启用。 最后确认配置信息无误后，单击【保存】。 验证上传一个新文件后再次访问即可验证。","raw":null,"content":null,"categories":[{"name":"技术手册","slug":"技术手册","permalink":"https://blog.bosong.online/categories/%E6%8A%80%E6%9C%AF%E6%89%8B%E5%86%8C/"}],"tags":[{"name":"cdn","slug":"cdn","permalink":"https://blog.bosong.online/tags/cdn/"}]},{"title":"搭建ipsec VPN 服务器","slug":"搭建ipsec VPN 服务器","date":"2019-01-15T07:20:59.000Z","updated":"2022-06-02T01:05:59.617Z","comments":true,"path":"搭建ipsec VPN 服务器.html","link":"","permalink":"https://blog.bosong.online/%E6%90%AD%E5%BB%BAipsec%20VPN%20%E6%9C%8D%E5%8A%A1%E5%99%A8.html","excerpt":"使用 Linux 脚本一键快速搭建自己的 IPsec VPN 服务器。支持 IPsec&#x2F;L2TP 和 Cisco IPsec 协议，可用于 Ubuntu&#x2F;Debian&#x2F;CentOS 系统。你只需提供自己的 VPN 登录凭证，然后运行脚本自动完成安装。\nIPsec VPN 可以加密你的网络流量，以防止在通过因特网传送时，你和 VPN 服务器之间的任何人对你的数据的未经授权的访问。在使用不安全的网络时，这是特别有用的，例如在咖啡厅，机场或旅馆房间。","text":"使用 Linux 脚本一键快速搭建自己的 IPsec VPN 服务器。支持 IPsec&#x2F;L2TP 和 Cisco IPsec 协议，可用于 Ubuntu&#x2F;Debian&#x2F;CentOS 系统。你只需提供自己的 VPN 登录凭证，然后运行脚本自动完成安装。 IPsec VPN 可以加密你的网络流量，以防止在通过因特网传送时，你和 VPN 服务器之间的任何人对你的数据的未经授权的访问。在使用不安全的网络时，这是特别有用的，例如在咖啡厅，机场或旅馆房间。 我们将使用 Libreswan 作为 IPsec 服务器，以及 xl2tpd 作为 L2TP 提供者。 安装 Docker首先，在你的 Linux 服务器上 安装并运行 Docker。 注： 本镜像不支持 Docker for Mac 或者 Windows。 下载预构建的可信任镜像可在 Docker Hub registry 下载： 1docker pull hwdsl2/ipsec-vpn-server 如何使用本镜像环境变量这个 Docker 镜像使用以下几个变量，可以在一个 env 文件中定义： 123VPN_IPSEC_PSK=your_ipsec_pre_shared_keyVPN_USER=your_vpn_usernameVPN_PASSWORD=your_vpn_password 这将创建一个用于 VPN 登录的用户账户，它可以在你的多个设备上使用*。 IPsec PSK (预共享密钥) 由 VPN_IPSEC_PSK 环境变量指定。 VPN 用户名和密码分别在 VPN_USER 和 VPN_PASSWORD 中定义。 支持创建额外的 VPN 用户，如果需要，可以像下面这样在你的 env 文件中定义。用户名和密码必须分别使用空格进行分隔，并且用户名不能有重复。所有的 VPN 用户将共享同一个 IPsec PSK。 12VPN_ADDL_USERS=additional_username_1 additional_username_2VPN_ADDL_PASSWORDS=additional_password_1 additional_password_2 注： 在你的 env 文件中，不要为变量值添加 &quot;&quot; 或者 &#39;&#39;，或在 = 两边添加空格。不要在值中使用这些字符： \\ &quot; &#39;。一个安全的 IPsec PSK 应该至少包含 20 个随机字符。 所有这些环境变量对于本镜像都是可选的，也就是说无需定义它们就可以搭建 IPsec VPN 服务器。详情请参见以下部分。 运行 IPsec VPN 服务器重要： 首先，在 Docker 主机上加载 IPsec af_key 内核模块。该步骤在 Ubuntu 和 Debian 上为可选步骤。 1sudo modprobe af_key 为保证这个内核模块在服务器启动时加载，请参见以下链接： Ubuntu&#x2F;Debian, CentOS 6, CentOS 7, Fedora 和 CoreOS。 使用本镜像创建一个新的 Docker 容器 （将 ./vpn.env 替换为你自己的 env 文件）： 123456789docker run \\ --name ipsec-vpn-server \\ --env-file ./vpn.env \\ --restart=always \\ -p 500:500/udp \\ -p 4500:4500/udp \\ -v /lib/modules:/lib/modules:ro \\ -d --privileged \\ hwdsl2/ipsec-vpn-server 获取 VPN 登录信息如果你在上述 docker run 命令中没有指定 env 文件，VPN_USER 会默认为 vpnuser，并且 VPN_IPSEC_PSK 和 VPN_PASSWORD 会被自动随机生成。要获取这些登录信息，可以查看容器的日志： 1docker logs ipsec-vpn-server 在命令输出中查找这些行： 123456Connect to your new VPN with these details:Server IP: 你的VPN服务器IPIPsec PSK: 你的IPsec预共享密钥Username: 你的VPN用户名Password: 你的VPN密码 （可选步骤）备份自动生成的 VPN 登录信息（如果有）到当前目录： 1docker cp ipsec-vpn-server:/opt/src/vpn-gen.env ./ 查看服务器状态如需查看你的 IPsec VPN 服务器状态，可以在容器中运行 ipsec status 命令： 1docker exec -it ipsec-vpn-server ipsec status 或者查看当前已建立的 VPN 连接： 1docker exec -it ipsec-vpn-server ipsec whack --trafficstatus 下一步配置你的计算机或其它设备使用 VPN 。请参见： 配置 IPsec&#x2F;L2TP VPN 客户端 配置 IPsec&#x2F;XAuth (“Cisco IPsec”) VPN 客户端 如果在连接过程中遇到错误，请参见 故障排除。 开始使用自己的专属 VPN ! 重要提示其他语言版本: English, 简体中文. Windows 用户 在首次连接之前需要修改注册表，以解决 VPN 服务器 和&#x2F;或 客户端与 NAT（比如家用路由器）的兼容问题。 同一个 VPN 账户可以在你的多个设备上使用。但是由于 IPsec&#x2F;L2TP 的局限性，如果需要同时连接在同一个 NAT （比如家用路由器）后面的多个设备到 VPN 服务器，你必须仅使用 IPsec&#x2F;XAuth 模式。 对于有外部防火墙的服务器（比如 EC2&#x2F;GCE），请为 VPN 打开 UDP 端口 500 和 4500。阿里云用户请参见 #433。 如果需要编辑 VPN 配置文件，你必须首先在正在运行的 Docker 容器中 开始一个 Bash 会话。 如需添加，修改或者删除 VPN 用户账户，首先更新你的 env 文件，然后你必须按照 下一节 的说明来删除并重新创建 Docker 容器。高级用户可以 绑定挂载 env 文件。 在 VPN 已连接时，客户端配置为使用 Google Public DNS。如果偏好其它的域名解析服务，请看这里。 更新 Docker 镜像如需更新你的 Docker 镜像和容器，请按以下步骤进行： 1docker pull hwdsl2/ipsec-vpn-server 如果 Docker 镜像已经是最新的，你会看到提示： 1Status: Image is up to date for hwdsl2/ipsec-vpn-server:latest 否则，将会下载最新版本。要更新你的 Docker 容器，首先在纸上记下你所有的 VPN 登录信息（参见上面的 “获取 VPN 登录信息”）。然后删除 Docker 容器： docker rm -f ipsec-vpn-server。最后按照 “如何使用本镜像” 的说明来重新创建它。 高级用法使用其他的 DNS 服务器在 VPN 已连接时，客户端配置为使用 Google Public DNS。如果偏好其它的域名解析服务，你可以在 env 文件中定义 VPN_DNS_SRV1 和 VPN_DNS_SRV2（可选），然后按照上面的说明重新创建 Docker 容器。比如你想使用 Cloudflare 的 DNS 服务： 12VPN_DNS_SRV1=1.1.1.1VPN_DNS_SRV2=1.0.0.1 从源代码构建高级用户可以从 GitHub 下载并自行编译源代码： 123git clone https://github.com/dislazy/docker-ipsec-vpn-server.gitcd docker-ipsec-vpn-serverdocker build -t dislazy/ipsec-vpn-server . 若不需要改动源码，也可以这样： 1docker build -t dislazy/ipsec-vpn-server github.com/dislazy/docker-ipsec-vpn-server.git 在容器中运行 Bash shell在正在运行的 Docker 容器中开始一个 Bash 会话： 1docker exec -it ipsec-vpn-server env TERM=xterm bash -l （可选步骤） 安装 nano 编辑器： 1apt-get update &amp;&amp; apt-get -y install nano 然后在容器中运行你的命令。完成后退出并重启 Docker 容器 （如果需要）： 12exitdocker restart ipsec-vpn-server 绑定挂载 env 文件作为 --env-file 选项的替代方案，高级用户可以绑定挂载 env 文件。该方法的好处是你在更新 env 文件之后可以重启 Docker 容器以生效，而不需要重新创建它。要使用这个方法，你必须首先编辑你的 env 文件并将所有的变量值用单引号 &#39;&#39; 括起来。然后（重新）创建 Docker 容器（将第一个 vpn.env 替换为你自己的 env 文件）： 123456789docker run \\ --name ipsec-vpn-server \\ --restart=always \\ -p 500:500/udp \\ -p 4500:4500/udp \\ -v &quot;$(pwd)/vpn.env:/opt/src/vpn.env:ro&quot; \\ -v /lib/modules:/lib/modules:ro \\ -d --privileged \\ hwdsl2/ipsec-vpn-server 启用 Libreswan 日志为了保持较小的 Docker 镜像，Libreswan (IPsec) 日志默认未开启。如果你是高级用户，并且需要启用它以便进行故障排除，首先在正在运行的 Docker 容器中开始一个 Bash 会话： 1docker exec -it ipsec-vpn-server env TERM=xterm bash -l 然后运行以下命令： 12345apt-get update &amp;&amp; apt-get -y install rsyslogservice rsyslog restartservice ipsec restartsed -i &#x27;/modprobe/a service rsyslog restart&#x27; /opt/src/run.shexit 完成后你可以这样查看 Libreswan 日志： 1docker exec -it ipsec-vpn-server grep pluto /var/log/auth.log 如需查看 xl2tpd 日志，请运行 docker logs ipsec-vpn-server。 技术细节需要运行以下两个服务： Libreswan (pluto) 提供 IPsec VPN， xl2tpd 提供 L2TP 支持。 默认的 IPsec 配置支持以下协议： IKEv1 with PSK and XAuth (“Cisco IPsec”) IPsec&#x2F;L2TP with PSK 为使 VPN 服务器正常工作，将会打开以下端口： 4500&#x2F;udp and 500&#x2F;udp for IPsec","raw":null,"content":null,"categories":[{"name":"Linux","slug":"Linux","permalink":"https://blog.bosong.online/categories/Linux/"}],"tags":[{"name":"vpn","slug":"vpn","permalink":"https://blog.bosong.online/tags/vpn/"}]},{"title":"Java常用工具类集锦","slug":"Java常用工具类方法集锦","date":"2019-01-05T14:41:13.000Z","updated":"2022-06-02T01:05:59.613Z","comments":true,"path":"Java常用工具类方法集锦.html","link":"","permalink":"https://blog.bosong.online/Java%E5%B8%B8%E7%94%A8%E5%B7%A5%E5%85%B7%E7%B1%BB%E6%96%B9%E6%B3%95%E9%9B%86%E9%94%A6.html","excerpt":"NumberUtils工具类判断字符串是否是数字NumberUtils.isNumber(“5.96”);&#x2F;&#x2F;结果是true\nNumberUtils.isNumber(“s5”);&#x2F;&#x2F;结果是false\nNumberUtils.isNumber(“0000000000596”);&#x2F;&#x2F;结果是true\n判断字符串中是否全为数字NumberUtils.isDigits(“0000000000.596”);&#x2F;&#x2F;false\nNumberUtils.isDigits(“0000000000596”);&#x2F;&#x2F;true\n字符串转换为整数NumberUtils.toInt(“5”);\nNumberUtils.toLong(“5”);\nNumberUtils.toByte(“3”);\nNumberUtils.toFloat(“3.2”);\nNumberUtils.toDouble(“4”);\nNumberUtils.toShort(“3”);\n找出最大的一个NumberUtils.max(newint[]{3,5,6});&#x2F;&#x2F;结果是6\nNumberUtils.max(3,1,7);&#x2F;&#x2F;结果是7\n找出最小的一个NumberUtils.min(newint[]{3,5,6});&#x2F;&#x2F;结果是6\nNumberUtils.min(3,1,7);&#x2F;&#x2F;结果是7\n通过字符串创建BigDecimal类型，支持long、int、float、double、number等数值NumberUtils.createBigDecimal(“1”);\nNumberUtils.createLong(“1”);\nNumberUtils.createInteger(“1”);\nArrayUtils工具类判断数组是否为空, 不为空返回false, 为空trueArrayUtils.isEmpty(new String[]{“21”,”是”});&#x2F;&#x2F;结果是false\nArrayUtils.isEmpty(new String[]{“”});&#x2F;&#x2F;结果是false\nArrayUtils.isEmpty(new String[]{null});&#x2F;&#x2F;结果是false\nArrayUtils.isEmpty(new String[]{});&#x2F;&#x2F;结果是true\n判断数组是否不为空,不为空返回true,为空falseArrayUtils.isNotEmpty(new String[]{“21”,”是”});&#x2F;&#x2F;结果是true\nArrayUtils.isNotEmpty(new String[]{“”});&#x2F;&#x2F;结果是true\nArrayUtils.isNotEmpty(new String[]{});&#x2F;&#x2F;结果是false\n判断两个数组长度是否相等,长度相等返回true,否则返回false。相比较的两个数组类型必须相同ArrayUtils.isSameLength(new String[]{“21”,”是”},new String[]{“21”,”是”});&#x2F;&#x2F;返回false\n判断两个数组的类型是否相同,相同返回true,否则返回falseArrayUtils.isSameType(new String[]{“21”,”是”},newInteger[]{3});\n判断两个数组是否相等ArrayUtils.isEquals(strs,strs);&#x2F;&#x2F;结果是true\n将一个数组转换成String,用于打印ArrayUtils.toString(new String[]{“21”,”是”});&#x2F;&#x2F;结果是：{21,是}\n赋值（克隆）数组Object[]s&#x3D;ArrayUtils.clone(newObject[]{“33”,”yy”});\n截取子数组：根据起始索引startIndexInclusive到结束索引startIndexInclusiveObject[]s1&#x3D;ArrayUtils.subarray(newObject[]{“33”,”yy”,”uu”},0,1);&#x2F;&#x2F;结果是返回数组：[33]\nObject[]s2&#x3D;ArrayUtils.subarray(newObject[]{“33”,”yy”,”uu”},0,2);&#x2F;&#x2F;结果是返回数组：[33,yy]\n查询某个object在数组中的位置，可是指定起始搜索位置intindex&#x3D;ArrayUtils.indexOf(newObject[]{“33”,”yy”,”uu”},”uu”);&#x2F;&#x2F;结果是2\nintindex1&#x3D;ArrayUtils.indexOf(newObject[]{“33”,”yy”,”uu”},”uu”,2);&#x2F;&#x2F;结果是2\nintindex3&#x3D;ArrayUtils.indexOf(newObject[]{“33”,”yy”,”uu”},”uu”,3);&#x2F;&#x2F;结果是-1\n反向查询某个object在数组中的位置，可以指定起始搜索位置intindex11&#x3D;ArrayUtils.lastIndexOf(newObject[]{“33”,”yy”,”uu”},”33”);&#x2F;&#x2F;结果是0\nintindex22&#x3D;ArrayUtils.lastIndexOf(newObject[]{“33”,”yy”,”uu”},”33”,2);\n查询某个object是否在数组中ArrayUtils.contains(new String[]{“1”, “2”, “3”}, “11”);\n反转数组ArrayUtils.reverse(new String[]{“22”,”yy”});&#x2F;&#x2F;结果是：{“yy”，”22”}\n添加一object到数组String[] t&#x3D;{“22”,”yy”};\nString[] gg&#x3D;(String[])ArrayUtils.add(t,”jj”);&#x2F;&#x2F;{“22”,”yy”,”jj”}\n合并两个数组String[]ggo&#x3D;(String[])ArrayUtils.addAll(new String[]{“22”,”yy”},new String[]{“jj”});&#x2F;&#x2F;结果是：[22,yy,jj]\nArrayUtils.addAll(new String[]{“22”,”yy”},new String[]{“jj”, “jj”}); &#x2F;&#x2F;结果是：[22,yy,jj,jj]\n删除数组某个位置的元素String[]gg4&#x3D;(String[])ArrayUtils.remove(new String[]{“22”,”yy”},1);\n删除数组中某个对象String[]ggpp&#x3D;(String[])ArrayUtils.removeElement(new String[]{“22”,”yy”},”yy”);\n","text":"NumberUtils工具类判断字符串是否是数字NumberUtils.isNumber(“5.96”);&#x2F;&#x2F;结果是true NumberUtils.isNumber(“s5”);&#x2F;&#x2F;结果是false NumberUtils.isNumber(“0000000000596”);&#x2F;&#x2F;结果是true 判断字符串中是否全为数字NumberUtils.isDigits(“0000000000.596”);&#x2F;&#x2F;false NumberUtils.isDigits(“0000000000596”);&#x2F;&#x2F;true 字符串转换为整数NumberUtils.toInt(“5”); NumberUtils.toLong(“5”); NumberUtils.toByte(“3”); NumberUtils.toFloat(“3.2”); NumberUtils.toDouble(“4”); NumberUtils.toShort(“3”); 找出最大的一个NumberUtils.max(newint[]{3,5,6});&#x2F;&#x2F;结果是6 NumberUtils.max(3,1,7);&#x2F;&#x2F;结果是7 找出最小的一个NumberUtils.min(newint[]{3,5,6});&#x2F;&#x2F;结果是6 NumberUtils.min(3,1,7);&#x2F;&#x2F;结果是7 通过字符串创建BigDecimal类型，支持long、int、float、double、number等数值NumberUtils.createBigDecimal(“1”); NumberUtils.createLong(“1”); NumberUtils.createInteger(“1”); ArrayUtils工具类判断数组是否为空, 不为空返回false, 为空trueArrayUtils.isEmpty(new String[]{“21”,”是”});&#x2F;&#x2F;结果是false ArrayUtils.isEmpty(new String[]{“”});&#x2F;&#x2F;结果是false ArrayUtils.isEmpty(new String[]{null});&#x2F;&#x2F;结果是false ArrayUtils.isEmpty(new String[]{});&#x2F;&#x2F;结果是true 判断数组是否不为空,不为空返回true,为空falseArrayUtils.isNotEmpty(new String[]{“21”,”是”});&#x2F;&#x2F;结果是true ArrayUtils.isNotEmpty(new String[]{“”});&#x2F;&#x2F;结果是true ArrayUtils.isNotEmpty(new String[]{});&#x2F;&#x2F;结果是false 判断两个数组长度是否相等,长度相等返回true,否则返回false。相比较的两个数组类型必须相同ArrayUtils.isSameLength(new String[]{“21”,”是”},new String[]{“21”,”是”});&#x2F;&#x2F;返回false 判断两个数组的类型是否相同,相同返回true,否则返回falseArrayUtils.isSameType(new String[]{“21”,”是”},newInteger[]{3}); 判断两个数组是否相等ArrayUtils.isEquals(strs,strs);&#x2F;&#x2F;结果是true 将一个数组转换成String,用于打印ArrayUtils.toString(new String[]{“21”,”是”});&#x2F;&#x2F;结果是：{21,是} 赋值（克隆）数组Object[]s&#x3D;ArrayUtils.clone(newObject[]{“33”,”yy”}); 截取子数组：根据起始索引startIndexInclusive到结束索引startIndexInclusiveObject[]s1&#x3D;ArrayUtils.subarray(newObject[]{“33”,”yy”,”uu”},0,1);&#x2F;&#x2F;结果是返回数组：[33] Object[]s2&#x3D;ArrayUtils.subarray(newObject[]{“33”,”yy”,”uu”},0,2);&#x2F;&#x2F;结果是返回数组：[33,yy] 查询某个object在数组中的位置，可是指定起始搜索位置intindex&#x3D;ArrayUtils.indexOf(newObject[]{“33”,”yy”,”uu”},”uu”);&#x2F;&#x2F;结果是2 intindex1&#x3D;ArrayUtils.indexOf(newObject[]{“33”,”yy”,”uu”},”uu”,2);&#x2F;&#x2F;结果是2 intindex3&#x3D;ArrayUtils.indexOf(newObject[]{“33”,”yy”,”uu”},”uu”,3);&#x2F;&#x2F;结果是-1 反向查询某个object在数组中的位置，可以指定起始搜索位置intindex11&#x3D;ArrayUtils.lastIndexOf(newObject[]{“33”,”yy”,”uu”},”33”);&#x2F;&#x2F;结果是0 intindex22&#x3D;ArrayUtils.lastIndexOf(newObject[]{“33”,”yy”,”uu”},”33”,2); 查询某个object是否在数组中ArrayUtils.contains(new String[]{“1”, “2”, “3”}, “11”); 反转数组ArrayUtils.reverse(new String[]{“22”,”yy”});&#x2F;&#x2F;结果是：{“yy”，”22”} 添加一object到数组String[] t&#x3D;{“22”,”yy”}; String[] gg&#x3D;(String[])ArrayUtils.add(t,”jj”);&#x2F;&#x2F;{“22”,”yy”,”jj”} 合并两个数组String[]ggo&#x3D;(String[])ArrayUtils.addAll(new String[]{“22”,”yy”},new String[]{“jj”});&#x2F;&#x2F;结果是：[22,yy,jj] ArrayUtils.addAll(new String[]{“22”,”yy”},new String[]{“jj”, “jj”}); &#x2F;&#x2F;结果是：[22,yy,jj,jj] 删除数组某个位置的元素String[]gg4&#x3D;(String[])ArrayUtils.remove(new String[]{“22”,”yy”},1); 删除数组中某个对象String[]ggpp&#x3D;(String[])ArrayUtils.removeElement(new String[]{“22”,”yy”},”yy”); RandomUtils工具类RandomUtils帮助我们产生随机数，不止是数字类型，连boolean类型都可以通过RandomUtils产生，RandomStringUtils生成字符随机数。 RandomUtils.nextBoolean(); RandomUtils.nextDouble(); RandomUtils.nextLong(); &#x2F;&#x2F; 注意这里传入的参数不是随机种子,而是在0~1000之间产生一位随机数 RandomUtils.nextInt(1000); StringUtils工具类空字符串检查StringUtils.isEmpty(String str);&#x2F;&#x2F;当为”“或者null时都为true StringUtils.isNotEmpty(String str); &#x2F;&#x2F;当为”“或者null时都为false StringUtils.isBlank(String str);&#x2F;&#x2F;当为”“或者null时都为true StringUtils.isNotBlank(String str);&#x2F;&#x2F;当为”“或者null时都为false 清除空白字符StringUtils.trimToNull(str)； &#x2F;&#x2F;清除掉str首尾的空白字符,如果仅str全由空白字符组成则返回null;函数StringUtils.trim(str)与StringUtils.trimToNull(str)功能类似，但str由空白字符 组成时返回零长度字符串。 查找嵌套字符串StringUtils.substringBetween(str,header,tail); &#x2F;&#x2F;在str中取得header和tail之间的字符串。不存在则返回空. 取得字符串的缩写StringUtils.abbreviate(str,width); StringUtils.abbreviate(str,offset，width); &#x2F;&#x2F; 在给定的width内取得str的缩写,当testString的长度小于width(大于等于4)则返回原字符串. 去除尾部换行符StringUtils.chomp(str) &#x2F;&#x2F;去除str尾部的换行符\\n 重复字符串StringUtils.repeat(str,count) &#x2F;&#x2F;得到将str重复count次后的字符串 StringUtils.center( str, count,repeatString ); &#x2F;&#x2F;把str插入将repeatString重复多次后的字符串中间,得到字符串的总长为count 颠倒字符串StringUtils.reverse(str) &#x2F;&#x2F;得到str中字符颠倒后的字符串 判断字符串内容的类型StringUtils.isNumeric( str); &#x2F;&#x2F;如果str全由数字组成返回True. StringUtils.isAlpha( str); &#x2F;&#x2F;如果str全由字母组成返回True. StringUtils.isAlphanumeric( str); &#x2F;&#x2F;如果str全由数字或数字组成返回True. StringUtils.isAlphaspace( str); &#x2F;&#x2F;如果str全由字母或空格组成返回True. StringUtils.isAlphanumericSpace(String str); &#x2F;&#x2F;只由字母数字和空格组成 StringUtils.isNumericSpace(String str); &#x2F;&#x2F;只由数字和空格组成 取得某字符串在另一字符串中出现的次数StringUtils.countMatches(str,seqString); &#x2F;&#x2F;取得seqString在str中出现的次数,未发现则返回零 部分截取字符串StringUtils.substringBetween(testString,fromString,toString ): &#x2F;&#x2F;取得两字符之间的字符串 StringUtils.substringAfter(str,seqStr ): &#x2F;&#x2F;取得指定字符串后的字符串 StringUtils.substringBefore(str,seqStr )： &#x2F;&#x2F;取得指定字符串之前的字符串 StringUtils.substringBeforeLast( str,seqStr )： &#x2F;&#x2F;取得最后一个指定字符串之前的字符串 StringUtils.substringAfterLast(str,seqStr )： &#x2F;&#x2F;取得最后一个指定字符串之后的字符串 首字母大写StringUtils.capitalize(String str); &#x2F;&#x2F;首字母大写 StringUtils.uncapitalize(String str);&#x2F;&#x2F;首字母小写 是否全是大写，是否全是小写StringUtils.isAllUpperCase(String str); StringUtils.isAllLowerCase(String str); 大小写转换，空格不动StringUtils.swapCase(String str);","raw":null,"content":null,"categories":[{"name":"Java","slug":"Java","permalink":"https://blog.bosong.online/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://blog.bosong.online/tags/Java/"}]},{"title":"hexo持续集成","slug":"hexo持续集成","date":"2019-01-04T03:04:49.000Z","updated":"2022-06-02T01:05:59.615Z","comments":true,"path":"hexo持续集成.html","link":"","permalink":"https://blog.bosong.online/hexo%E6%8C%81%E7%BB%AD%E9%9B%86%E6%88%90.html","excerpt":"申请注册coding，然后通过coding升级至腾讯云开发者平台https://feedback.coding.net/topics/7257","text":"申请注册coding，然后通过coding升级至腾讯云开发者平台https://feedback.coding.net/topics/7257 新建仓库后开通持续集成功能将hexo的源代码提交至coding仓库，然后选择持续集成，进行配置，简单配置如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344pipeline &#123; agent &#123; label &quot;node-8&quot; &#125; stages &#123; stage(&quot;检出&quot;) &#123; steps &#123; sh &#x27;ci-init&#x27; checkout( [$class: &#x27;GitSCM&#x27;, branches: [[name: env.GIT_BUILD_REF]], userRemoteConfigs: [[url: env.GIT_REPO_URL]]] ) &#125; &#125; stage(&quot;构建&quot;) &#123; steps &#123; echo &quot;构建中...&quot; sh &#x27;node -v&#x27; sh &#x27;npm install hexo-cli -g&#x27; sh &#x27;npm install&#x27; sh &#x27;hexo clean&#x27; sh &#x27;hexo g&#x27; sh &#x27;hexo d&#x27; echo &quot;构建完成.&quot; &#125; &#125; stage(&quot;测试&quot;) &#123; steps &#123; echo &quot;单元测试中...&quot; echo &quot;单元测试完成.&quot; &#125; &#125; stage(&quot;部署&quot;) &#123; steps &#123; echo &quot;部署中...&quot; echo &quot;部署完成&quot; &#125; &#125; &#125; &#125; 选择相应分支，然后提交代码大功告成，每次需要部署时候直接提交代码即可。","raw":null,"content":null,"categories":[{"name":"技术手册","slug":"技术手册","permalink":"https://blog.bosong.online/categories/%E6%8A%80%E6%9C%AF%E6%89%8B%E5%86%8C/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"https://blog.bosong.online/tags/hexo/"}]},{"title":"SpringCloudEureka源码详解","slug":"SpringCloudEureka源码详解","date":"2018-12-09T12:20:57.000Z","updated":"2022-06-02T01:05:59.615Z","comments":true,"path":"SpringCloudEureka源码详解.html","link":"","permalink":"https://blog.bosong.online/SpringCloudEureka%E6%BA%90%E7%A0%81%E8%AF%A6%E8%A7%A3.html","excerpt":"概述Spring Cloud Eureka是Spring Cloud Netflix项目下的服务治理模块。\n由于微服务概念的引入，使大型服务在一定程度上彻底的解耦，当服务集群足够庞大的时候，服务治理成为了微服务的痛点之一。\nEureka是Spring Could中服务发现的推荐组件，保证服务的高可用性，它有着丰富的API，使得Eureka作为服务发现与治理都比较方便。\n架构与原理\n\nEureka Server：服务的注册中心，负责维护注册的服务列表。\nService Provider：服务提供方，作为一个Eureka Client，向Eureka Server做服务注册、续约和下线等操作，注册的主要数据包括服务名、机器ip、端口号、域名等等。\nService Consumer：服务消费方，作为一个Eureka Client，向Eureka Server获取Service Provider的注册信息，并通过远程调用与Service Provider进行通信\n\nEureka Server作为一个独立的部署单元，以REST API的形式为服务实例提供了注册、管理和查询等操作。同时，Eureka Server也为我们提供了可视化的监控页面，可以直观地看到各个Eureka  Server当前的运行状态和所有已注册服务的情况。如图:\n\n原理：服务启动后向Eureka注册，Eureka Server会将注册信息向其他Eureka Server进行同步，当服务消费者要调用服务提供者，则向服务注册中心获取服务提供者地址，\n然后会将服务提供者地址缓存在本地，下次再调用时，则直接从本地缓存中取，完成一次调用。\n当服务注册中心Eureka  Server检测到服务提供者因为宕机、网络原因不可用时，则在服务注册中心将服务置为DOWN状态，并把当前服务提供者状态向订阅者发布，订阅过的服务消费者更新本地缓存。\n服务提供者在启动后，周期性（默认30秒）向Eureka Server发送心跳，以证明当前服务是可用状态。Eureka Server在一定的时间（默认90秒）未收到客户端的心跳，则认为服务宕机，注销该实例。\n源码解读：eureka主体实现方式：\nApplicationResource类接收Http服务请求，调用PeerAwareInstanceRegistryImpl的register方法，PeerAwareInstanceRegistryImpl完成服务注册后，调用replicateToPeers向其它Eureka Server节点（Peer）做状态同步。\neureka client启动时候会创建一个定时任务，定时任务会将本地的服务配置信息，也就是注册到远端的服务信息自动刷新到注册服务器上，实现了服务注册以及缓存更新的机制。\n1、com.netflix.discovery.DiscoveryClient.java中的可以看到initScheduledTasks方法，它封装了一个instanceInfoReplicator的定时任务，以一定的时间（默认30秒）来刷新服务的缓存和心跳信息。\n2、instanceInfoReplicator中的run方法调用register来实现注册功能，start方法实现了定时刷新调用,定时注册到eureka\neureka server1、com.netflix.eureka.resources.ApplicationResource 中使用addInstance方法接收来自client的请求消息，然后进行处理，最终的注册信息缓存在ConcurrentHashMap中，实现服务缓存。\nEureka的自我保护机制：在默认情况下，Eureka Server在默认90s时间内没有收到服务端的心跳（默认30秒一次心跳，三次心跳），会将该服务注销。在一般情况下，网络通信的故障率较高，在网络通信出现异常时，Eureka Server如果正常注销服务，\n将会导致大部分服务不可用，这违背了微服务高可用的初衷，在这种情况下，Eureka Server有自我保护机制，当它在短时间内丢失过多的客户端时（默认15分钟内低于85%），该节点将进入自我保护模式，不再注销服务，并且同时继续提供新服务的注册，当网络故障修复之后，该节点能自动的退出自我保护模式。\n总之一句话：不管好数据坏数据，一个不落。\n","text":"概述Spring Cloud Eureka是Spring Cloud Netflix项目下的服务治理模块。 由于微服务概念的引入，使大型服务在一定程度上彻底的解耦，当服务集群足够庞大的时候，服务治理成为了微服务的痛点之一。 Eureka是Spring Could中服务发现的推荐组件，保证服务的高可用性，它有着丰富的API，使得Eureka作为服务发现与治理都比较方便。 架构与原理 Eureka Server：服务的注册中心，负责维护注册的服务列表。 Service Provider：服务提供方，作为一个Eureka Client，向Eureka Server做服务注册、续约和下线等操作，注册的主要数据包括服务名、机器ip、端口号、域名等等。 Service Consumer：服务消费方，作为一个Eureka Client，向Eureka Server获取Service Provider的注册信息，并通过远程调用与Service Provider进行通信 Eureka Server作为一个独立的部署单元，以REST API的形式为服务实例提供了注册、管理和查询等操作。同时，Eureka Server也为我们提供了可视化的监控页面，可以直观地看到各个Eureka Server当前的运行状态和所有已注册服务的情况。如图: 原理：服务启动后向Eureka注册，Eureka Server会将注册信息向其他Eureka Server进行同步，当服务消费者要调用服务提供者，则向服务注册中心获取服务提供者地址， 然后会将服务提供者地址缓存在本地，下次再调用时，则直接从本地缓存中取，完成一次调用。 当服务注册中心Eureka Server检测到服务提供者因为宕机、网络原因不可用时，则在服务注册中心将服务置为DOWN状态，并把当前服务提供者状态向订阅者发布，订阅过的服务消费者更新本地缓存。 服务提供者在启动后，周期性（默认30秒）向Eureka Server发送心跳，以证明当前服务是可用状态。Eureka Server在一定的时间（默认90秒）未收到客户端的心跳，则认为服务宕机，注销该实例。 源码解读：eureka主体实现方式： ApplicationResource类接收Http服务请求，调用PeerAwareInstanceRegistryImpl的register方法，PeerAwareInstanceRegistryImpl完成服务注册后，调用replicateToPeers向其它Eureka Server节点（Peer）做状态同步。 eureka client启动时候会创建一个定时任务，定时任务会将本地的服务配置信息，也就是注册到远端的服务信息自动刷新到注册服务器上，实现了服务注册以及缓存更新的机制。 1、com.netflix.discovery.DiscoveryClient.java中的可以看到initScheduledTasks方法，它封装了一个instanceInfoReplicator的定时任务，以一定的时间（默认30秒）来刷新服务的缓存和心跳信息。 2、instanceInfoReplicator中的run方法调用register来实现注册功能，start方法实现了定时刷新调用,定时注册到eureka eureka server1、com.netflix.eureka.resources.ApplicationResource 中使用addInstance方法接收来自client的请求消息，然后进行处理，最终的注册信息缓存在ConcurrentHashMap中，实现服务缓存。 Eureka的自我保护机制：在默认情况下，Eureka Server在默认90s时间内没有收到服务端的心跳（默认30秒一次心跳，三次心跳），会将该服务注销。在一般情况下，网络通信的故障率较高，在网络通信出现异常时，Eureka Server如果正常注销服务， 将会导致大部分服务不可用，这违背了微服务高可用的初衷，在这种情况下，Eureka Server有自我保护机制，当它在短时间内丢失过多的客户端时（默认15分钟内低于85%），该节点将进入自我保护模式，不再注销服务，并且同时继续提供新服务的注册，当网络故障修复之后，该节点能自动的退出自我保护模式。 总之一句话：不管好数据坏数据，一个不落。 核心特性 Eureka通过相互注册与复制支持高可用 Eureka支持用户认证 Eureka Client支持注册表缓存 Eureka提供保护模式以解决网络分区故障 Eureka提供健康检查 Eureka支持RESTful API 为什么选择Eureka而非Zookeeper作为服务发现组件，以下对比： 使用方法服务注册过程： 当实例状态发生变化时（上线Or下线），都会请求到eureka-server发送一个状态，在一定的时间后，eureka会对该服务进行加入或者删除，然后进行eureka集群的缓存复制。 创建Eureka Sever服务1.创建一个Spring Boot工程，命名问Eureka-Server，并在pom文件中引入依赖： 1234567891011121314151617181920212223242526&lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-eureka-server&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-security&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;Dalston.SR1&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt; 2.创建启动类 1234567@EnableEurekaServer //用来指定该项目为Eureka的服务注册中心@SpringBootApplicationpublic class EurekaApp &#123; public static void main(String[] args) &#123; SpringApplication.run(EurekaApp.class, args); &#125; 3.配置server服务 123456789101112131415161718192021222324252627282930313233# server (eureka 默认端口为：8761)server.port=8761# springspring.application.name=spring-cloud-server# eureka# 是否注册到eurekaeureka.client.register-with-eureka=false# 是否从eureka获取注册信息eureka.client.fetch-registry=false# eureka服务器的地址（注意：地址最后面的 /eureka/ 这个是固定值）eureka.client.serviceUrl.defaultZone=http://localhost:$&#123;server.port&#125;/eureka/# info自定义,读取pom文件中的内容info.build.name=@project.name@info.build.description=@project.description@info.build.groupId=@project.groupId@info.build.artifact=@project.artifactId@info.build.version=@project.version@# 指定环境eureka.environment=dev#指定数据中心#eureka.datacenter=roncoo# 配置自我保护模式eureka.server.enable-self-preservation=true#设置清理无效节点的时间间隔，默认60000，即是60seureka.server.eviction-interval-timer-in-ms=5000#设置连接密码security.basic.enabled=truesecurity.user.name=qbsecurity.user.password=123456 4.配置完成启动eureka server即可，访问http://localhost:8761/eureka/ Eureka高可用集群配置: 三注册中心，两两互相注册将eureka.client.serviceUrl.defaultZone值设置为其他两节点值即可。 创建Eureka Client项目1.创建Springboot项目，引入如下依赖： 1234567891011121314151617181920212223242526&lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-eureka&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-security&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;Dalston.SR1&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt; 2.新增启动类 1234567891011/** * * @EnableEurekaServer * 用来指定该项目为Eureka的服务注册中心 */@EnableDiscoveryClient@SpringBootApplicationpublic class ClientApp &#123; public static void main(String[] args) &#123; SpringApplication.run(EurekaApp.class, args); &#125; 3.配置client连接上服务发现 123456789101112131415161718192021222324# serverserver.port=8888# springspring.application.name=spring-cloud-consumer# eurekaeureka.client.serviceUrl.defaultZone=http://qb:123456@localhost:8761/eureka/#自定义访问路径eureka.instance.status-page-url-path=/info#自定义实例IDeureka.instance.instanceId=$&#123;spring.application.name&#125;:$&#123;random.value&#125;#显示IP地址eureka.instance.prefer-ip-address=true#设置拉取服务注册信息时间，默认60seureka.client.registry-fetch-interval-seconds=30#指定续约更新频率，默认是30seureka.instance.lease-renewal-interval-in-seconds=15#设置过期剔除时间，默认90seureka.instance.lease-expiration-duration-in-seconds=45 4.启动后，能在Eurekaweb端上看到服务的列表 服务发现使用场景服务发现并不是为了服务发现而服务发现，是为了使用一些必要的功能而必不可少的组件，服务发现的下游有丰富的内部服务调用工具 Ribbon，实现客户端的负载均衡。 Hystrix，断路器。 Feign，RESTful Web Service客户端，整合了Ribbon和Hystrix。 服务调用端负载均衡——RibbonRibbon是Netflix发布的开源项目，主要功能是为REST客户端实现负载均衡。它主要包括六个组件： ServerList，负载均衡使用的服务器列表。这个列表会缓存在负载均衡器中，并定期更新。当Ribbon与Eureka结合使用时，ServerList的实现类就是DiscoveryEnabledNIWSServerList，它会保存Eureka Server中注册的服务实例表。 ServerListFilter，服务器列表过滤器。这是一个接口，主要用于对Service Consumer获取到的服务器列表进行预过滤，过滤的结果也是ServerList。Ribbon提供了多种过滤器的实现。 IPing，探测服务实例是否存活的策略。 IRule，负载均衡策略，其实现类表述的策略包括：轮询、随机、根据响应时间加权，（可以自定义负载均衡策略，实现完之后可以重新注入ribbon） ILoadBalancer，负载均衡器。这也是一个接口，Ribbon为其提供了多个实现，比如ZoneAwareLoadBalancer。而上层代码通过调用其API进行服务调用的负载均衡选择。一般ILoadBalancer的实现类中会引用一个IRule。 RestClient，服务调用器。顾名思义，这就是负载均衡后，Ribbon向Service Provider发起REST请求的工具。 Ribbon工作时会做四件事情：1.优先选择在同一个Zone（区域）且负载较少的Eureka Server；2.定期从Eureka更新并过滤服务实例列表；3.根据用户指定的策略，在从Server取到的服务注册列表中选择一个实例的地址；4.通过RestClient进行服务调用。 Ribbon的源码实现大致原理： LoadBalancerClient ： 继承了ServiceInstanceChooser接口，实现类是RibbonLoadBalancerClient.主要方法有choose（ServiceInstanceChooser用来选择instance） ,execute（LoadBalancerClient 用来执行）. ILoadBalancer:接口方法有addServers，chooseServer，markServerDown,getReachableServers,getAllServers.（负载均衡）实现类为BaseLoadBalancer 和 DynamicServerListLoadBalancer. BaseLoadBalancer :主要由以下类进行配置IClientConfig（基本配置，用于初始化） IRule（路由策略） IPing （判断响应） （静态配置负载均衡） DynamicServerListLoadBalancer： ServerList（用于从Eureka中获取服务列表） ServerListFilter（列表过滤） 动态配置负载均衡） 负载均衡过程： 1.RibbonLoadBalancerClient接收到一个serviceid之后，调用ServiceInstanceChooser的choose方法，choose方法首先得到 ILoadBalancer （当中有client列表）。再利用ILoadBalancer 的chooseServer方法得到普通Server实例并实例化RibbonServer，并返回。chooseserver会通过loadbalancer中的rule来返回正确的instance。 2.DynamicServerListLoadBalancer由iconfig初始化，初始化完成后调用updateListOfServers方法获得所有ServerList。（方法中通过ServerList实现类来访问EurekaClient中的注册列表） 3.BaseLoadBalancer中有一个PingTask任务，他每10秒钟会向EurekaClient发送一个Ping。如果从Eureka拉取的注册列表发生了改变，则重新更新列表。 4.LoadBalancerClient根据注册列表和IRule来进行负载均衡 Ribbon的应用springcloud提供了默认的配置RibbonClientConfiguration。它提供了包含ILoadBalancer,ServerListFilter在内的许多配置。 你可以更改默认的配置，更改方法为在.property文件中添加.ribbon.*的配置项 服务调用端熔断——HystrixNetflix创建了一个名为Hystrix的库,实现了断路器的模式。 “断路器”本身是一种开关装置，当某个服务单元发生故障之后，通过断路器的故障监控（类似熔断保险丝），向调用方返回一个符合预期的、可处理的备选响应（FallBack），而不是长时间的等待或者抛出调用方无法处理的异常，这样就保证了服务调用方的线程不会被长时间、不必要地占用，从而避免了故障在分布式系统中的蔓延，乃至雪崩。正常情况下，在请求失败频率较低的情况下，Hystrix还是会直接把故障返回给客户端。只有当失败次数达到阈值（默认在20秒内失败5次）时，断路器打开并且不进行后续通信，而是直接返回备选响应。 当然，Hystrix的备选响应也是可以由开发者定制的。 除了隔离依赖服务的调用以外，Hystrix还提供了准实时的调用监控（Hystrix Dashboard），Hystrix会持续地记录所有通过Hystrix发起的请求的执行信息，并以统计报表和图形的形式展示给用户，包括每秒执行多少请求多少成功，多少失败等。Netflix通过hystrix-metrics-event-stream项目实现了对以上指标的监控。Spring Cloud也提供了Hystrix Dashboard的整合，对监控内容转化成可视化界面，Hystrix Dashboard Wiki上详细说明了图上每个指标的含义。 服务调用端代码抽象和封装——FeignFeign是一个声明式的Web Service客户端，它的目的就是让Web Service调用更加简单。 它整合了Ribbon和Hystrix，从而让我们不再需要显式地使用这两个组件。 Feign还提供了HTTP请求的模板，通过编写简单的接口和插入注解，我们就可以定义好HTTP请求的参数、格式、地址等信息。 接下来，Feign会完全代理HTTP的请求，我们只需要像调用方法一样调用它就可以完成服务请求。 Feign具有如下特性： 可插拔的注解支持，包括Feign注解和JAX-RS注解 支持可插拔的HTTP编码器和解码器 支持Hystrix和它的Fallback 支持Ribbon的负载均衡 支持HTTP请求和响应的压缩 以下是一个Feign的简单示例： 12345678910111213141516171819202122232425262728293031323334353637383940@SpringBootApplication@EnableDiscoveryClient @EnableFeignClients //启用fegin调用public class Application&#123; public static void main(String[] args) &#123; SpringApplication.run(Application.class, args); &#125;&#125;@FeignClient(name = &quot;elements&quot;, fallback = ElementsFallback.class) //指定feign调用的服务和Hystrix Fallback（name即eureka的application name）public interface Elements&#123; @RequestMapping(value = &quot;/index&quot;) String index();&#125;//Hystrix Fallback @Componentpublic class ElementsFallback implements Elements&#123; @Override public String index() &#123; return &quot;熔断生效&quot;; &#125;&#125;//测试类@Component public class TestController &#123; @Autowired Elements elements; @RequestMapping(value = &quot;/testEureka&quot;, method = RequestMethod.GET) public String testeureka() &#123; return elements.index(); &#125;&#125; 说明：（1）使用 @Component 注解向SpringBoot中注入该组件。 （2）使用@FeignClient(&quot;XXX&quot;)注解来绑定该接口对应的服务。 注意：在启动类上加 @EnableFeignClients 注解，如果定义的Feign接口定义跟启动类不在一个包名下，还需要制定扫描的包名：@EnableFeignClients(basePackages = &quot;xxx.xxx.xxx&quot;) 建议将接口定义，单独抽一个项目出来，后面打成公共的jar，这样无论是哪个项目需要调用接口，引入公共的接口SDK jar即可，不需要重新定义一遍。 注意事项eureka在服务下线后30秒节点还存在，需妥善处理 替代方案Eureka-&gt;consul consul实际也是CP型服务发现，并且监控的指标较多，可作为替代方案 Ribbon-&gt;nginx 负载均衡nginx有相对较为成熟的机制，但是配置项较多，谨慎使用","raw":null,"content":null,"categories":[{"name":"Java","slug":"Java","permalink":"https://blog.bosong.online/categories/Java/"}],"tags":[{"name":"spring cloud","slug":"spring-cloud","permalink":"https://blog.bosong.online/tags/spring-cloud/"}]},{"title":"mysql主从同步带来的影响及部分解决方案","slug":"mysql主从同步带来的影响及部分解决方案","date":"2018-12-08T22:53:33.000Z","updated":"2022-06-02T01:05:59.616Z","comments":true,"path":"mysql主从同步带来的影响及部分解决方案.html","link":"","permalink":"https://blog.bosong.online/mysql%E4%B8%BB%E4%BB%8E%E5%90%8C%E6%AD%A5%E5%B8%A6%E6%9D%A5%E7%9A%84%E5%BD%B1%E5%93%8D%E5%8F%8A%E9%83%A8%E5%88%86%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88.html","excerpt":"前因场景1：线上的数据异步同步使用的是rabbitmq，当对数据库数据进行增删改时候会发送一条mq消息到同步服务，同时进行查库写入es。","text":"前因场景1：线上的数据异步同步使用的是rabbitmq，当对数据库数据进行增删改时候会发送一条mq消息到同步服务，同时进行查库写入es。 场景2：线上redis数据读取mysql中数据写入，由于该数据为访问量巨大的数据，所以未设置过期时间，有增删改操作时，会读库重新写入redis。 场景3：线上数据库实时读取，当修改为某项后异步刷新列表，发现该数据未进行修改，重新刷新后才显示正确数据 排查过程以上问题，我们排查过程比较迅速，第一时间对比es，redis，mysql中数据，发现了数据不同步的情况，然后查看代码，发现未有对数据进行代码层改动，我们已知数据库为主从模式，由此主从延时故障找到。 解决方案方案1：发mq消息时，直接将整条数据发送并且写入。但是一旦数据量过大，会造成压力，并且有删改的情况出现时，我们一般不会去获取整条数据，还是得查询数据库后发送 方案2：redis设置有效期，过完有效期redis会重新加载数据入库，但是有效期内的数据是不正确的 方案3：增加主库数据库读，在写mq，写redis这些场景下直接读取主库，避免了碰到主从延时的问题，数据也能及时更新，但是此种方案有可能对主库造成大压力。 后果以上几种方案，我们使用了方案二和方案三并行的情况，保证主从有延时的情况下，数据不会出错。 反思： 1.发生了一次主从延时，我们后面在结构优化，数据读的场景都会考虑到此种情况，从而针对进行改进 2.在一定的范围内，还是建议数据库独立，尽量不使用公共数据库（此种方案的决定方是运维）","raw":null,"content":null,"categories":[{"name":"数据库","slug":"数据库","permalink":"https://blog.bosong.online/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"https://blog.bosong.online/tags/mysql/"}]},{"title":"线上long型数据丢失精度问题","slug":"线上long型数据丢失精度问题","date":"2018-12-08T12:15:26.000Z","updated":"2022-06-02T01:05:59.618Z","comments":true,"path":"线上long型数据丢失精度问题.html","link":"","permalink":"https://blog.bosong.online/%E7%BA%BF%E4%B8%8Along%E5%9E%8B%E6%95%B0%E6%8D%AE%E4%B8%A2%E5%A4%B1%E7%B2%BE%E5%BA%A6%E9%97%AE%E9%A2%98.html","excerpt":"前因在dev和qa环境正常获取到用户的userId,dev和qa环境的userId长度都不长，通过userId查询数据，显示数据完全正常。","text":"前因在dev和qa环境正常获取到用户的userId,dev和qa环境的userId长度都不长，通过userId查询数据，显示数据完全正常。 但是上线之后，很快有运营反馈使用userId查询不出结果，经过验证发现确实这样，开始排查问题 排查过程由于我们项目后端使用的是接口层与业务层隔离的架构，所以先在业务层加上日志，拿到日志之后和web层获取到的数据进行对比。对比结果发现该userId在较长时候确实出现了不一致的情况，但是业务层的数据和数据库中的数据完全一致，哪一步操作导致精度丢失了呢？ 进一步排查，在接口层打输入输出日志，发现接口层的输入输出与业务层完全一致，在此种情形下，我们有点摸不着头脑，还以为是我们读错了库的原因。 验证数据库后发现，库没读错，数据完全和库一致，那只能是传输过程中出现问题了。 我们使用的是chrome浏览器，接口层数据是直接使用network扩展里面的preview，经过仔细排查发现，preview的数据和response里面的数据不一致，至此问题找到： 前端接受json数据时，精度丢失。 解决方案因为字段固定的缘故，我们不准备从后端进行更改，准备web层直接进行修改，经过一番修改，查询的传输的userId并没有出现丢失的情况，但是展示的问题前端确实没法解决。 由于业务层和接口层分离的原因，我们不能为了一个字段去改动业务层（业务层的接口是公共接口，并且是完全对应db字段），直接从接口层去修改，使用一个新类继承老类来进行操作，将该long数据转化成字符串，经验证，该问题解决。 后果该问题经过紧张迅速排查并解决，并且让我们意识到数据不会骗人，但是浏览器会骗人，在long型数据上，我们进行展示和操作时，需要谨慎对待，丢失精度成本很高。","raw":null,"content":null,"categories":[{"name":"Java","slug":"Java","permalink":"https://blog.bosong.online/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://blog.bosong.online/tags/Java/"}]},{"title":"Linux磁盘管理","slug":"Linux磁盘管理","date":"2018-12-03T14:06:39.000Z","updated":"2022-06-02T01:05:59.613Z","comments":true,"path":"Linux磁盘管理.html","link":"","permalink":"https://blog.bosong.online/Linux%E7%A3%81%E7%9B%98%E7%AE%A1%E7%90%86.html","excerpt":"Linux磁盘管理好坏直接关系到整个系统的性能问题。\nLinux磁盘管理常用三个命令为df、du和fdisk。","text":"Linux磁盘管理好坏直接关系到整个系统的性能问题。 Linux磁盘管理常用三个命令为df、du和fdisk。 df：列出文件系统的整体磁盘使用量du：检查磁盘空间使用量fdisk：用于磁盘分区 dfLinux磁盘管理好坏直接关系到整个系统的性能问题。 Linux磁盘管理常用三个命令为df、du和fdisk。 df：列出文件系统的整体磁盘使用量 du：检查磁盘空间使用量 fdisk：用于磁盘分区 df命令df命令参数功能：检查文件系统的磁盘空间占用情况。可以利用该命令来获取硬盘被占用了多少空间，目前还剩下多少空间等信息。 语法： df [-ahikHTm] [目录或文件名]选项与参数： a ：列出所有的文件系统，包括系统特有的 &#x2F;proc 等文件系统； k ：以 KBytes 的容量显示各文件系统； m ：以 MBytes 的容量显示各文件系统； h ：以人们较易阅读的 GBytes, MBytes, KBytes 等格式自行显示； H ：以 M&#x3D;1000K 取代 M&#x3D;1024K 的进位方式； T ：显示文件系统类型, 连同该 partition 的 filesystem 名称 (例如 ext3) 也列出； i ：不用硬盘容量，而以 inode 的数量来显示实例 1 将系统内所有的文件系统列出来！ 123456[root@www ~]# dfFilesystem 1K-blocks Used Available Use% Mounted on/dev/hdc2 9920624 3823112 5585444 41% //dev/hdc3 4956316 141376 4559108 4% /home/dev/hdc1 101086 11126 84741 12% /boottmpfs 371332 0 371332 0% /dev/shm 在 Linux 底下如果 df 没有加任何选项，那么默认会将系统内所有的 (不含特殊内存内的文件系统与 swap) 都以 1 Kbytes 的容量来列出来！ 实例 2将容量结果以易读的容量格式显示出来 123456[root@www ~]# df -hFilesystem Size Used Avail Use% Mounted on/dev/hdc2 9.5G 3.7G 5.4G 41% //dev/hdc3 4.8G 139M 4.4G 4% /home/dev/hdc1 99M 11M 83M 12% /boottmpfs 363M 0 363M 0% /dev/shm 实例 3将系统内的所有特殊文件格式及名称都列出来 1234567891011[root@www ~]# df -aTFilesystem Type 1K-blocks Used Available Use% Mounted on/dev/hdc2 ext3 9920624 3823112 5585444 41% /proc proc 0 0 0 - /procsysfs sysfs 0 0 0 - /sysdevpts devpts 0 0 0 - /dev/pts/dev/hdc3 ext3 4956316 141376 4559108 4% /home/dev/hdc1 ext3 101086 11126 84741 12% /boottmpfs tmpfs 371332 0 371332 0% /dev/shmnone binfmt_misc 0 0 0 - /proc/sys/fs/binfmt_miscsunrpc rpc_pipefs 0 0 0 - /var/lib/nfs/rpc_pipefs 实例 4将 &#x2F;etc 底下的可用的磁盘容量以易读的容量格式显示 123[root@www ~]# df -h /etcFilesystem Size Used Avail Use% Mounted on/dev/hdc2 9.5G 3.7G 5.4G 41% / du命令Linux du命令也是查看使用空间的，但是与df命令不同的是Linux du命令是对文件和目录磁盘使用的空间的查看，还是和df命令有一些区别的，这里介绍Linux du命令。 语法： du [-ahskm] 文件或目录名称 选项与参数： a ：列出所有的文件与目录容量，因为默认仅统计目录底下的文件量而已。 h ：以人们较易读的容量格式 (G&#x2F;M) 显示； s ：列出总量而已，而不列出每个各别的目录占用容量； S ：不包括子目录下的总计，与 -s 有点差别。 k ：以 KBytes 列出容量显示； m ：以 MBytes 列出容量显示； 实例 1列出目前目录下的所有文件容量 123456[root@www ~]# du8 ./test4 &lt;==每个目录都会列出来8 ./test2....中间省略....12 ./.gconfd &lt;==包括隐藏文件的目录220 . &lt;==这个目录(.)所占用的总量 直接输入 du 没有加任何选项时，则 du会分析当前所在目录的文件与目录所占用的硬盘空间。 实例 2将文件的容量也列出来 12345678[root@www ~]# du -a12 ./install.log.syslog &lt;==有文件的列表了8 ./.bash_logout8 ./test48 ./test2....中间省略....12 ./.gconfd220 . 实例 3检查根目录底下每个目录所占用的容量 123456789[root@www ~]# du -sm /*7 /bin6 /boot.....中间省略....0 /proc.....中间省略....1 /tmp3859 /usr &lt;==系统初期最大就是他了啦！77 /var 通配符 * 来代表每个目录。 与 df 不一样的是，du 这个命令其实会直接到文件系统内去搜寻所有的文件数据。 fdisk命令fdisk 是 Linux 的磁盘分区表操作工具。 语法： fdisk [-l] 装置名称 选项与参数： l ：输出后面接的装置所有的分区内容。若仅有 fdisk -l 时， 则系统将会把整个系统内能够搜寻到的装置的分区均列出来。 实例 1列出所有分区信息 12345678910111213141516171819202122[root@AY120919111755c246621 tmp]# fdisk -lDisk /dev/xvda: 21.5 GB, 21474836480 bytes255 heads, 63 sectors/track, 2610 cylindersUnits = cylinders of 16065 * 512 = 8225280 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytesDisk identifier: 0x00000000 Device Boot Start End Blocks Id System/dev/xvda1 * 1 2550 20480000 83 Linux/dev/xvda2 2550 2611 490496 82 Linux swap / SolarisDisk /dev/xvdb: 21.5 GB, 21474836480 bytes255 heads, 63 sectors/track, 2610 cylindersUnits = cylinders of 16065 * 512 = 8225280 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytesDisk identifier: 0x56f40944 Device Boot Start End Blocks Id System/dev/xvdb2 1 2610 20964793+ 83 Linux 磁盘挂载与卸除Linux 的磁盘挂载使用 mount 命令，卸载使用 umount 命令。 磁盘挂载语法： mount [-t 文件系统] [-L Label名] [-o 额外选项] [-n] 装置文件名 挂载点 实例 1用默认的方式，将刚刚创建的 &#x2F;dev&#x2F;hdc6 挂载到 &#x2F;mnt&#x2F;hdc6 上面！ 123456[root@www ~]# mkdir /mnt/hdc6[root@www ~]# mount /dev/hdc6 /mnt/hdc6[root@www ~]# dfFilesystem 1K-blocks Used Available Use% Mounted on.....中间省略...../dev/hdc6 1976312 42072 1833836 3% /mnt/hdc6 磁盘卸载命令 umount 语法： umount [-fn] 装置文件名或挂载点 选项与参数： f ：强制卸除！可用在类似网络文件系统 (NFS) 无法读取到的情况下； n ：不升级 &#x2F;etc&#x2F;mtab 情况下卸除。 卸载&#x2F;dev&#x2F;hdc6 1[root@www ~]# umount /dev/hdc6","raw":null,"content":null,"categories":[{"name":"Linux","slug":"Linux","permalink":"https://blog.bosong.online/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://blog.bosong.online/tags/Linux/"}]},{"title":"stream-常用数组操作","slug":"stream-常用数组操作","date":"2018-11-28T15:26:44.000Z","updated":"2022-06-02T01:05:59.616Z","comments":true,"path":"stream-常用数组操作.html","link":"","permalink":"https://blog.bosong.online/stream-%E5%B8%B8%E7%94%A8%E6%95%B0%E7%BB%84%E6%93%8D%E4%BD%9C.html","excerpt":"对User集合进行升序，倒序操作对listResult进行排序,根据伴随度进行降序,根据集合中对象User中的伴随度进行倒序排列…reversed(),默认正序,reversed反转后即倒序;","text":"对User集合进行升序，倒序操作对listResult进行排序,根据伴随度进行降序,根据集合中对象User中的伴随度进行倒序排列…reversed(),默认正序,reversed反转后即倒序; 123List&lt;User&gt; collect = listResult.stream() .sorted(Comparator.comparing(User::getUserId()).reversed()) .collect(Collectors.toList()); 过滤User集合中符合条件的结果过滤出User中UserId大于1的结果,firstA中存放的都是的大于1的 123List&lt;User&gt; firstA = listResult.stream() .filter(User -&gt; user.getUserId() &gt;= 1) .collect(Collectors.toList()); 将User集合按照UserId从小到大重新进行排序123List&lt;User&gt; result = listResult.stream() .sorted(Comparator.comparing(User::getUserId())) .collect(Collectors.toList()); 提取出User集合中的UserId重新生成一个新的数组1List&lt;Integer&gt; collect = listResult.stream().map(e-&gt;e.getUserId()).collect(Collectors.toList()); 按照某个主键来讲User集合分别归类转化成map12Map&lt;Integer, User&gt; map = listResult.stream().collect(Collectors.toMap(User::getUserId, User -&gt; User));","raw":null,"content":null,"categories":[{"name":"Java","slug":"Java","permalink":"https://blog.bosong.online/categories/Java/"}],"tags":[{"name":"stream","slug":"stream","permalink":"https://blog.bosong.online/tags/stream/"}]},{"title":"Docker","slug":"Docker常用操作","date":"2018-10-14T12:57:48.000Z","updated":"2022-06-02T01:05:59.612Z","comments":true,"path":"Docker常用操作.html","link":"","permalink":"https://blog.bosong.online/Docker%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C.html","excerpt":"docker ps  查看运行正常进程\ndocker ps -a  查看所有存在过进程","text":"docker ps 查看运行正常进程 docker ps -a 查看所有存在过进程 docker search XXX 搜索镜像 docker rm -f xxx 删除images docker load &lt; 镜像名称 导入镜像 docker pull +镜像名称 下载镜像 docker logs -f +查看容器Id 查看容器运行日志 docker save -o 导出文件名称 镜像名 导出镜像 docker tag &lt;IMAGE ID&gt; &lt;REPOSITORY NAME&gt; 复制并修改镜像名称 mvn clean package docker:build java 打包成镜像 docker run -d -p 1200:1200 -v /data:/data 镜像名称 运行容器 docker logs -f --tail=10 容器Id 查看实时日志 docker exec -it 容器ID/别名 /bin/bash 进入 容器 docker exec -it &lt;image&gt; sh 进入容器 docker version 查看docker的版本号，包括客户端、服务端、依赖的Go等 docker info 查看系统(docker)层面信息，包括管理的images, containers数等 docker search &lt;image&gt; 在docker index中搜索image docker pull &lt;image&gt; 从docker registry server 中下拉image docker push &lt;image|repository&gt; 推送一个image或repository到registry docker push &lt;image|repository&gt;:TAG 同上，指定tag docker inspect &lt;image|container&gt; 查看image或container的底层信息 docker images TODO filter out the intermediate image layers (intermediate image layers 是什么) docker images -a 列出所有的images docker ps 默认显示正在运行中的container docker ps -l 显示最后一次创建的container，包括未运行的 docker ps -a 显示所有的container，包括未运行的 docker logs &lt;container&gt; 查看container的日志，也就是执行命令的一些输出 docker rm &lt;container...&gt; 删除一个或多个container docker rm docker ps -a -q&#96;&#96; 删除所有的container docker ps -a -q | xargs docker rm 同上, 删除所有的container docker rmi &lt;image...&gt; 删除一个或多个image docker start/stop/restart &lt;container&gt; 开启&#x2F;停止&#x2F;重启container docker start -i &lt;container&gt; 启动一个container并进入交互模式 docker attach &lt;container&gt; attach一个运行中的container docker commit &lt;container&gt; [repo:tag] 将一个container固化为一个新的image，后面的repo:tag可选 docker build &lt;path&gt; 寻找path路径下名为的Dockerfile的配置文件，使用此配置生成新的image docker build -t repo[:tag] 同上，可以指定repo和可选的tag docker build - &lt; &lt;dockerfile&gt; 使用指定的dockerfile配置文件，docker以stdin方式获取内容，使用此配置生成新的image docker port &lt;container&gt; &lt;container port&gt; 查看本地哪个端口映射到container的指定端口，其实用docker ps 也可以看到","raw":null,"content":null,"categories":[{"name":"Docker","slug":"Docker","permalink":"https://blog.bosong.online/categories/Docker/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://blog.bosong.online/tags/Docker/"}]},{"title":"Springboot集成druid数据库连接池","slug":"Springboot集成druid数据库连接池","date":"2018-10-14T11:35:52.000Z","updated":"2022-06-02T01:05:59.615Z","comments":true,"path":"Springboot集成druid数据库连接池.html","link":"","permalink":"https://blog.bosong.online/Springboot%E9%9B%86%E6%88%90druid%E6%95%B0%E6%8D%AE%E5%BA%93%E8%BF%9E%E6%8E%A5%E6%B1%A0.html","excerpt":"1.使用http://start.spring.io/ 新建web项目，选择springboot版本为1.5.13选择mysql，mybatis，web依赖，下载好生成的demo\n2.导入idea，然后写导入druid依赖","text":"1.使用http://start.spring.io/ 新建web项目，选择springboot版本为1.5.13选择mysql，mybatis，web依赖，下载好生成的demo 2.导入idea，然后写导入druid依赖 12345&lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid&lt;/artifactId&gt; &lt;version&gt;1.0.23&lt;/version&gt;&lt;/dependency&gt; 2.设置druid 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179package com.my.blog.website.config;import com.alibaba.druid.filter.Filter;import com.alibaba.druid.filter.logging.Slf4jLogFilter;import com.alibaba.druid.pool.DruidDataSource;import com.alibaba.druid.support.http.StatViewServlet;import com.alibaba.druid.support.http.WebStatFilter;import com.github.pagehelper.PageHelper;import org.apache.ibatis.plugin.Interceptor;import org.apache.ibatis.session.SqlSessionFactory;import org.mybatis.spring.SqlSessionFactoryBean;import org.mybatis.spring.SqlSessionTemplate;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import org.springframework.boot.context.properties.ConfigurationProperties;import org.springframework.boot.web.servlet.FilterRegistrationBean;import org.springframework.boot.web.servlet.ServletRegistrationBean;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.context.annotation.Primary;import org.springframework.core.io.support.PathMatchingResourcePatternResolver;import org.springframework.core.io.support.ResourcePatternResolver;import org.springframework.jdbc.datasource.DataSourceTransactionManager;import org.springframework.transaction.PlatformTransactionManager;import javax.sql.DataSource;import java.sql.SQLException;import java.util.ArrayList;import java.util.List;import java.util.Properties;/** * cn.sparrowx.druid.conf * * @author bosong * @since 2018/6/11 15:30. */@Configurationpublic class DruidConfiguration &#123; private static final Logger logger = LoggerFactory.getLogger(DruidConfiguration.class); private static final String DB_PREFIX = &quot;spring.datasource&quot;; @Bean public ServletRegistrationBean druidServlet() &#123; logger.info(&quot;init Druid Servlet Configuration &quot;); ServletRegistrationBean servletRegistrationBean = new ServletRegistrationBean(new StatViewServlet(), &quot;/druid/*&quot;); // IP白名单 servletRegistrationBean.addInitParameter(&quot;allow&quot;, &quot;&quot;); // IP黑名单(共同存在时，deny优先于allow) servletRegistrationBean.addInitParameter(&quot;deny&quot;, &quot;&quot;); //控制台管理用户 servletRegistrationBean.addInitParameter(&quot;loginUsername&quot;, &quot;bosong&quot;); servletRegistrationBean.addInitParameter(&quot;loginPassword&quot;, &quot;qwe13579QWE&quot;); //是否能够重置数据 禁用HTML页面上的“Reset All”功能 servletRegistrationBean.addInitParameter(&quot;resetEnable&quot;, &quot;true&quot;); return servletRegistrationBean; &#125; @Bean public FilterRegistrationBean filterRegistrationBean() &#123; FilterRegistrationBean filterRegistrationBean = new FilterRegistrationBean(new WebStatFilter()); filterRegistrationBean.addUrlPatterns(&quot;/*&quot;); filterRegistrationBean.addInitParameter(&quot;exclusions&quot;, &quot;*.js,*.gif,*.jpg,*.png,*.css,*.ico,/druid/*&quot;); return filterRegistrationBean; &#125; List&lt;Filter&gt; list=new ArrayList&lt;&gt;(); @Bean Slf4jLogFilter logfilter()&#123; Slf4jLogFilter slf4jLogFilter=new Slf4jLogFilter(); slf4jLogFilter.setConnectionLogEnabled(false); slf4jLogFilter.setStatementLogEnabled(false); slf4jLogFilter.setStatementExecutableSqlLogEnable(true); slf4jLogFilter.setResultSetLogEnabled(true); list.add(slf4jLogFilter); return slf4jLogFilter; &#125; //解决 spring.datasource.filters=stat,wall,log4j 无法正常注册进去 @ConfigurationProperties(prefix = DB_PREFIX) class IDataSourceProperties &#123; private String url; private String username; private String password; private String filters; private String connectionProperties; @Bean //声明其为Bean实例 @Primary //在同样的DataSource中，首先使用被标注的DataSource public DataSource dataSource() &#123; DruidDataSource datasource = new DruidDataSource(); datasource.setName(&quot;blog-onlie&quot;); datasource.setUrl(url); datasource.setUsername(username); datasource.setPassword(password); //configuration datasource.setInitialSize(1); datasource.setMinIdle(1); datasource.setMaxActive(20); datasource.setMaxWait(60000); datasource.setTimeBetweenLogStatsMillis(300000); datasource.setTimeBetweenEvictionRunsMillis(60000); datasource.setMinEvictableIdleTimeMillis(300000); datasource.setTestWhileIdle(true); datasource.setTestOnBorrow(false); datasource.setTestOnReturn(false); datasource.setPoolPreparedStatements(true); datasource.setMaxPoolPreparedStatementPerConnectionSize(20); datasource.setAsyncInit(true); datasource.setProxyFilters(list); datasource.setValidationQuery(&quot;select &#x27;x&#x27;&quot;); try &#123; datasource.setFilters(filters); &#125; catch (SQLException e) &#123; System.err.println(&quot;druid configuration initialization filter: &quot; + e); &#125; datasource.setConnectionProperties(connectionProperties); return datasource; &#125; @Bean(name = &quot;sqlSessionFactory&quot;) @Primary public SqlSessionFactory sqlSessionFactoryBean() &#123; SqlSessionFactoryBean bean = new SqlSessionFactoryBean(); bean.setDataSource(dataSource()); bean.setTypeAliasesPackage(&quot;com.my.blog.website.model.Vo&quot;); // 分页插件 PageHelper pageHelper = new PageHelper(); Properties properties = new Properties(); properties.setProperty(&quot;reasonable&quot;, &quot;true&quot;); properties.setProperty(&quot;supportMethodsArguments&quot;, &quot;true&quot;); properties.setProperty(&quot;returnPageInfo&quot;, &quot;check&quot;); properties.setProperty(&quot;params&quot;, &quot;count=countSql&quot;); pageHelper.setProperties(properties); // 添加插件 bean.setPlugins(new Interceptor[] &#123;pageHelper&#125;); // 添加XML目录 ResourcePatternResolver resolver = new PathMatchingResourcePatternResolver(); try &#123; bean.setMapperLocations(resolver.getResources(&quot;classpath:mapper/*.xml&quot;)); return bean.getObject(); &#125; catch (Exception e) &#123; throw new RuntimeException(e); &#125; &#125; @Bean @Primary public SqlSessionTemplate sqlSessionTemplate( SqlSessionFactory sqlSessionFactory) &#123; return new SqlSessionTemplate(sqlSessionFactory); &#125; @Bean @Primary public PlatformTransactionManager annotationDrivenTransactionManager() &#123; return new DataSourceTransactionManager(dataSource()); &#125; public String getUrl() &#123; return url; &#125; public void setUrl(String url) &#123; this.url = url; &#125; public String getUsername() &#123; return username; &#125; public void setUsername(String username) &#123; this.username = username; &#125; public String getPassword() &#123; return password; &#125; public void setPassword(String password) &#123; this.password = password; &#125; public String getFilters() &#123; return filters; &#125; public void setFilters(String filters) &#123; this.filters = filters; &#125; public String getConnectionProperties() &#123; return connectionProperties; &#125; public void setConnectionProperties(String connectionProperties) &#123; this.connectionProperties = connectionProperties; &#125; &#125;&#125; 6.配置application.yml 12345678910111213141516171819spring: datasource: type: com.alibaba.druid.pool.DruidDataSource url: jdbc:mysql://xxxxxx:3306/teaching?useSSL=false username: root password: SK7q1NJTgWERV924WLnm7IcxBHjDNJ81UMo10EuFzjcXwblNte68QyxAHpoaV57KHRob7Rle+syYyvaGE2Fa7Q== # 下面为连接池的补充设置，应用到上面所有数据源中 # 配置监控统计拦截的filters，去掉后监控界面sql无法统计，&#x27;wall&#x27;用于防火墙 filters: config,stat,wall,slf4j # 通过connectProperties属性来打开mergeSql功能；慢SQL记录 connectionProperties: druid.stat.mergeSql=true;druid.stat.slowSqlMillis=5000;config.decrypt=true;config.decrypt.key=MFwwDQYJKoZIhvcNAQEBBQADSwAwSAJBAItGtxZCgxe9j3hEBJtW46xjlm6doeYY0/VvOEqcs3VQG5pcA3Tyv0SjjMXAq0zOQdI6nGMXUhtqrMG41Yk7RgMCAwEAAQ== # mybatis配置mybatis: mapper-locations: classpath*:/mapper/*Mapper.xmlserver: port: 10086logging: level: debug file: logs/spring.log 7.数据库密码可以经过加密，加密方法可以直接在网上查询,配置好数据库的查询语句 就可以了 。登录到http://localhost:10086/druid/login.html使用账号密码登录进去即可成功","raw":null,"content":null,"categories":[{"name":"Java","slug":"Java","permalink":"https://blog.bosong.online/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://blog.bosong.online/tags/Java/"}]},{"title":"Linux安装Nginx","slug":"Linux安装Nginx","date":"2018-10-14T11:32:35.000Z","updated":"2022-06-02T01:05:59.613Z","comments":true,"path":"Linux安装Nginx.html","link":"","permalink":"https://blog.bosong.online/Linux%E5%AE%89%E8%A3%85Nginx.html","excerpt":"linux系统为Centos 64位\n第一步：从   http://tengine.taobao.org/download.html   上下载相应的版本，或者","text":"linux系统为Centos 64位 第一步：从 http://tengine.taobao.org/download.html 上下载相应的版本，或者 1wget http://nginx.org/download/nginx-1.5.9.tar.gz 第二步：解压 tar -zxvf nginx-1.5.9.tar.gz 第三步：安装必要的软件 1yum -y install pcre-devel openssl openssl-devel 第四步：设置一下配置信息 1./configure --prefix=/data/nginx --with-http_stub_status_module --with-http_ssl_module --with-file-aio --with-http_realip_module ，或者不执行此步，直接默认配置 第四步： make 编译 （make的过程是把各种语言写的源码文件，变成可执行文件和各种库文件） make install 安装 （make install是把这些编译出来的可执行文件和库文件复制到合适的地方） 第五步：将nginx放在启动命令中 vi /etc/profile 将 123#nginxexport NGINX_HOME=/data/nginxexport PATH=$NGINX_HOME/sbin:$PATH 放在/etc/profile尾部后，执行source /etc/profile #第六步：启动nginx或者检查nginx配置 nginx / nginx -t","raw":null,"content":null,"categories":[{"name":"Linux","slug":"Linux","permalink":"https://blog.bosong.online/categories/Linux/"}],"tags":[{"name":"nginx","slug":"nginx","permalink":"https://blog.bosong.online/tags/nginx/"}]},{"title":"Linux安装maven","slug":"Linux安装Maven","date":"2018-10-14T11:30:41.000Z","updated":"2022-06-02T01:05:59.613Z","comments":true,"path":"Linux安装Maven.html","link":"","permalink":"https://blog.bosong.online/Linux%E5%AE%89%E8%A3%85Maven.html","excerpt":"1.mkdir -p /data/maven\n2.wget http://mirrors.shu.edu.cn/apache/maven/maven-3/3.5.3/binaries/apache-maven-3.5.3-bin.tar.gz","text":"1.mkdir -p /data/maven 2.wget http://mirrors.shu.edu.cn/apache/maven/maven-3/3.5.3/binaries/apache-maven-3.5.3-bin.tar.gz 3.tar -zxvf apache-maven-3.5.3-bin.tar.gz 4.修改conf setting 1234567&lt;mirror&gt; &lt;id&gt;nexus-aliyun&lt;/id&gt; &lt;mirrorOf&gt;central&lt;/mirrorOf&gt; &lt;name&gt;Nexus aliyun&lt;/name&gt; &lt;url&gt;http://maven.aliyun.com/nexus/content/groups/public&lt;/url&gt; &lt;/mirror&gt; &lt;localRepository&gt;/data/java/repo&lt;/localRepository&gt; 5.vi /etc/profile 123export MAVEN_HOME=/usr/local/maven/apache-maven-3.5.2PATH=$JAVA_HOME/bin:$MAVEN_HOME/bin:$PATH 保存source /etc/profile","raw":null,"content":null,"categories":[{"name":"Linux","slug":"Linux","permalink":"https://blog.bosong.online/categories/Linux/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://blog.bosong.online/tags/Java/"}]},{"title":"Linux安装JDK","slug":"Linux安装Jdk","date":"2018-10-14T11:29:27.000Z","updated":"2022-06-02T01:05:59.613Z","comments":true,"path":"Linux安装Jdk.html","link":"","permalink":"https://blog.bosong.online/Linux%E5%AE%89%E8%A3%85Jdk.html","excerpt":"1.将jdk-8u60-linux-x64.tar.gz拷贝到java目录下\ncp /mnt/hgfs/linux/jdk-8u60-linux-x64.tar.gz /usr/java/","text":"1.将jdk-8u60-linux-x64.tar.gz拷贝到java目录下 cp /mnt/hgfs/linux/jdk-8u60-linux-x64.tar.gz /usr/java/ 2.解压jdk到当前目录 tar -zxvf jdk-8u60-linux-x64.tar.gz 得到文件夹 jdk1.8.0_60 3.安装完毕为他建立一个链接以节省目录长度 (我没用这一步) ln -s /usr/java/jdk1.8.0_144/ /usr/jdk 4.编辑配置文件，配置环境变量 vim /etc/profile 添加如下内容：JAVA_HOME根据实际目录来 JAVA_HOME=/usr/java/jdk1.8.0_60 CLASSPATH=$JAVA_HOME/lib/ PATH=$PATH:$JAVA_HOME/bin export PATH JAVA_HOME CLASSPATH 5.重启机器或执行命令 ：source /etc/profile or sudo shutdown -r now 6.查看安装情况 java -version","raw":null,"content":null,"categories":[{"name":"Linux","slug":"Linux","permalink":"https://blog.bosong.online/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://blog.bosong.online/tags/Linux/"}]},{"title":"公网环境下部署Elasticsearch","slug":"公网环境下部署Elasticsearch","date":"2018-10-14T10:06:14.000Z","updated":"2022-06-02T01:05:59.617Z","comments":true,"path":"公网环境下部署Elasticsearch.html","link":"","permalink":"https://blog.bosong.online/%E5%85%AC%E7%BD%91%E7%8E%AF%E5%A2%83%E4%B8%8B%E9%83%A8%E7%BD%B2Elasticsearch.html","excerpt":"1.下载elasticsearch:\ncurl -L -O https://download.elastic.co/elasticsearch/release/org/elasticsearch/distribution/tar/elasticsearch/2.4.0/elasticsearch-2.4.0.tar.gz","text":"1.下载elasticsearch: curl -L -O https://download.elastic.co/elasticsearch/release/org/elasticsearch/distribution/tar/elasticsearch/2.4.0/elasticsearch-2.4.0.tar.gz 2.解压: tar -xvf elasticsearch-2.4.0.tar.gz 3.编辑elasticsearch.yml vi ./config/elasticsearch.yml(此设置每一项之前都必须有空格，否则运行报错，切记切记) 集群名 cluster.name: elasticsearch 节点名node.name: node-1 存储数据和log地址，可以自配，但是需要自建path.data: /data/elasticsearch/data path.logs:/data/elasticsearch/logs 开放存储bootstrap.mlockall: true Set the bind address to a specific IP (IPv4 or IPv6): network.bind_host: 0.0.0.0 network.publish_host: 115.239.210.27（如果是在局域网内配置，三个IP都可以配置成一样的，如果是公网内联机，此项需要配成真实IP地址） network.host: 0.0.0.0 Set a custom port for HTTP: transport.tcp.port: 9300 http.port: 9200 集群内联机IP（公网）discovery.zen.ping.unicast.hosts: [&quot;0.0.0.0&quot;, &quot;115.239.210.27&quot;] 集群可存活的最小节点，建议设置为1discovery.zen.minimum_master_nodes: 1 附：配置项网址http://www.cnblogs.com/hanyouchun/p/5163183.html 配置文件中给出了三种配置高性能集群拓扑结构的模式,如下：1.如果你想让节点从不选举为主节点,只用来存储数据,可作为负载器 node.master: false node.data: true 2.如果想让节点成为主节点,且不存储任何数据,并保有空闲资源,可作为协调器 node.master: true node.data: false 3.如果想让节点既不称为主节点,又不成为数据节点,那么可将他作为搜索器,从节点中获取数据,生成搜索结果等 node.master: false node.data: false 4.安装插件./bin/plugin install mobz/elasticsearch-head 5.启动 如果当前是root用户 vi ./bin/elasticsearch将 设置该属性为ES_JAVA_OPTS=&quot;-Des.insecure.allow.root=true&quot; 前台启动（测试是否启动成功） ./bin/elasticsearch -Xms512m -Xmx512m 后台启动 ./elasticsearch -d -Xms512m -Xmx512m 6.部署完成，更多的细节需要自己花时间去挖掘","raw":null,"content":null,"categories":[{"name":"Linux","slug":"Linux","permalink":"https://blog.bosong.online/categories/Linux/"}],"tags":[{"name":"elasticsearch","slug":"elasticsearch","permalink":"https://blog.bosong.online/tags/elasticsearch/"}]},{"title":"markdown实用语法","slug":"Markdown实用语法","date":"2018-10-14T10:04:31.000Z","updated":"2022-06-02T01:05:59.614Z","comments":true,"path":"Markdown实用语法.html","link":"","permalink":"https://blog.bosong.online/Markdown%E5%AE%9E%E7%94%A8%E8%AF%AD%E6%B3%95.html","excerpt":"欢迎使用Markdown编辑器写博客本Markdown编辑器使用[StackEdit][6]修改而来，用它写博客，将会带来全新的体验哦：","text":"欢迎使用Markdown编辑器写博客本Markdown编辑器使用[StackEdit][6]修改而来，用它写博客，将会带来全新的体验哦： Markdown和扩展Markdown简洁的语法 代码块高亮 图片链接和图片上传 LaTex数学公式 UML序列图和流程图 离线写博客 导入导出Markdown文件 丰富的快捷键 快捷键 加粗 Ctrl + B 斜体 Ctrl + I 引用 Ctrl + Q 插入链接 Ctrl + L 插入代码 Ctrl + K 插入图片 Ctrl + G 提升标题 Ctrl + H 有序列表 Ctrl + O 无序列表 Ctrl + U 横线 Ctrl + R 撤销 Ctrl + Z 重做 Ctrl + YMarkdown及扩展 Markdown 是一种轻量级标记语言，它允许人们使用易读易写的纯文本格式编写文档，然后转换成格式丰富的HTML页面。 —— [ 维基百科 ]使用简单的符号标识不同的标题，将某些文字标记为粗体或者斜体，创建一个链接等，详细语法参考帮助？。本编辑器支持 Markdown Extra , 扩展了很多好用的功能。具体请参考[Github][2]. 表格Markdown Extra 表格语法： 项目 价格 Computer $1600 Phone $12 Pipe $1 可以使用冒号来定义对齐方式： 项目 价格 :——– ——–: Computer 1600 元 Phone 12 元 Pipe 1 元 ###定义列表 Markdown Extra 定义列表语法： 项目１ 项目２ : 定义 A : 定义 B 项目３ : 定义 C : 定义 D 定义D内容 代码块代码块语法遵循标准markdown代码，例如： 12345678910@requires_authorizationdef somefunc(param1=&#x27;&#x27;, param2=0):&#x27;&#x27;&#x27;A docstring&#x27;&#x27;&#x27;if param1 &gt; param2: # interestingprint &#x27;Greater&#x27;return (param2 - param1 + 1) or Noneclass SomeClass:pass&gt;&gt;&gt; message = &#x27;&#x27;&#x27;interpreter... prompt&#x27;&#x27;&#x27; ###脚注生成一个脚注[^footnote].[^footnote]: 这里是 脚注 的 内容. 目录用 [TOC]来生成目录：[TOC] 数学公式使用MathJax渲染LaTex 数学公式，详见[math.stackexchange.com][1]. 行内公式，数学公式为：$\\Gamma(n) &#x3D; (n-1)!\\quad\\forall n\\in\\mathbb N$。 块级公式： $$ x &#x3D; \\dfrac{-b \\pm \\sqrt{b^2 - 4ac}}{2a} $$更多LaTex语法请参考 [这儿][3].UML 图:可以渲染序列图：123张三-&gt;李四: 嘿，小四儿, 写博客了没?Note right of 李四: 李四愣了一下，说：李四--&gt;张三: 忙得吐血，哪有时间写。 或者流程图：1234567st=&gt;start: 开始e=&gt;end: 结束op=&gt;operation: 我的操作cond=&gt;condition: 确认？st-&gt;op-&gt;condcond(yes)-&gt;econd(no)-&gt;op 关于 序列图 语法，参考 [这儿][4], 关于 流程图 语法，参考 [这儿][5].离线写博客即使用户在没有网络的情况下，也可以通过本编辑器离线写博客（直接在曾经使用过的浏览器中输入write.blog.csdn.net&#x2F;mdeditor即可。Markdown编辑器使用浏览器离线存储将内容保存在本地。用户写博客的过程中，内容实时保存在浏览器缓存中，在用户关闭浏览器或者其它异常情况下，内容不会丢失。用户再次打开浏览器时，会显示上次用户正在编辑的没有发表的内容。博客发表后，本地缓存将被删除。 用户可以选择 把正在写的博客保存到服务器草稿箱，即使换浏览器或者清除缓存，内容也不会丢失。 注意：虽然浏览器存储大部分时候都比较可靠，但为了您的数据安全，在联网后，请务必及时发表或者保存到服务器草稿箱。##浏览器兼容 目前，本编辑器对Chrome浏览器支持最为完整。建议大家使用较新版本的Chrome。 IE９以下不支持 IE９，１０，１１存在以下问题 不支持离线功能 IE9不支持文件导入导出 IE10不支持拖拽文件导入","raw":null,"content":null,"categories":[{"name":"技术手册","slug":"技术手册","permalink":"https://blog.bosong.online/categories/%E6%8A%80%E6%9C%AF%E6%89%8B%E5%86%8C/"}],"tags":[{"name":"markdown","slug":"markdown","permalink":"https://blog.bosong.online/tags/markdown/"}]},{"title":"redis线上管理工具","slug":"Redis线上管理工具","date":"2018-10-14T10:01:34.000Z","updated":"2022-06-02T01:05:59.615Z","comments":true,"path":"Redis线上管理工具.html","link":"","permalink":"https://blog.bosong.online/Redis%E7%BA%BF%E4%B8%8A%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7.html","excerpt":"","text":"1.使用docker安装redis下载redis镜像 docker pull redis 然后直接直接 docker run -d -p 31522:6379 -v /data/redis-data:/data --name redis redis redis-server --appendonly yes --requirepass &#39;yourpassword&#39; 参数解释：-p 31522:6379 修改redis对外暴露端口号 -v /data/redis-data:/data 将redis数据保存在宿主机上 --appendonly yes 开启数据持久化 --requirepass &#39;yourpassword&#39; 设置redis访问密码 2.安装redis管理工具并使用nginx对外反向代理使用git clone项目 Python环境 python &gt;&#x3D; 2.7 clone项目和虚拟环境依赖安装123mkdir -p /data/wwwroot/ &amp;&amp; cd /data/wwwrootgit clone https://gitee.com/careyjike_173/redis_web_client.git redis_admincd redis_admin &amp;&amp; pip install -r requirements.txt 数据库配置配置文件在项目目录下conf&#x2F;conf.py文件中 12345678// 数据库信息database = &#123; &quot;name&quot;: &quot;redis_admin&quot;, &quot;host&quot;: &quot;127.0.0.1&quot;, &quot;username&quot;: &quot;root&quot;, &quot;password&quot;: &quot;root&quot;, &quot;port&quot;: &quot;3306&quot;,&#125; 生成数据库表文件1python manage.py migrate 创建管理员用户1python manage.py createsuperuser 配置nginx123456789101112131415server &#123;listen 80;server_name _;access_log /data/wwwlogs/access_nginx.log combined;index index.html index.htm index.php;location / &#123; proxy_pass http://127.0.0.1:8000;&#125;location /static &#123; expires 7d; autoindex on; add_header Cache-Control provate; alias /data/wwwroot/redis_admin/static; &#125;&#125; 启动 redis_admin12chmod +x start.sh./start.sh start 启动后请检查是否监听8000端口，如未启动请查看log目录下日志信息 启动nginx1service nginx start 访问浏览器 http://ip/ 项目配置文件说明12345678910111213141516171819202122232425262728293031323334353637383940#DEBUG值:True/False 开启debug模式，使用请将其改为False###LOG_LEVEL值:ERROR/WARNING/INFO/DEBUG日志级别#####socket_timeout值: 2,数字连接redis超时时间##### scan_batch值: 10000,数字如果redis key过多避免导致性能问题，key列表最多获取值##### mail_host邮箱smtp服务器地址##### mail_user邮箱用户##### mail_pass邮箱密码##### mail_receivers邮件接收者##### admin_mail管理员邮箱##### 数据库信息database = &#123; &quot;name&quot;: &quot;redis_admin&quot;, //数据库名称 &quot;host&quot;: &quot;127.0.0.1&quot;, //连接地址 &quot;username&quot;: &quot;root&quot;, //用户名 &quot;password&quot;: &quot;root&quot;, //密码 &quot;port&quot;: &quot;3306&quot;, //端口&#125; ####添加redis 名称: 单机redis请注意唯一性, cluster请一致性 主机: redis主机地址 端口: redis端口 DB数: 请保持和redis配置文件中db数量一致 密码: 如redis有密码请填写 如redis为cluster模式，请添加多个redis，名称保持一致并勾选类型为cluster 添加配置后请为用户配置redis权限，被授权用户需要退出登陆方可看的左侧菜单栏显示 编辑redis这里只需要点击单元格信息即可进行修改，编辑按钮是为了提示信息 左侧菜单栏和权限相关联并进行了本地缓存，配置了redis后需要在用户管理中给相应用户授权，被授权用户需要退出重新登陆即可看到左侧菜单栏 用户管理这里可对用户进行管理，如添加，编辑，删除用户 重点: 添加redis配置后需要在此编辑用户，为用户授权redis并退出登陆后才可看到右侧菜单栏信息 分之说明 master为主开发分支，体验最新版本可clone该版本 Vx.x.x 为稳定发布版本","raw":null,"content":null,"categories":[{"name":"数据库","slug":"数据库","permalink":"https://blog.bosong.online/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"redis","slug":"redis","permalink":"https://blog.bosong.online/tags/redis/"}]},{"title":"Docker备份Mysql数据库","slug":"Docker备份Mysql数据库","date":"2018-10-14T10:00:12.000Z","updated":"2022-06-02T01:05:59.612Z","comments":true,"path":"Docker备份Mysql数据库.html","link":"","permalink":"https://blog.bosong.online/Docker%E5%A4%87%E4%BB%BDMysql%E6%95%B0%E6%8D%AE%E5%BA%93.html","excerpt":"1.备份数据库脚本vi dump.sh","text":"1.备份数据库脚本vi dump.sh 123456789101112mysql=`docker ps|grep mysql | awk &#x27;&#123;print $1&#125;&#x27;`backDate=`date +%F_%H-%M-%S`if [ ! -e &quot;/data/backup/$backDate&quot; ]; then mkdir -p /data/backup/$backDatefiecho $mysqldataBases=&quot;teaching&quot;; //备份数据库名称for dataname in $&#123;dataBases&#125;do docker exec -i $mysql mysqldump -h localhost --opt -u root --password=mypassword --default-character-set=utf8 --hex-blob $dataname &gt; /data/backup/$backDate/$dataname-$backDate.sqldone 2.linux设置定时任务crontab -e 130 2 * * * sh -x /root/mysql/dump.sh &gt; /data/backup/back_mysql.log 2&gt;&amp;1 30 2 代表凌晨2点30分执行脚本 * * * sh -x /root/mysql/dump.sh &gt; 执行路径下dump.sh脚本 /data/backup/back_mysql.log 2&gt;&amp;1 记录备份日志 备份mysql数据库完成","raw":null,"content":null,"categories":[{"name":"Docker","slug":"Docker","permalink":"https://blog.bosong.online/categories/Docker/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://blog.bosong.online/tags/Docker/"}]},{"title":"Java5-8新特性一览","slug":"Java5-8新特性一览","date":"2018-10-14T09:58:46.000Z","updated":"2022-06-02T01:05:59.613Z","comments":true,"path":"Java5-8新特性一览.html","link":"","permalink":"https://blog.bosong.online/Java5-8%E6%96%B0%E7%89%B9%E6%80%A7%E4%B8%80%E8%A7%88.html","excerpt":"jdk5新特性\n1、自动装箱和拆箱","text":"jdk5新特性 1、自动装箱和拆箱 2、枚举 3、静态导入 4、可变参数 5、內省 是Java语言对Bean类属性、事件的一种缺省处理方法。例如类A中有属性那么，那我们可以通过getName，setName来得到其值或者设置新的值。通过getName&#x2F;setName来访问name属性，这就是默认的规则。Java中提供了一套API用来访问某个属性的getter，setter方法，通过这些API可以使你不需要了解这个规则，这些API存放于包java.beans中。 一般的做法是通过类Introspector来获取某个对象的BeanInfo信息，然后通过BeanInfo来获取属性的描述器（PropertyDescriptor），通过这个属性描述器就可以获取某个属性对应的getter&#x2F;setter方法，然后我们就可以通过反射机制来调用这些方法。 6、泛型 7、For-Each循环 jdk6新特性 1、Desktop类和SystemTray类 AWT新增加了两个雷：Desktop，SystemTray。 Desktop可以用来打开系统默认浏览器指定的URL，打开系统默认邮件客户端给指定的邮件账号发邮件，用默认应用程序打开或编辑文件（比如，用记事本打开txt文件），用系统默认的打印机打印文档SystemTray可以用来在系统托盘区创建一个托盘程序 2、使用JAXB2来实现对象与XML之间的映射也就是对象与XML之间的映射（OXM），也可以通过XMLBeans和Castor等来实现同样的功能。 3、StAX StAX是The Streaming API for XML的缩写，一种利用拉模式解析(pull-parsing)XML文档的API.StAX通过提供一种基于事件迭代器(Iterator)的API让 程序员去控制xml文档解析过程,程序遍历这个事件迭代器去处理每一个解析事件，解析事件可以看做是程序拉出来的，也就是程序促使解析器产生一个解析事件 然后处理该事件，之后又促使解析器产生下一个解析事件，如此循环直到碰到文档结束符； SAX也是基于事件处理xml文档，但却 是用推模式解析，解析器解析完整个xml文档后，才产生解析事件，然后推给程序去处理这些事件；DOM 采用的方式是将整个xml文档映射到一颗内存树，这样就可以很容易地得到父节点和子结点以及兄弟节点的数据，但如果文档很大，将会严重影响性能。 4、使用Compiler API使用JDK6的Compiler API去动态的编译Java源文件，Compiler API结合反射功能就可以实现动态的产生Java代码并编译执行这些代码。 5、轻量级Http Server API 6、插入式注解处理API 7、用Console开发控制台程序 8、对脚本语言的支持如：ruby，groovy，javascript 9、Common Annotations jdk7新特性 1、switch中可以使用字符串 2、泛型的自动判断 3、自定义自动关闭类（实现AutoCloseable接口） 4、新增一些取环境信息的工具方法（System中的方法） 5、Boolean类型反转，空指针安全，参数与位运算 6、两个char间的equals 7、安全的加减乘除 1、对Java集合（Collections）的增强支持 123456List&lt;String&gt; list=[&quot;item&quot;]; //向List集合中添加元素String item=list[0]; //从List集合中获取元素Set&lt;String&gt; set=&#123;&quot;item&quot;&#125;; //向Set集合对象中添加元Map&lt;String,Integer&gt; map=&#123;&quot;key&quot;:1&#125;; //向Map集合中添加对象int value=map[&quot;key&quot;]; //从Map集合中获取对象但是经过自己测试，按照上面的使用方法，并不能创建集合。 2、int支持二进制数据 3、在try catch异常捕捉中，一个catch可以写多个异常类型 123456789101112131415161718Connection conn = null;try &#123; Class.forName(&quot;com.mysql.jdbc.Driver&quot;); conn = DriverManager.getConnection(&quot;&quot;,&quot;&quot;,&quot;&quot;);&#125; catch(ClassNotFoundException|SQLException ex) &#123; ex.printStackTrace();&#125;4、try catch中资源定义好之后try catch自动关闭try (BufferedReader in = new BufferedReader(new FileReader(&quot;in.txt&quot;)); BufferedWriter out = new BufferedWriter(new FileWriter(&quot;out.txt&quot;))) &#123;int charRead;while ((charRead = in.read()) != -1) &#123; System.out.printf(&quot;%c &quot;, (char)charRead); out.write(charRead); &#125;&#125; catch (IOException ex) &#123; ex.printStackTrace();&#125; jdk8新特性 1、接口的默认方法 Java 8允许我们给接口添加一个非抽象的方法实现，只需要使用default关键字即可，这个特征又叫做扩展方法，示例如下： 123456public interface Formula &#123; double calculate(int a); default double sqrt(int a) &#123;return Math.sqrt(a); &#125;&#125; Formula接口在拥有calculate方法之外同时还定义了sqrt方法，实现了Formula接口的子类只需要实现一个calculate方法，默认方法sqrt将在子类上可以直接使用。 12345678 Formula formula = new Formula() &#123;@Overridepublic double calculate(int a) &#123;return sqrt(a * 100); &#125; &#125;; System.out.println(formula.calculate(100)); // 100.0 System.out.println(formula.sqrt(16)); // 4.0 文中的formula被实现为一个匿名类的实例，该代码非常2、Lambda表达式 1234567List&lt;String&gt; names = Arrays.asList(&quot;tom&quot;,&quot;jace&quot;,&quot;mike&quot;);Collections.sort(names, new Comparator&lt;String&gt;() &#123;@Overridepublic int compare(String o1, String o2) &#123;return o2.compareTo(o1); &#125;&#125;); 只需要给静态方法Collections.sort传入一个List对象以及一个比较器来指定顺序排列。通常做法都是创建一个匿名的比较器对象，然后将其传递给sort方法。 在Java 8中提供了更简洁的语法，lambda表达式： 123Collections.sort(names, (String a, String b) -&gt; &#123;return b.compareTo(a);&#125;); 还可以更简洁： 1Collections.sort(names, (String a, String b) -&gt; b.compareTo(a)); 去掉大括号以及return关键字 1Collections.sort(names, (a,b) -&gt; b.compareTo(a)); Java编译器可以自动推导出参数类型，所以可以不用再写一次类型。 3、函数式接口 Lambda表达式是如何在java的类型系统中表示的呢？每一个lambda表达式都对应着一个类型，通常是接口类型。而“函数式接口”是指仅仅只包含一个抽象方法的接口，每一个该类型的lambda表达式都会被匹配到这个抽象方法。因为默认方法不算抽象方法，所以也可以给自己的函数式接口添加默认方法。我们可以将lambda表达式当做一个抽象方法的接口类型，确保自己的接口一定达到这个要求，你只需要给你的接口添加@FunctionalInterface注解，编译器如果发现标注了这个注解的接口有多于一个抽象方法的时候就会报错。也就是说@ FunctionalInterface注解标注的接口只能有一个抽象方法。 例如： 1234567@FunctionalInterfacepublic interface Converter&lt;F, T&gt; &#123;T convert(F from);&#125;Converter&lt;String, Integer&gt; converter = (from) -&gt; Integer.valueOf(from);Integer converted = converter.convert(&quot;123&quot;);System.out.println(converted); 以上代码不需要@FunctionalInterface注解也是正确的。 4、方法与构造函数引用 上面的代码也可以通过静态方法引用来表示： 1234567891011121314Converter&lt;String, Integer&gt; converter = Integer::valueOf;Integer converted = converter.convert(&quot;123&quot;);System.out.println(converted);Java8允许使用::关键字来传递方法或者构造函数引用，上面的代码展示了如何引用一个静态方法，我们也可以引用一个对象的方法：public class Person &#123; String firstName; String lastName; Person() &#123; &#125;public Person(String firstName, String lastName) &#123;this.firstName = firstName;this.lastName = lastName; &#125;&#125; 指定一个用来创建Person对象的对象工厂接口： 123public interface PersonFactory&lt;P extends Person&gt; &#123;P create(String fisrtName, String lastName);&#125; 创建Person对象 12PersonFactory&lt;Person&gt; personFactory = Person::new;Person person = personFactory.create(&quot;Peter&quot;,&quot;Parker”); 我们只需要使用Person::new 来获取Person类构造函数的引用，Java编译器就会自动根据PersonFactory.create方法的签名来选择合适的构造函数。 5、Lambda作用域 在lambda表达式中访问外层作用域和老版本的匿名对象中的方式很相似。你可以直接访问标记了final的外层局部变量，或者实例的字段以及静态变量。 6、访问局部变量 我们可以直接在lambda表达式中访问外层的局部变量 123final int num = 1;Converter&lt;Integer, String&gt; stringConverter = (from) -&gt; String.valueOf(from + num);stringConverter.convert(2); 但是和匿名对象不同的是，这里的变量num可以不用声明为final，该代码同样正确。 7、访问对象字段与静态变量和本地不良不同的是，lambda内部对于实例的字段以及静态变量是即可读又可写。该行为和匿名对象是一致的： 123456789101112static int outerStaticNum;int outerNum;public void testScopes() &#123; Converter stringConverter1 = (from) -&gt; &#123; outerNum = 23; return String.valueOf(from); &#125;; Converter stringConverter2 = (from) -&gt; &#123; outerStaticNum = 72; return String.valueOf(from); &#125;;&#125; 8、访问接口的默认方法 9、Date API 10、Annotation注解","raw":null,"content":null,"categories":[{"name":"Java","slug":"Java","permalink":"https://blog.bosong.online/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://blog.bosong.online/tags/Java/"}]},{"title":"Docker制作jdk镜像","slug":"Docker制作jdk镜像","date":"2018-10-14T09:55:13.000Z","updated":"2022-06-02T01:05:59.611Z","comments":true,"path":"Docker制作jdk镜像.html","link":"","permalink":"https://blog.bosong.online/Docker%E5%88%B6%E4%BD%9Cjdk%E9%95%9C%E5%83%8F.html","excerpt":"由于相关需求，现有的docker制作的jdk镜像是Java8早期版本的镜像，在安全性上存在较大的问题，所以计划对docker依赖的系统以及jdk进行升级操作。这其中遇到了一些问题，不过都顺利的圆满解决了，下面来具体聊一聊细节把\ndocker制作JDK镜像选型","text":"由于相关需求，现有的docker制作的jdk镜像是Java8早期版本的镜像，在安全性上存在较大的问题，所以计划对docker依赖的系统以及jdk进行升级操作。这其中遇到了一些问题，不过都顺利的圆满解决了，下面来具体聊一聊细节把 docker制作JDK镜像选型为了减小容器的体积，所以考虑使用alpine的镜像，这次选择alpine没有做版本相关的限制，考虑最新版本的镜像在安全性上会有一个较大的提升，目前经过阿里云的安全扫描，相关漏洞的个数为0； JDK选择的也是JDK8的最新长期支持版，JDK8相对来说目前使用比较广泛，而且稳定性较高。 docker制作JDK第一版的过程由于alpine镜像作为极小型的Linux容器，它的运行环境是没法直接运行JDK的，所以需要新增一些依赖来进行相关兼容，在此过程中安装了glibc-2.31-r0.apk，该包在Github上下载的，由于服务器带宽较低，所以下载速度奇慢，所以自己将对应的包下载下来，放到了腾讯云的COS上供自己下载使用。 下面是第一版Dockerfile的内容 123456789101112131415161718192021FROM alpine:latestMAINTAINER dislazy2019@outlook.comRUN echo http://mirrors.aliyun.com/alpine/v3.7/main &gt; /etc/apk/repositories &amp;&amp; \\echo http://mirrors.aliyun.com/alpine/v3.7/community &gt;&gt; /etc/apk/repositoriesRUN apk update &amp;&amp; apk upgradeRUN wget -q -O /etc/apk/keys/sgerrand.rsa.pub https://imagecdn.bosong.online/sgerrand.rsa.pub &amp;&amp; \\ wget https://imagecdn.bosong.online/glibc-2.31-r0.apk &amp;&amp; \\ apk add glibc-bin-2.31-r0.apkADD jdk1.8.0_231 /usr/localENV JAVA_HOME=/usr/local/jdk1.8.0_231ENV CLASSPATH=$JAVA_HOME/binENV JRE_HOME=/usr/local/jdk1.8.0_231/jreENV PATH=$JAVA_HOME/bin:$PATHCMD [&quot;java&quot;,&quot;-version&quot;] 在上面的镜像中，只安装了运行JDK所需要的相关包以及将JDK放到了容器文件中，其实在此之前有一步是需要对JDK进行内容的删减，删减一些多余的JAR包和介绍文件，来达到减少容器体积的目的。 时区问题JDK镜像制作成功后，很顺利的推到了阿里云的镜像仓库中，并且迅速进行服务的打包部署，一切都进行的很顺利，服务也正常运行并启动。 后来在查看日志的过程中，发现服务运行日志的时差达到了8个小时，马上想到了没设置正确的时区，导致Java运行获取的当地时间不正确，这问题在生产中是致命的，然后迅速进行第二次镜像升级改造，本次主要正确设置了时区，使Java进行按照本地时间运行。 下面是第二版Dockerfile的内容 1234567891011121314151617181920FROM alpine:latestMAINTAINER dislazy2019@outlook.comRUN echo http://mirrors.aliyun.com/alpine/v3.7/main &gt; /etc/apk/repositories &amp;&amp; \\echo http://mirrors.aliyun.com/alpine/v3.7/community &gt;&gt; /etc/apk/repositoriesRUN apk update &amp;&amp; apk upgrade &amp;&amp; ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime &amp;&amp; echo &quot;Asia/Shanghai&quot; &gt; /etc/timezoneRUN wget -q -O /etc/apk/keys/sgerrand.rsa.pub https://imagecdn.bosong.online/sgerrand.rsa.pub &amp;&amp; \\ wget https://imagecdn.bosong.online/glibc-2.31-r0.apk &amp;&amp; \\ apk add glibc-bin-2.31-r0.apkADD jdk1.8.0_231 /usr/localENV JAVA_HOME=/usr/local/jdk1.8.0_231ENV CLASSPATH=$JAVA_HOME/binENV JRE_HOME=/usr/local/jdk1.8.0_231/jreENV PATH=$JAVA_HOME/bin:$PATHCMD [&quot;java&quot;,&quot;-version&quot;] 上面的镜像设置了时区文件，顺利解决了时区的问题。 编码问题作为一个程序员，对乱码这个一定会异常的敏感，在大学计算机的课堂上，对于这个问题始终会强调，编码问题是数据可读性的重要保障，一个不慎，可能全盘皆输。 问题的发现比较偶然，因为我平常在工作中养成的工作习惯是日志基本使用英文，能不使用中文尽量不使用，所以一直没发现中文编码存在问题，后来因为接入了美团Cat，想试试告警效果，然后发现相关告警发送到企业微信的时候发现是乱码，此时才想到没有对乱码问题进行及时设置，此时有了第三版本的JDK镜像。 下面是第三版本的Dokcerfile 123456789101112131415161718192021222324252627FROM alpine:latestMAINTAINER dislazy2019@outlook.comRUN echo http://mirrors.aliyun.com/alpine/v3.7/main &gt; /etc/apk/repositories &amp;&amp; \\echo http://mirrors.aliyun.com/alpine/v3.7/community &gt;&gt; /etc/apk/repositoriesRUN apk update &amp;&amp; apk upgrade &amp;&amp; ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime &amp;&amp; echo &quot;Asia/Shanghai&quot; &gt; /etc/timezoneRUN wget -q -O /etc/apk/keys/sgerrand.rsa.pub https://imagecdn.bosong.online/sgerrand.rsa.pub &amp;&amp; \\ wget https://imagecdn.bosong.online/glibc-2.31-r0.apk &amp;&amp; \\ wget https://imagecdn.bosong.online/glibc-bin-2.31-r0.apk &amp;&amp; \\ wget https://imagecdn.bosong.online/glibc-i18n-2.31-r0.apk &amp;&amp; \\ apk add glibc-bin-2.31-r0.apk glibc-i18n-2.31-r0.apk glibc-2.31-r0.apk#复制本地编辑的locale.mdCOPY ./locale.md /locale.md#此时设置utfu编码RUN cat locale.md | xargs -i /usr/glibc-compat/bin/localedef -i &#123;&#125; -f UTF-8 &#123;&#125;.UTF-8ADD jdk1.8.0_231 /usr/localENV JAVA_HOME=/usr/local/jdk1.8.0_231ENV CLASSPATH=$JAVA_HOME/binENV JRE_HOME=/usr/local/jdk1.8.0_231/jreENV PATH=$JAVA_HOME/bin:$PATHENV LANG=en_US.UTF-8ENV LANGUAGE=en_US.UTF-8CMD [&quot;java&quot;,&quot;-version&quot;] 为了加快镜像的构建速度，所以把必要的jar包都放到了腾讯云的COS上，以便于快速下载以及备份。 其中locale.md文件内容如下,有些不必要用到的我都给移除掉了，能大大节省镜像的构建速度 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647el_CYel_GRen_AGen_AUen_BWen_CAen_DKen_GBen_HKen_IEen_INen_NGen_NZen_PHen_SGen_USen_ZAen_ZMen_ZWes_ARes_BOes_CLes_COes_CRes_CUes_DOes_ECes_ESes_GTes_HNes_MXes_NIes_PAes_PEes_PRes_PYes_SVes_USes_UYes_VEet_EEeu_ESzh_CNzh_HKzh_SGzh_TWzu_ZA 该问题比较经典，在github上也有解决方案，主要原因就是alpine镜像本身原因没有对一些需要的特性需要支持，顺利解决了时区问题以及乱码问题，服务目前平稳运行，可以大大松口气。 结束语以前用别人制作好的JDK镜像，发现很香，很多问题都不需要去考虑，直接拿来就用。 在自己制作并投入使用的时候会出现很多状况，所以我们制作镜像前后最好先了解一下有哪些坑，提前发现并且避免掉，这样才能减少错误，快速做好镜像。","raw":null,"content":null,"categories":[{"name":"Docker","slug":"Docker","permalink":"https://blog.bosong.online/categories/Docker/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://blog.bosong.online/tags/Docker/"}]},{"title":"Docker故障记录","slug":"Docker故障记录","date":"2018-10-14T09:55:13.000Z","updated":"2022-06-02T01:05:59.612Z","comments":true,"path":"Docker故障记录.html","link":"","permalink":"https://blog.bosong.online/Docker%E6%95%85%E9%9A%9C%E8%AE%B0%E5%BD%95.html","excerpt":"1.故障起因正常使用docker查看镜像日志过程中，发现系统插播了一条奇怪的错误日志，如下","text":"1.故障起因正常使用docker查看镜像日志过程中，发现系统插播了一条奇怪的错误日志，如下 123[root@liunian127~]# Message from syslogd@i1234567890 at Mar xxx.xxx.xxx.xxx ... kernel:unregister_netdevice: waiting for lo to become free. Usage count = 1 查询之后，简单认为是linux内核与docker内核之间的问题，内核之间的问题技术能力不够暂时没法解决 然后决定对linux进行一次update 使用 yum update update了431个包，之后未进行改动，访问该博客网站，结果提示，502错误 之后到控制台查看日志，如下图 简单来看是由于无法解析到我的mysql服务器的域名，然后在linux主机上ping该域名，发现能ping通 之后决定 vi /etc/hosts 将该域名对应的IP 与域名添加进host文件内，然后重启net服务，重启之后重新生成该镜像并重启 问题未得到解决。 再之后决定用一个笨方法 在启动命令中添加 --net=host 将主机net服务完全与docker服务共享，重新后问题得到解决。 暂时解决该问题，目前使用的方法就这一个成功，后续会进行更多调研。","raw":null,"content":null,"categories":[{"name":"Docker","slug":"Docker","permalink":"https://blog.bosong.online/categories/Docker/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://blog.bosong.online/tags/Docker/"}]},{"title":"Docker常用操作(补充)","slug":"Docker常用操作命令（补充）","date":"2018-10-14T09:53:27.000Z","updated":"2022-06-02T01:05:59.612Z","comments":true,"path":"Docker常用操作命令（补充）.html","link":"","permalink":"https://blog.bosong.online/Docker%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C%E5%91%BD%E4%BB%A4%EF%BC%88%E8%A1%A5%E5%85%85%EF%BC%89.html","excerpt":"docker version 查看docker的版本号，包括客户端、服务端、依赖的Go等\ndocker info 查看系统(docker)层面信息，包括管理的images, containers数等","text":"docker version 查看docker的版本号，包括客户端、服务端、依赖的Go等 docker info 查看系统(docker)层面信息，包括管理的images, containers数等 docker search &lt;image&gt; 在docker index中搜索image docker pull &lt;image&gt; 从docker registry server 中下拉image docker push &lt;image|repository&gt; 推送一个image或repository到registry docker push &lt;image|repository&gt;:TAG 同上，指定tag docker inspect &lt;image|container&gt; 查看image或container的底层信息 docker images TODO filter out the intermediate image layers (intermediate image layers 是什么) docker images -a 列出所有的images docker ps 默认显示正在运行中的container docker ps -l 显示最后一次创建的container，包括未运行的 docker ps -a 显示所有的container，包括未运行的 docker logs &lt;container&gt; 查看container的日志，也就是执行命令的一些输出 docker rm &lt;container...&gt; 删除一个或多个container docker rm docker ps -a -q&#96;&#96; 删除所有的container docker ps -a -q | xargs docker rm 同上, 删除所有的container docker rmi &lt;image...&gt; 删除一个或多个image docker start/stop/restart &lt;container&gt; 开启&#x2F;停止&#x2F;重启container docker start -i &lt;container&gt; 启动一个container并进入交互模式 docker attach &lt;container&gt; attach一个运行中的container docker run &lt;image&gt; &lt;command&gt; 使用image创建container并执行相应命令，然后停止 docker run -i -t &lt;image&gt; /bin/bash 使用image创建container并进入交互模式, login shell是&#x2F;bin&#x2F;bash docker run -i -t -p &lt;host_port:contain_port&gt; 将container的端口映射到宿主机的端口 docker commit &lt;container&gt; [repo:tag] 将一个container固化为一个新的image，后面的repo:tag可选 docker build &lt;path&gt; 寻找path路径下名为的Dockerfile的配置文件，使用此配置生成新的image docker build -t repo[:tag] 同上，可以指定repo和可选的tag docker build - &lt; &lt;dockerfile&gt; 使用指定的dockerfile配置文件，docker以stdin方式获取内容，使用此配置生成新的image docker port &lt;container&gt; &lt;container port&gt; 查看本地哪个端口映射到container的指定端口，其实用docker ps 也可以看到","raw":null,"content":null,"categories":[{"name":"Docker","slug":"Docker","permalink":"https://blog.bosong.online/categories/Docker/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://blog.bosong.online/tags/Docker/"}]},{"title":"Maven常用命令总结","slug":"Maven常用命令总结","date":"2018-10-14T09:49:25.000Z","updated":"2022-06-02T01:05:59.614Z","comments":true,"path":"Maven常用命令总结.html","link":"","permalink":"https://blog.bosong.online/Maven%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%80%BB%E7%BB%93.html","excerpt":"","text":"创建Maven的普通java项目：mvn archetype:create -DgroupId=com.codeline.commons -DartifactId=pjoName 创建Maven的Web项目：mvn archetype:create -DgroupId=com.mycompany.app-DartifactId=my-webapp -DarchetypeArtifactId=maven-archetype-webapp 编译源代码：mvn compile （或者：mvn compiler:compile） 编译测试代码：mvn test-compile 运行测试：mvn test 产生site：mvn site 打包：mvn package 在本地Repository中安装jar：mvn install 清除产生的项目：mvn clean 生成eclipse项目：mvn eclipse:eclipse 组合使用goal命令，如只打包不测试：mvn -Dtest package 编译测试的内容：mvn test-compile 只打jar包: mvn jar:jar 只测试而不编译，也不测试编译：mvn test -skipping compile -skipping test-compile(这里要特别注意 -skipping 的灵活运用，当然也可以用于其他组合命令) 只编译不测试 mvn clean install -DskipTest=true 清除eclipse的一些系统设置:mvn eclipse:clean 查看解析依赖mvn dependency:list 项目依赖属mvn dependency:tree 分析依赖mvn dependency:analyze","raw":null,"content":null,"categories":[{"name":"Java","slug":"Java","permalink":"https://blog.bosong.online/categories/Java/"}],"tags":[{"name":"maven","slug":"maven","permalink":"https://blog.bosong.online/tags/maven/"}]},{"title":"Spring中几种常用的Bean配置方式","slug":"Spring中几种常用的Bean配置方式","date":"2018-10-14T09:47:27.000Z","updated":"2022-06-02T01:05:59.615Z","comments":true,"path":"Spring中几种常用的Bean配置方式.html","link":"","permalink":"https://blog.bosong.online/Spring%E4%B8%AD%E5%87%A0%E7%A7%8D%E5%B8%B8%E7%94%A8%E7%9A%84Bean%E9%85%8D%E7%BD%AE%E6%96%B9%E5%BC%8F.html","excerpt":"Spring 3.x提供了三种配置，分别是：基于XML的配置、基于注解的配置和基于Java类的配置。\n下面分别介绍下这三种配置方式；首先定义一个用于举例的JavaBean。","text":"Spring 3.x提供了三种配置，分别是：基于XML的配置、基于注解的配置和基于Java类的配置。 下面分别介绍下这三种配置方式；首先定义一个用于举例的JavaBean。 123456789101112package com.abc.servicepublic class userService&#123; …… // 用于设置初始化方法 public void init() &#123; &#125; // 用于设置销毁方法 public void destory() &#123; &#125; &#125; 1.基于XML配置12345&lt;bean id=“userService” class=“com.abc.service.impl.userServiceImpl” lazy-init=“true” init-method=“init” destroy-method=“destory” scope=“prototype”&gt; …… &lt;/bean&gt; 在XML配置中，通过 来定义Bean，通过id或name属性定义Bean的名称，如果未指定id和name属性，Spring则自动将全限定类名作为Bean的名称。通过子元素或者p命名空间的动态属性为Bean注入值。还可以通过的init-method和destory-method属性指定Bean实现类的方法名来设置生命过程方法（最多指定一个初始化方法和销毁方法）。通过的scope指定Bean的作用范围。听过的lazy-init属性指定是否延迟初始化。 当Bean的实现类来源于第三方类库，比如DataSource、HibernateTemplate等，无法在类中标注注解信息，只能通过XML进行配置；而且命名空间的配置，比如aop、context等，也只能采用基于XML的配置。 2.基于注解的配置12345678910111213141516@Scope(“prototype”) @Lazy(true) @Component(“userService”) public class userService&#123; …… // 用于设置初始化方法 @PostConstruct public void init() &#123; &#125; // 用于设置销毁方法 @PreDestroy public void destory() &#123; &#125; &#125; 在Bean实现类中通过一些Annotation来标注Bean类： @Component：标注一个普通的Spring Bean类（可以指定Bean名称，未指定时默认为小写字母开头的类名） @Controller：标注一个控制器类 @Service：标注一个业务逻辑类 @Repository：标注一个DAO类 通过在成员变量或者方法入参处标注@Autowired按类型匹配注入，也可以使用@Qualifier按名称配置注入。通过在方法上标注@PostConstrut和PreDestroy注解指定的初始化方法和销毁方法（可以定义任意多个）。通过@Scope(“prototype”)指定Bean的作用范围。通过在类定义处标注@Lazy(true)指定Bean的延迟加载。 当Bean的实现类是当前项目开发的，可以直接在Java类中使用基于注解的配置，配置比较简单。 3.基于Java类配置12345678@Configuration public class Conf &#123; @Scope(“prototype”) @Bean(“userService”) public userService userService() &#123; return new userService(); &#125; &#125; 在标注了@Configuration的java类中，通过在类方法标注@Bean定义一个Bean。方法必须提供Bean的实例化逻辑。通过@Bean的name属性可以定义Bean的名称，未指定时默认名称为方法名。在方法处通过@Autowired使方法入参绑定Bean，然后在方法中通过代码进行注入；也可以调用配置类的@Bean方法进行注入。通过@Bean的initMethod或destroyMethod指定一个初始化或者销毁方法。通过Bean方法定义处标注@Scope指定Bean的作用范围。通过在Bean方法定义处标注@Lazy指定Bean的延迟初始化。 当实例化Bean的逻辑比较复杂时，则比较适合基于Java类配置的方式。 转自https://blog.csdn.net/iloveyin/article/details/51019225","raw":null,"content":null,"categories":[{"name":"Java","slug":"Java","permalink":"https://blog.bosong.online/categories/Java/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"https://blog.bosong.online/tags/Spring/"}]},{"title":"sql之left join、right join、inner join的区别","slug":"Sql之leftjoin、rightjoin、inner、join的区别","date":"2018-10-14T09:33:43.000Z","updated":"2022-06-02T01:05:59.615Z","comments":true,"path":"Sql之leftjoin、rightjoin、inner、join的区别.html","link":"","permalink":"https://blog.bosong.online/Sql%E4%B9%8Bleftjoin%E3%80%81rightjoin%E3%80%81inner%E3%80%81join%E7%9A%84%E5%8C%BA%E5%88%AB.html","excerpt":"left join(左联接) 返回包括左表中的所有记录和右表中联结字段相等的记录right join(右联接) 返回包括右表中的所有记录和左表中联结字段相等的记录inner join(等值连接) 只返回两个表中联结字段相等的行\n举例如下：表A记录如下：","text":"left join(左联接) 返回包括左表中的所有记录和右表中联结字段相等的记录right join(右联接) 返回包括右表中的所有记录和左表中联结字段相等的记录inner join(等值连接) 只返回两个表中联结字段相等的行 举例如下：表A记录如下： 123456aID aNum1 a200501112 a200501123 a200501134 a200501145 a20050115 表B记录如下: 123456bID bName1 20060324012 20060324023 20060324034 20060324048 2006032408 1.left joinsql语句如下: 123select * from Aleft join B on A.aID = B.bID 结果如下: 123456aID aNum bID bName1 a20050111 1 20060324012 a20050112 2 20060324023 a20050113 3 20060324034 a20050114 4 20060324045 a20050115 NULL NULL （所影响的行数为 5 行）结果说明:left join是以A表的记录为基础的,A可以看成左表,B可以看成右表,left join是以左表为准的.换句话说,左表(A)的记录将会全部表示出来,而右表(B)只会显示符合搜索条件的记录(例子中为: A.aID &#x3D; B.bID).B表记录不足的地方均为NULL. 2.right joinsql语句如下: 123select * from Aright join B on A.aID = B.bID 结果如下: 123456aID aNum bID bName1 a20050111 1 20060324012 a20050112 2 20060324023 a20050113 3 20060324034 a20050114 4 2006032404NULL NULL 8 2006032408 （所影响的行数为 5 行）结果说明:仔细观察一下,就会发现,和left join的结果刚好相反,这次是以右表(B)为基础的,A表不足的地方用NULL填充. 3.inner joinsql语句如下: 123select * from Ainnerjoin B on A.aID = B.bID 结果如下: 12345aID aNum bID bName1 a20050111 1 20060324012 a20050112 2 20060324023 a20050113 3 20060324034 a20050114 4 2006032404 结果说明:很明显,这里只显示出了 A.aID &#x3D; B.bID的记录.这说明inner join并不以谁为基础,它只显示符合条件的记录.注:LEFT JOIN操作用于在任何的 FROM 子句中，组合来源表的记录。使用 LEFT JOIN 运算来创建一个左边外部联接。左边外部联接将包含了从第一个（左边）开始的两个表中的全部记录，即使在第二个（右边）表中并没有相符值的记录。 语法：FROM table1 LEFT JOIN table2 ON table1.field1 compopr table2.field2 说明：table1, table2参数用于指定要将记录组合的表的名称。field1, field2参数指定被联接的字段的名称。且这些字段必须有相同的数据类型及包含相同类型的数据，但它们不需要有相同的名称。compopr参数指定关系比较运算符：”&#x3D;”， “&lt;”， “&gt;”， “&lt;&#x3D;”， “&gt;&#x3D;” 或 “&lt;&gt;”。如果在INNER JOIN操作中要联接包含Memo 数据类型或 OLE Object 数据类型数据的字段，将会发生错误. 转载自https://blog.csdn.net/iloveyin/article/details/50855101","raw":null,"content":null,"categories":[{"name":"数据库","slug":"数据库","permalink":"https://blog.bosong.online/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"https://blog.bosong.online/tags/mysql/"}]},{"title":"说一说Java异常处理的心得体会","slug":"说一说Java异常处理的心得体会","date":"2018-10-14T09:20:53.000Z","updated":"2022-06-02T01:05:59.618Z","comments":true,"path":"说一说Java异常处理的心得体会.html","link":"","permalink":"https://blog.bosong.online/%E8%AF%B4%E4%B8%80%E8%AF%B4Java%E5%BC%82%E5%B8%B8%E5%A4%84%E7%90%86%E7%9A%84%E5%BF%83%E5%BE%97%E4%BD%93%E4%BC%9A.html","excerpt":"1.切勿捕获异常不处理使用try-catch捕获异常后，无任何处理，这样的做法会吞噬异常，外层代码或调用方无法感知异常的发生。捕获异常后，打印错误日志，可以立即处理掉，也可以直接向外抛出或构建内部异常向外抛出，切勿无任务处理操作。","text":"1.切勿捕获异常不处理使用try-catch捕获异常后，无任何处理，这样的做法会吞噬异常，外层代码或调用方无法感知异常的发生。捕获异常后，打印错误日志，可以立即处理掉，也可以直接向外抛出或构建内部异常向外抛出，切勿无任务处理操作。 2.不要catch中捕获Exception异常Exception代表的是异常的大类，而代码中通常需要捕获的是某某特定异常，进而进行特定的异常处理；而且，从写代码的角度来说，捕获清晰明了的特定异常会提升代码的可读性。 3.切勿使用e.printStackTrace()e.printStackTrace()方法打印出的信息不利于跟踪出错的具体轨迹，特别是对于一些复杂的系统，所以切勿使用。 4.减小try块的范围try-catch会影响JVM对代码进行优化，所以尽量减少try块中的代码，只对有必要的代码进行try。 5.切勿在finally块中对返回值进行操作finally代码块一般用于收尾工作，例如释放资源、释放连接等，如果在这里有对返回值进行操作的处理，可能会被忽略。 6.有必要，才使用每创建一个Exception实例，都会对栈信息进行快照，如果很频繁将会产生很大的开销。","raw":null,"content":null,"categories":[{"name":"Java","slug":"Java","permalink":"https://blog.bosong.online/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://blog.bosong.online/tags/Java/"}]},{"title":"mysql主从同步原理、配置以及延迟","slug":"Mysql主从同步原理、配置以及延迟","date":"2018-10-14T09:17:32.000Z","updated":"2022-06-02T01:05:59.614Z","comments":true,"path":"Mysql主从同步原理、配置以及延迟.html","link":"","permalink":"https://blog.bosong.online/Mysql%E4%B8%BB%E4%BB%8E%E5%90%8C%E6%AD%A5%E5%8E%9F%E7%90%86%E3%80%81%E9%85%8D%E7%BD%AE%E4%BB%A5%E5%8F%8A%E5%BB%B6%E8%BF%9F.html","excerpt":"我们先来了解什么是主从同步，主从同步，顾名思义也称为主从复制，用来建立一个和主数据库完全一样的数据库环境。主从同步使得数据可以从一个数据库服务器复制到其他服务器上，实现主数据库的数据和从数据库的数据保持一致。\n集群是共享存储的,是data-sharing . 主从复制中没有任何共享 . 每台机器都是独立且完整的系统,是nothing-sharing.","text":"我们先来了解什么是主从同步，主从同步，顾名思义也称为主从复制，用来建立一个和主数据库完全一样的数据库环境。主从同步使得数据可以从一个数据库服务器复制到其他服务器上，实现主数据库的数据和从数据库的数据保持一致。 集群是共享存储的,是data-sharing . 主从复制中没有任何共享 . 每台机器都是独立且完整的系统,是nothing-sharing. 主从同步的原理 从mysql5.6之后主从复制的实现方式主要有3种: 异步复制 全同步复制 半同步复制 主从同步原理图 1.当主数据库的更新事件(update、insert、delete)被写到binary-log . 2.从库创建一个I&#x2F;O线程，该线程连接到主库并请求主库发送binlog里面的更新记录到从库上 .主库创建一个binlog dump thread线程，把binlog的内容发送到从库 ,从库的I&#x2F;O线程读取主库的输出线程发送的更新并拷贝这些更新到本地relay log文件中 . 3.从库创建一个SQL线程，这个线程读取从库I&#x2F;O线程写到relay log的更新事件并执行 . 主从同步的实现(异步复制,数据库在不同服务器) 1.配置主数据库打开binary-log vi /etc/my.cnf 在[mysqld]下添加 12345server-id=1(用来标识不同的数据库)log-bin=master-bin(打开bin-log并配置文件名为master-bin)log-bin-index=master-bin.index(区分不同的log-bin文件) 重启数据库:&#96;systemctl restart mysqld&#96;&#96; 2.配置从数据库打开relay-log &#96;&#96;vi &#x2F;etc&#x2F;my.cnf&#96; 在[mysqld]下添加 123server-id=2relay-log=slave-relay-bin(打开relay-log并配置文件名为slave-relay-bin)relay-log-index=slave-relay-bin.index 重启数据库:systemctl restart mysqld 3.连接两个数据库 在主数据库中:创建用户repl ,每一个从服务器都需要用到主数据库一个账户名和密码来连接主服务器 . 1CREATE USER &#x27;repl&#x27;@&#x27;master-IP:port&#x27; IDENTIFIED BY &#x27;password&#x27;;GRANT REPLICATION SLAVE ON *.* TO &#x27;repl&#x27;@&#x27;slave-IP:port&#x27; IDENTIFIED BY &#x27;password&#x27;; 在从数据库中: 1change master to master_host=&#x27;ip:port&#x27;,master_user=&#x27;repl&#x27;,master_password=&#x27;password&#x27;,master_log_file=&#x27;master-bin.000001&#x27;,master_log_pos=0; 启动同步:start slave; 4.验证 在主数据库创建一个数据库,然后在从数据库查看 主从同步的作用 做数据的热备，作为后备数据库，主数据库服务器故障后，可切换到从数据库继续工作，避免数据丢失 . 读写分离,使数据库能支撑更大的并发 . 主从同步的注意事项 主库可以读写数据,而从库只能读数据,因为当从库写了数据positon会变化,但是主库的position是不会变的,当主库写数据变化position的时候就可能会有冲突.当主库的binatylog文件存储的数据很多,也就是position很大的时候,会再分裂一个新的binarylog文件,position置为0;主从库的mysql版本可以不一样,但是从库的mysql版本要比主库的版本要高,如果不是的话,那么主库的语句到了从库可能就不能执行.因为mysql是向后兼容的,也就是说低版本的语句在高版本里面是支持的,但是高版本的有些语句在低版本是不支持的.面试相关 （如果问到数据库主从问题，必问以下问题）： 主从的好处是？主从的原理是？从数据库的读的延迟问题了解吗？如何解决？做主从后主服务器挂了怎么办？主从同步的延迟的原因主从同步的延迟的原因主从同步延迟问题 主从同步的延迟的原因 我们知道， 一个服务器开放Ｎ个链接给客户端来连接的， 这样有会有大并发的更新操作, 但是从服务器的里面读取binlog 的线程仅有一个， 当某个SQL在从服务器上执行的时间稍长 或者由于某个SQL要进行锁表就会导致，主服务器的SQL大量积压，未被同步到从服务器里。这就导致了主从不一致， 也就是主从延迟。 主从同步延迟的解决办法 实际上主从同步延迟根本没有什么一招制敌的办法， 因为所有的SQL必须都要在从服务器里面执行一遍，但是主服务器如果不断的有更新操作源源不断的写入， 那么一旦有延迟产生， 那么延迟加重的可能性就会原来越大。 当然我们可以做一些缓解的措施。 a. 我们知道因为主服务器要负责更新操作， 他对安全性的要求比从服务器高， 所有有些设置可以修改，比如sync_binlog&#x3D;1，innodb_flush_log_at_trx_commit &#x3D; 1 之类的设置，而slave则不需要这么高的数据安全，完全可以讲sync_binlog设置为0或者关闭binlog，innodb_flushlog， innodb_flush_log_at_trx_commit 也 可以设置为0来提高sql的执行效率 这个能很大程度上提高效率。另外就是使用比主库更好的硬件设备作为slave。 b. 就是把，一台从服务器当度作为备份使用， 而不提供查询， 那边他的负载下来了， 执行relay log 里面的SQL效率自然就高了。 c. 增加从服务器喽，这个目的还是分散读的压力， 从而降低服务器负载。","raw":null,"content":null,"categories":[{"name":"数据库","slug":"数据库","permalink":"https://blog.bosong.online/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"https://blog.bosong.online/tags/mysql/"}]},{"title":"15个对MySQL的优化建议与总结","slug":"15个对MySQL的优化建议与总结","date":"2018-10-14T09:14:20.000Z","updated":"2022-06-02T01:05:59.611Z","comments":true,"path":"15个对MySQL的优化建议与总结.html","link":"","permalink":"https://blog.bosong.online/15%E4%B8%AA%E5%AF%B9MySQL%E7%9A%84%E4%BC%98%E5%8C%96%E5%BB%BA%E8%AE%AE%E4%B8%8E%E6%80%BB%E7%BB%93.html","excerpt":"1、 为查询缓存优化查询\n像 NOW() 和 RAND() 或是其它的诸如此类的SQL函数都不会开启查询缓存，谨慎使用","text":"1、 为查询缓存优化查询 像 NOW() 和 RAND() 或是其它的诸如此类的SQL函数都不会开启查询缓存，谨慎使用 2、EXPLAIN 我们的SELECT查询(可以查看执行的行数) 可以让我们找到潜在的性能问题 3、当只要一行数据时使用LIMIT 1 MySQL数据库引擎会在查找到一条数据后停止搜索，而不是继续往后查询下一条符合条件的数据记录。 4、为搜索字段建立索引 在识别度高的列上建立正确的索引，以提升性能 5、在Join表的时候使用相当类型的列，并将其索引 关联表的关键字段，类型一致，字符集一致，才能提高性能，否则无法使用它们的索引 6、千万不要 ORDER BY RAND () 执行RAND()函数（很耗CPU时间），会让你的数据库的性能呈指数级的下降 7、 避免SELECT * 从数据库里读出越多的数据，那么查询就会变得越慢。 8、永远为每张表设置一个ID 我们应该为数据库里的每张表都设置一个ID做为其主键，而且最好的是一个INT型的（推荐使用UNSIGNED），并设置上自动增加的 AUTO_INCREMENT标志。 9、可以使用ENUM 而不要VARCHAR ENUM 类型是非常快和紧凑的。在实际上，其保存的是 TINYINT，但其外表上显示为字符串。 10、尽可能的使用NOT NULL 如果不是特殊情况，尽可能的不要使用NULL。在MYSQL中对于INT类型而言，EMPTY是0，而NULL是空值。而在Oracle中 NULL和EMPTY的字符串是一样的。NULL也需要占用存储空间，并且会使我们的程序判断时更加复杂。现实情况是很复杂的，依然会有些情况下，我们需要使用NULL值。 11、固定长度的表会更快 表中没有如下类型的字段： VARCHAR，TEXT，BLOB。只要我们包括了其中一个这些字段，那么这个表就不是“固定长度静态表”了，这样，MySQL 引擎会用另一种方法来处理。 固定长度的表会提高性能，因为MySQL搜寻得会更快一些，因为这些固定的长度是很容易计算下一个数据的偏移量的，所以读取的自然也会很快。 12、垂直分割 “垂直分割”是一种把数据库中的表按列变成几张表的方法，这样可以降低表的复杂度和字段的数目，从而达到优化的目的。 13、拆分打的DELETE或INSERT语句 这两个操作是会锁表的 14、越小的列会越快 对于大多数的数据库引擎来说，硬盘操作可能是最重大的瓶颈。越小的列消耗的io资源越少 15、选择正确的存储引擎 MyISAM是MYSQL5.5版本以前默认的存储引擎，基于传统的ISAM类型，支持B-Tree，全文检索，但是不是事务安全的，而且不支持外键。不具有原子性。支持锁表。 总结 InnoDB是事务型引擎，支持ACID事务(实现4种事务隔离机制)、回滚、崩溃恢复能力、行锁。以及提供与Oracle一致的不加锁的读取方式。InnoDB存储它的表和索引在一个表空间中，表空间可以包含多个文件。 转载自https://www.toutiao.com/a6587214191122186766/","raw":null,"content":null,"categories":[{"name":"数据库","slug":"数据库","permalink":"https://blog.bosong.online/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"https://blog.bosong.online/tags/mysql/"}]},{"title":"MYSQL千万级数据量的优化方法积累","slug":"Mysql千万级数据量的优化方法积累","date":"2018-10-14T09:10:26.000Z","updated":"2022-06-02T01:05:59.614Z","comments":true,"path":"Mysql千万级数据量的优化方法积累.html","link":"","permalink":"https://blog.bosong.online/Mysql%E5%8D%83%E4%B8%87%E7%BA%A7%E6%95%B0%E6%8D%AE%E9%87%8F%E7%9A%84%E4%BC%98%E5%8C%96%E6%96%B9%E6%B3%95%E7%A7%AF%E7%B4%AF.html","excerpt":"1.对查询进行优化，应尽量避免全表扫描，首先应考虑在 where 及 order by 涉及的列上建立索引。\n2.应尽量避免在 where 子句中对字段进行 null 值判断，否则将导致引擎放弃使用索引而进行全表扫描，如：select id from t where num is null可以在num上设置默认值0，确保表中num列没有null值，然后这样查询：select id from t where num&#x3D;0","text":"1.对查询进行优化，应尽量避免全表扫描，首先应考虑在 where 及 order by 涉及的列上建立索引。 2.应尽量避免在 where 子句中对字段进行 null 值判断，否则将导致引擎放弃使用索引而进行全表扫描，如：select id from t where num is null可以在num上设置默认值0，确保表中num列没有null值，然后这样查询：select id from t where num&#x3D;0 3.应尽量避免在 where 子句中使用!&#x3D;或&lt;&gt;操作符，否则引擎将放弃使用索引而进行全表扫描。 4.应尽量避免在 where 子句中使用or 来连接条件，否则将导致引擎放弃使用索引而进行全表扫描，如：select id from t where num&#x3D;10 or num&#x3D;20可以这样查询：select id from t where num&#x3D;10 union all select id from t where num&#x3D;20 5.in 和 not in 也要慎用，否则会导致全表扫描，如：select id from t where num in(1,2,3) 对于连续的数值，能用 between 就不要用 in 了：select id from t where num between 1 and 3 6.下面的查询也将导致全表扫描：select id from t where name like ‘%李%’若要提高效率，可以考虑全文检索。 如果在 where 子句中使用参数，也会导致全表扫描。因为SQL只有在运行时才会解析局部变量，但优化程序不能将访问计划的选择推迟到运行时；它必须在编译时进行选择。然 而，如果在编译时建立访问计划，变量的值还是未知的，因而无法作为索引选择的输入项。如下面语句将进行全表扫描：select id from t where num&#x3D;@num可以改为强制查询使用索引：select id from t with(index(索引名)) where num&#x3D;@num8.应尽量避免在 where 子句中对字段进行表达式操作，这将导致引擎放弃使用索引而进行全表扫描。如：select id from t where num&#x2F;2&#x3D;100应改为:select id from t where num&#x3D;100*2 9.应尽量避免在where子句中对字段进行函数操作，这将导致引擎放弃使用索引而进行全表扫描。如：select id from t where substring(name,1,3)&#x3D;’abc’ ，name以abc开头的id应改为: select id from t where name like ‘abc%’ 10.不要在 where 子句中的“&#x3D;”左边进行函数、算术运算或其他表达式运算，否则系统将可能无法正确使用索引。 11.在使用索引字段作为条件时，如果该索引是复合索引，那么必须使用到该索引中的第一个字段作为条件时才能保证系统使用该索引，否则该索引将不会被使用，并且应尽可能的让字段顺序与索引顺序相一致。 12.不要写一些没有意义的查询，如需要生成一个空表结构：select col1,col2 into #t from t where 1=0 这类代码不会返回任何结果集，但是会消耗系统资源的，应改成这样： create table #t(…) 13.很多时候用 exists 代替 in 是一个好的选择：select num from a where num in(select num from b) 用下面的语句替换： select num from a where exists(select 1 from b where num=a.num) 14.并不是所有索引对查询都有效，SQL是根据表中数据来进行查询优化的，当索引列有大量数据重复时，SQL查询可能不会去利用索引，如一表中有字段sex，male、female几乎各一半，那么即使在sex上建了索引也对查询效率起不了作用。 索引并不是越多越好，索引固然可 以提高相应的 select 的效率，但同时也降低了 insert 及 update 的效率，因为 insert 或 update 时有可能会重建索引，所以怎样建索引需要慎重考虑，视具体情况而定。一个表的索引数最好不要超过6个，若太多则应考虑一些不常使用到的列上建的索引是否有 必要。应尽可能的避免更新 clustered 索引数据列，因为 clustered 索引数据列的顺序就是表记录的物理存储顺序，一旦该列值改变将导致整个表记录的顺序的调整，会耗费相当大的资源。若应用系统需要频繁更新 clustered 索引数据列，那么需要考虑是否应将该索引建为 clustered 索引。17.尽量使用数字型字段，若只含数值信息的字段尽量不要设计为字符型，这会降低查询和连接的性能，并会增加存储开销。这是因为引擎在处理查询和连接时会逐个比较字符串中每一个字符，而对于数字型而言只需要比较一次就够了. 18.尽可能的使用 varchar&#x2F;nvarchar 代替 char&#x2F;nchar ，因为首先变长字段存储空间小，可以节省存储空间，其次对于查询来说，在一个相对较小的字段内搜索效率显然要高些。 19.任何地方都不要使用 select * from t ，用具体的字段列表代替“*”，不要返回用不到的任何字段。 20.尽量使用表变量来代替临时表。如果表变量包含大量数据，请注意索引非常有限（只有主键索引）。 21.避免频繁创建和删除临时表，以减少系统表资源的消耗。 22.临时表并不是不可使用，适当地使用它们可以使某些例程更有效，例如，当需要重复引用大型表或常用表中的某个数据集时。但是，对于一次性事件，最好使用导出表。 23.在新建临时表时，如果一次性插入数据量很大，那么可以使用 select into 代替 create table，避免造成大量 log ，以提高速度；如果数据量不大，为了缓和系统表的资源，应先create table，然后insert。 24.如果使用到了临时表，在存储过程的最后务必将所有的临时表显式删除，先 truncate table ，然后 drop table ，这样可以避免系统表的较长时间锁定。 25.尽量避免使用游标，因为游标的效率较差，如果游标操作的数据超过1万行，那么就应该考虑改写。 26.使用基于游标的方法或临时表方法之前，应先寻找基于集的解决方案来解决问题，基于集的方法通常更有效。 与临时表一样，游标并不是不可使 用。对小型数据集使用 FAST_FORWARD 游标通常要优于其他逐行处理方法，尤其是在必须引用几个表才能获得所需的数据时。在结果集中包括“合计”的例程通常要比使用游标执行的速度快。如果开发时 间允许，基于游标的方法和基于集的方法都可以尝试一下，看哪一种方法的效果更好。28.在所有的存储过程和触发器的开始处设置 SET NOCOUNT ON ，在结束时设置 SET NOCOUNT OFF 。无需在执行存储过程和触发器的每个语句后向客户端发送DONE_IN_PROC 消息。 29.尽量避免大事务操作，提高系统并发能力. 30.尽量避免向客户端返回大数据量，若数据量过大，应该考虑相应需求是否合理。 &#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D; 1、分库分表 很明显，一个主表（也就是很重要的表，例如用户表）无限制的增长势必严重影响性能，分库与分表是一个很不错的解决途径，也就是性能优化途径，现在的案例是我们有一个1000多万条记录的用户表members,查询起来非常之慢，同事的做法是将其散列到100个表中，分别从members0到members99，然后根据mid分发记录到这些表中，牛逼的代码大概是这样子： \"; echo \"INSERT INTO members{$i} SELECT * FROM members WHERE mid0={$i}\"; } ?> 2、不停机修改mysql表结构 同样还是members表，前期设计的表结构不尽合理，随着数据库不断运行，其冗余数据也是增长巨大，同事使用了下面的方法来处理： 先创建一个临时表： CREATE TABLE members_tmp LIKE members 然后修改members_tmp的表结构为新结构，接着使用上面那个for循环来导出数据，因为1000万的数据一次性导出是不对的，mid是主键，一个区间一个区间的导，基本是一次导出5万条吧，这里略去了 接着重命名将新表替换上去： RENAME TABLE members TO members_bak,members_tmp TO members; 就是这样，基本可以做到无损失，无需停机更新表结构，但实际上RENAME期间表是被锁死的，所以选择在线少的时候操作是一个技巧。经过这个操作，使得原先8G多的表，一下子变成了2G多 另外还讲到了mysql中float字段类型的时候出现的诡异现象，就是在pma中看到的数字根本不能作为条件来查询 3、常用SQL语句优化： 数据库(表)设计合理 我们的表设计要符合3NF 3范式(规范的模式) , 有时我们需要适当的逆范式 sql语句的优化(索引，常用小技巧.) 数据的配置(缓存设大) 适当硬件配置和操作系统 (读写分离.) 数据的3NF 1NF :就是具有原子性，不可分割.(只要使用的是关系性数据库，就自动符合) 2NF: 在满足1NF 的基础上，我们考虑是否满足2NF: 只要表的记录满足唯一性,也是说,你的同一张表，不可能出现完全相同的记录, 一般说我们在 表中设计一个主键即可. 3NF: 在满足2NF 的基础上，我们考虑是否满足3NF：即我们的字段信息可以通过关联的关系，派生即可.(通常我们通过外键来处理) 逆范式: 为什么需呀逆范式: (相册的功能对应数据库的设计) 适当的逆范式. sql语句的优化 sql语句有几类 ddl (数据定义语言) [create alter drop] dml(数据操作语言)[insert delete upate ] select dtl(数据事务语句) [commit rollback savepoint] dcl(数据控制语句) [grant revoke] show status命令 该命令可以显示你的mysql数据库的当前状态.我们主要关心的是 “com”开头的指令 show status like ‘Com%’ &lt;&#x3D;&gt; show session status like ‘Com%’ &#x2F;&#x2F;显示当前控制台的情况 show global status like ‘Com%’ ; &#x2F;&#x2F;显示数据库从启动到 查询的次数 显示连接数据库次数 show status like ‘Connections’; 这里我们优化的重点是在 慢查询. (在默认情况下是10 ) mysql5.5.19 显示查看慢查询的情况 show variables like ‘long_query_time’ 为了教学，我们搞一个海量表(mysql存储过程) 目的，就是看看怎样处理，在海量表中，查询的速度很快! select * from emp where empno&#x3D;123456; 需求：如何在一个项目中，找到慢查询的select , mysql数据库支持把慢查询语句，记录到日志中，程序员分析. (但是注意，默认情况下不启动.) 步骤: 要这样启动mysql 进入到 mysql安装目录 启动 xx&gt;binmysqld.exe –slow-query-log 这点注意测试 ,比如我们把 select * from emp where empno&#x3D;34678 ； 用了1.5秒，我现在优化. 快速体验: 在emp表的 empno建立索引. alter table emp add primary key(empno); &#x2F;&#x2F;删除主键索引 alter table emp drop primary key 然后，再查速度变快. l 索引的原理 介绍一款非常重要工具explain, 这个分析工具可以对 sql语句进行分析,可以预测你的sql执行的效率. 他的基本用法是: explain sql语句G &#x2F;&#x2F;根据返回的信息，我们可知,该sql语句是否使用索引，从多少记录中取出,可以看到排序的方式. l 在什么列上添加索引比较合适 ① 在经常查询的列上加索引. ② 列的数据，内容就只有少数几个值,不太适合加索引. ③ 内容频繁变化，不合适加索引 l 索引的种类 ① 主键索引 (把某列设为主键，则就是主键索引) ② 唯一索引(unique) （即该列具有唯一性，同时又是索引） ③ index （普通索引） ④ 全文索引(FULLTEXT) select * from article where content like ‘%李连杰%’; hello, i am a boy l 你好，我是一个男孩 &#x3D;&gt;中文 sphinx ⑤ 复合索引(多列和在一起) create index myind on 表名 (列1,列2); l 如何创建索引 如果创建unique &#x2F; 普通&#x2F;fulltext 索引 create [unique|FULLTEXT] index 索引名 on 表名 (列名…)alter table 表名 add index 索引名 (列名…)&#x2F;&#x2F;如果要添加主键索引 alter table 表名 add primary key (列…) 删除索引 drop index 索引名 on 表名 alter table 表名 drop index index_name; alter table 表名 drop primary key 显示索引 show index(es) from 表名 show keys from 表名 desc 表名 如何查询某表的索引 show indexes from 表名 l 使用索引的注意事项 查询要使用索引最重要的条件是查询条件中需要使用索引。 下列几种情况下有可能使用到索引： 1，对于创建的多列索引，只要查询条件使用了最左边的列，索引一般就会被使用。 2，对于使用like的查询，查询如果是 ‘�a’ 不会使用到索引 aaa%’ 会使用到索引。 下列的表将不使用索引： 1，如果条件中有or，即使其中有条件带索引也不会使用。 2，对于多列索引，不是使用的第一部分，则不会使用索引。 3，like查询是以%开头 4，如果列类型是字符串，那一定要在条件中将数据使用引号引用起来。否则不使用索引。 5，如果mysql估计使用全表扫描要比使用索引快，则不使用索引。 l 如何检测你的索引是否有效 结论: Handler_read_key 越大越少 Handler_read_rnd_next 越小越好 fdisk find l MyISAM 和 Innodb区别是什么 MyISAM 不支持外键, Innodb支持 MyISAM 不支持事务,不支持外键. 对数据信息的存储处理方式不同.（如果存储引擎是MyISAM的，则创建一张表，对于三个文件..,如果是Innodb则只有一张文件 *.frm,数据存放到ibdata1） 对于 MyISAM 数据库，需要定时清理 optimize table 表名 l 常见的sql优化手法 使用order by null 禁用排序 比如 select A/B/C from dept group by ename order by null 在精度要求高的应用中，建议使用定点数(decimal)来存储数值，以保证结果的准确性 如果字段是字符类型的索引，用作条件查询时一定要加单引号，不然索引无效。 主键索引如果没用到，再查询for update这种情况，会造成表锁定。容易造成卡死。1000000.32 万 create table sal(t1 float(10,2)); create table sal2(t1 decimal(10,2)); 问?在php中 ,int 如果是一个有符号数，最大值. int- 4*8&#x3D;32 2 31 -1 l 表的水平划分 l 垂直分割表 如果你的数据库的存储引擎是MyISAM的，则当创建一个表，后三个文件. .frm 记录表结构. .myd 数据 *.myi 这个是索引. mysql5.5.19的版本，数据库文件，默认放在 （看 my.ini文件中的配置.） 转自https://www.toutiao.com/i6583260372269007374/?tt_from=mobile_qq&amp;utm_campaign=client_share&amp;timestamp=1533830508&amp;app=news_article&amp;utm_source=mobile_qq&amp;iid=39018175817&amp;utm_medium=toutiao_ios&amp;group_id=6583260372269007374","raw":null,"content":null,"categories":[{"name":"数据库","slug":"数据库","permalink":"https://blog.bosong.online/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"https://blog.bosong.online/tags/mysql/"}]},{"title":"mysql中间件-Mycat","slug":"Mysql中间件-Mycat","date":"2018-10-14T09:04:21.000Z","updated":"2022-06-02T01:05:59.614Z","comments":true,"path":"Mysql中间件-Mycat.html","link":"","permalink":"https://blog.bosong.online/Mysql%E4%B8%AD%E9%97%B4%E4%BB%B6-Mycat.html","excerpt":"前言因业务需要，给mysql做了主备，然后准备使用数据库中间件来进行读写分离和分片。","text":"前言因业务需要，给mysql做了主备，然后准备使用数据库中间件来进行读写分离和分片。 学习过程学习过程中使用了三台服务器，一主两备，此处只用一主一备参与中间件的试用。 集群组成如下： 角色 主机名 主机IP master liunian1 192.168.1.1 slave liunian2 192.168.1.2 slave liunian3 192.168.1.3 先配置mycat配置文件schema.xml 123456789101112131415161718&lt;?xml version=&quot;1.0&quot;?&gt;&lt;!DOCTYPE mycat:schema SYSTEM &quot;schema.dtd&quot;&gt;&lt;mycat:schema xmlns:mycat=&quot;http://io.mycat/&quot;&gt; &lt;!-- 逻辑库 --&gt; &lt;schema name=&quot;TESTDB&quot; checkSQLschema=&quot;false&quot; sqlMaxLimit=&quot;100&quot; dataNode=&quot;dn1&quot;/&gt; &lt;!-- 物理节点--&gt; &lt;dataNode name=&quot;dn1&quot; dataHost=&quot;dh1&quot; database=&quot;tale&quot; /&gt; &lt;!-- 物理读写分离--&gt; &lt;dataHost name=&quot;dh1&quot; maxCon=&quot;1000&quot; minCon=&quot;10&quot; balance=&quot;2&quot; writeType=&quot;0&quot; dbType=&quot;mysql&quot; dbDriver=&quot;native&quot; switchType=&quot;1&quot; slaveThreshold=&quot;100&quot;&gt; &lt;heartbeat&gt;select user()&lt;/heartbeat&gt; &lt;!-- 设置 --&gt; &lt;writeHost host=&quot;hostM1&quot; url=&quot;192.168.1.1:3306&quot; user=&quot;root&quot; password=&quot;password&quot;&gt; &lt;readHost host=&quot;hostS1&quot; url=&quot;192.168.1.2:3306&quot; user=&quot;root&quot; password=&quot;password&quot; /&gt; &lt;/writeHost&gt; &lt;/dataHost&gt;&lt;/mycat:schema&gt; 以下是一些重要参数 balance指的负载均衡类型，目前的取值有4种： balance&#x3D;”0”, 不开启读写分离机制，所有读操作都发送到当前可用的writeHost上。 balance&#x3D;”1”，全部的readHost与stand by writeHost参与select语句的负载均衡，简单的说，当双主双从模式(M1-&gt;S1，M2-&gt;S2，并且M1与 M2互为主备)，正常情况下，M2,S1,S2都参与select语句的负载均衡。 balance&#x3D;”2”，所有读操作都随机的在writeHost、readhost上分发。 balance&#x3D;”3”，所有读请求随机的分发到wiriterHost对应的readhost执行，writerHost不负担读压力 switchType指的是切换的模式，目前的取值也有4种： switchType&#x3D;’-1’ 表示不自动切换 switchType&#x3D;’1’ 默认值，表示自动切换 switchType&#x3D;’2’ 基于MySQL主从同步的状态决定是否切换,心跳语句为 show slave status switchType&#x3D;’3’基于MySQL galary cluster的切换机制（适合集群）（1.4.1），心跳语句为 show status like ‘wsrep%’。 writeType表示写模式 writeType&#x3D;”0”，所有的操作发送到配置的第一个writehost writeType&#x3D;”1”，随机发送到配置的所有writehost writeType&#x3D;”2”，不执行写操作 rule规则需要读者自己去详细发掘，server.xml主要配置用户逻辑库以及用户账户，端口等系统配置，可酌情进行配置。 mycat的使用过程比较坎坷，Navicat连接上之后无法直接读库，需要进行sql语句查询，此问题目前未解决。","raw":null,"content":null,"categories":[{"name":"中间件","slug":"中间件","permalink":"https://blog.bosong.online/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"}],"tags":[{"name":"数据库中间件","slug":"数据库中间件","permalink":"https://blog.bosong.online/tags/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%B8%AD%E9%97%B4%E4%BB%B6/"}]},{"title":"Mybatis中SQL的语句总结","slug":"Mybatis中SQL的语句总结","date":"2018-10-14T05:51:59.000Z","updated":"2022-06-02T01:05:59.614Z","comments":true,"path":"Mybatis中SQL的语句总结.html","link":"","permalink":"https://blog.bosong.online/Mybatis%E4%B8%ADSQL%E7%9A%84%E8%AF%AD%E5%8F%A5%E6%80%BB%E7%BB%93.html","excerpt":" 建表\n","text":"建表 查询 简单查询 注意：如果这里不指定parameterType，则默认会识别处理；如果指定了类型，则传入的值就需要和当前指定的类型保持一致，不然就会出现数据类型转换异常。 简单分页查询 left join app_info表和app_verion表分别存储的是应用信息和应用版本信息。现在要根据appId和versionId查出一个应用的具体信息【包括信息信息和版本信息】 批量查询 更新 简单更新 批量更新 有这样一个需求，把 app_info表中id 为1，2，3的app的app_name改为appName1，appName2，appName3;使用 case ..when ..then 这样的语法结构来完成： case 是当前的条件，when表示条件值，then后面是当前目前更新字段的值； 1下面的说明：当前id=#&#123;item.appId&#125;时,app_name=#&#123;item.appName&#125; 还有这样的需要： 根据应用类型的不同，更新不同的运行环境配置； trim属性说明 1.prefix,suffix 表示在trim标签包裹的部分的前面或者后面添加内容 2.如果同时有prefixOverrides,suffixOverrides 表示会用prefix,suffix覆盖Overrides中的内容。 3.如果只有prefixOverrides,suffixOverrides 表示删除开头的或结尾的xxxOverides指定的内容. 删除 简单删除 DELETE FROM app_info where id = #&#123;id&#125; 批量删除 时间字符串 order by 有这样一种情况，在项目中将时间用字符串的方式存在DB中，而不是使用DATE,然后需要按照时间来排序…. 123字符串转为日期格式 SELECT DATE_FORMAT(&#x27;2011-09-20 08:30:45&#x27;, &#x27;%Y-%m-%d %H:%i:%S&#x27;);把日期转为字符串格式 SELECT DATE_FORMAT(NOW(), &#x27;%Y-%m-%d %H:%i:%S&#x27;); 附件： 转自https://www.toutiao.com/a6575727316167557646/","raw":null,"content":null,"categories":[{"name":"Java","slug":"Java","permalink":"https://blog.bosong.online/categories/Java/"}],"tags":[{"name":"mybaties","slug":"mybaties","permalink":"https://blog.bosong.online/tags/mybaties/"}]},{"title":"mysql中间件-Atlas初步试用","slug":"mysql中间件-Atlas初步试用","date":"2018-10-12T02:10:42.000Z","updated":"2022-06-02T01:05:59.616Z","comments":true,"path":"mysql中间件-Atlas初步试用.html","link":"","permalink":"https://blog.bosong.online/mysql%E4%B8%AD%E9%97%B4%E4%BB%B6-Atlas%E5%88%9D%E6%AD%A5%E8%AF%95%E7%94%A8.html","excerpt":"前言Atlas是360开源的mysql数据库中间件，主要致力于读写分离，分片等操作，降低数据库与后端耦合性。","text":"前言Atlas是360开源的mysql数据库中间件，主要致力于读写分离，分片等操作，降低数据库与后端耦合性。 踩坑过程下载地址 https://github.com/Qihoo360/Atlas/releases 下载rpm 版本 直接 rpm -i 文件.rpm进行安装即可 安装好之后文件在&#x2F;usr&#x2F;local&#x2F;mysql-proxy文件夹中 配置conf&#x2F;test.cnf 如下所示： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667[mysql-proxy]#带#号的为非必需的配置项目#模块名称plugins = admin, proxy#管理接口的用户名admin-username = root#管理接口的密码admin-password = password#实现管理接口的Lua脚本所在路径admin-lua-script = /usr/local/mysql-proxy/lib/mysql-proxy/lua/admin.lua#Atlas后端连接的MySQL主库的IP和端口，可设置多项，用逗号分隔proxy-backend-addresses = 192.168.1.1:3306#Atlas后端连接的MySQL从库的IP和端口，@后面的数字代表权重，用来作负载均衡，若省略则默认为1，可设置多项，用逗号分隔proxy-read-only-backend-addresses = 192.168.1.2:3306@1#用户名与其对应的加密过的MySQL密码，密码使用PREFIX/bin目录下的加密程序encrypt加密，下行的user1和user2为示例，将其替换为你的MySQL的用户名和加密密码！pwds = root:m+06L1D7s0r4BeIIXLqb3w==, root:m+06L1D7s0r4BeIIXLqb3w==#设置Atlas的运行方式，设为true时为守护进程方式，设为false时为前台方式，一般开发调试时设为false，线上运行时设为true,true后面不能有空格。daemon = true#设置Atlas的运行方式，设为true时Atlas会启动两个进程，一个为monitor，一个为worker，monitor在worker意外退出后会自动将其重启，设为false时只有worker，没有monitor，一般开发调试时设为false，线上运行时设为true,true后面不能有空格。keepalive = true#工作线程数，对Atlas的性能有很大影响，可根据情况适当设置event-threads = 4#日志级别，分为message、warning、critical、error、debug五个级别log-level = debug#日志存放的路径log-path = /usr/local/mysql-proxy/log#SQL日志的开关，可设置为OFF、ON、REALTIME，OFF代表不记录SQL日志，ON代表记录SQL日志，REALTIME代表记录SQL日志且实时写入磁盘，默认为OFFsql-log = ON#慢日志输出设置。当设置了该参数时，则日志只输出执行时间超过sql-log-slow（单位：ms)的日志记录。不设置该参数则输出全部日志。sql-log-slow = 10#实例名称，用于同一台机器上多个Atlas实例间的区分#instance = test#Atlas监听的工作接口IP和端口proxy-address = 0.0.0.0:31523#Atlas监听的管理接口IP和端口admin-address = 0.0.0.0:31524#分表设置，此例中person为库名，mt为表名，id为分表字段，3为子表数量，可设置多项，以逗号分隔，若不分表则不需要设置该项#tables = person.mt.id.3#默认字符集，设置该项后客户端不再需要执行SET NAMES语句#charset = utf8#允许连接Atlas的客户端的IP，可以是精确IP，也可以是IP段，以逗号分隔，若不设置该项则允许所有IP连接，否则只允许列表中的IP连接#client-ips = 127.0.0.1, 192.168.1#Atlas前面挂接的LVS的物理网卡的IP(注意不是虚IP)，若有LVS且设置了client-ips则此项必须设置，否则可以不设置#lvs-ips = 192.168.1.1 启动方式有两种 一种是官方介绍的 /usr/local/mysql-proxy/bin/mycat start 或者/usr/local/mysql-proxy/bin/mysql-proxy --defaults-file=/usr/local/mysql-proxy/conf/test.cnf 哪个能用用哪个，中间件配好以后，直接使用Navicat连接，连接数据库后可显示两台机器的综合库，数据为两库数据重合部分与不重合部分数据。 使用java-druid连接后，中文乱码，给mysql连接加上characterEncoding=utf-8&amp;zeroDateTimeBehavior=convertToNull&amp;useSSL=true参数即可，读写分离明显。 以上，现阶段还在学习中，后续。","raw":null,"content":null,"categories":[{"name":"中间件","slug":"中间件","permalink":"https://blog.bosong.online/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"}],"tags":[{"name":"数据库中间件","slug":"数据库中间件","permalink":"https://blog.bosong.online/tags/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%B8%AD%E9%97%B4%E4%BB%B6/"}]},{"title":"centos7.4安装MYSQL及主从同步设置","slug":"Centos7-4安装MYSQL及主从同步设置","date":"2018-10-12T02:06:46.000Z","updated":"2022-06-02T01:05:59.611Z","comments":true,"path":"Centos7-4安装MYSQL及主从同步设置.html","link":"","permalink":"https://blog.bosong.online/Centos7-4%E5%AE%89%E8%A3%85MYSQL%E5%8F%8A%E4%B8%BB%E4%BB%8E%E5%90%8C%E6%AD%A5%E8%AE%BE%E7%BD%AE.html","excerpt":"1. 下载mysql wget https://dev.mysql.com/get/Downloads/MySQL-5.7/mysql-5.7.23-linux-glibc2.12-x86_64.tar.gz","text":"1. 下载mysql wget https://dev.mysql.com/get/Downloads/MySQL-5.7/mysql-5.7.23-linux-glibc2.12-x86_64.tar.gz 2. 解压mysqltar -zxvf mysql mysql-5.7.23-linux-glibc2.12-i686.tar.gz 3. 将mysql安装文件移动到系统目录文件夹cp -r mysql/* /usr/local/mysql 4. 安装mysql&#96;bin&#x2F;mysqld –initialize –user&#x3D;mysql –basedir&#x3D;&#x2F;usr&#x2F;local&#x2F;mysql –datadir&#x3D;&#x2F;usr&#x2F;local&#x2F;mysql&#x2F;data –lc_messages_dir&#x3D;&#x2F;usr&#x2F;local&#x2F;mysql&#x2F;share –lc_messages&#x3D;en_US&#96;&#96; - 遇到问题bin/mysqld: error while loading shared libraries: libnuma.so.1: cannot open shared object file: No such file or directory - 解决方案yum -y install numactl - 遇到问题 [ERROR] Could not open file &#39;/var/log/mysqld.log&#39; for error logging: Permission denied - 解决方案touch /var/log/mysqld.log chown mysql:mysql /var/log/mysqld.log - 设置mysql快捷启动 ln -s /usr/local/mysql/bin/mysql /usr/bin - 启动mysqlservice start mysql - 遇到问题/usr/local/mysql/bin/mysqld: Can&#39;t create/write to file &#39;/var/run/mysqld/mysqld.pid&#39; (Errcode: 13 - Permission denied) - 解决方案chown -R mysql /var/run/mysqldchgrp -R mysql /var/run/mysqld service start mysql - 关闭mysqlsystemctl stop mysql - 遇到问题Failed to restart mysql.service: Unit not found. - 解决方案systemctl enable mysql.service 进入/var/log/mysqld.log 最后一行为密码 - 进入mysqlmysql -uroot -p - 修改初始密码set password=password(&quot;new password&quot;); - 设置外部访问use mysql; update user set host=&#39;%&#39; where user=&#39;root&#39; and host=&#39;localhost&#39;; flush privileges; - 记录File和Position对应的信息(主库)show master status; - 配置同步（从库）stop slave; change master to master_host=&#39;35.203.167.155:31521&#39;, master_user=&#39;root&#39;,master_password=&#39;qwe13579QWE&#39;,master_file_log=&#39;log.000007&#39;,master_log_pos=&#39;1357&#39;; - 遇到问题ERROR 1064 (42000): You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near &#39;master_file_log=log.000007,master_log_pos=1357&#39; at line 1 - 解决方案（MASTER_LOG_FILE,MASTER_LOG_POS为主库的信息）CHANGE MASTER TO MASTER_HOST=&#39;192.168,1.1&#39;, MASTER_PORT=3306,MASTER_USER=&#39;root&#39;, MASTER_PASSWORD=&#39;mypassword&#39;, MASTER_LOG_FILE=&#39;log.000004&#39;, MASTER_LOG_POS=1665; - 启动同步start slave; 查看同步状态show slave status \\G; 验证，可在主库创建数据库后查看从库，然后从从库再写数据，验证主动同步。","raw":null,"content":null,"categories":[{"name":"Linux","slug":"Linux","permalink":"https://blog.bosong.online/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://blog.bosong.online/tags/Linux/"}]},{"title":"nginx负载均衡策略","slug":"nginx负载均衡策略","date":"2018-10-12T02:02:04.000Z","updated":"2022-06-02T01:05:59.616Z","comments":true,"path":"nginx负载均衡策略.html","link":"","permalink":"https://blog.bosong.online/nginx%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E7%AD%96%E7%95%A5.html","excerpt":"nginx负载均衡策略相对来说比较方便配置。\n策略有以下几种：","text":"nginx负载均衡策略相对来说比较方便配置。 策略有以下几种： 1)、轮询（默认） 每个请求按时间顺序逐一分配到不同的后端服务器，如果后端服务器down掉，能自动剔除。 12345678910111213141516upstream test &#123; server 10.0.1.31:8080; server 10.0.1.32:8080;&#125; server&#123; listen 80; server_name www.xxxx.com; location / &#123; proxy_pass http://test; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; &#125;&#125; 2)、weight 指定轮询几率，weight和访问比率成正比，用于后端服务器性能不均的情况。 12345678910111213141516171819202122232425upstream test &#123; server 10.0.1.31:8080 down; server 10.0.1.32:8080 weight=2; server 10.0.1.33:8080; server 10.0.1.34:8080 backup; &#125;server&#123; listen 80; server_name www.xxxx.com; location / &#123; proxy_pass http://test; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; &#125;&#125; upstream 每个设备的状态:down 表示单前的server暂时不参与负载 weight 默认为1.weight越大，负载的权重就越大。 max_fails ：允许请求失败的次数默认为1.当超过最大次数时，返回proxy_next_upstream 模块定义的错误 fail_timeout:max_fails 次失败后，暂停的时间。 backup： 其它所有的非backup机器down或者忙的时候，请求backup机器。所以这台机器压力会最轻 3)、ip_hash 每个请求按访问ip的hash结果分配，这样每个访客固定访问一个后端服务器，可以解决session的问题。 1234567891011121314151617upstream test &#123; server 127.0.0.1:8080 ; server 127.0.0.1:9090 ; ip_hash;&#125;server&#123; listen 80; server_name www.xxxx.com; location / &#123; proxy_pass http://test; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; &#125;&#125; 4)、第三方插件 关于第三方插件，可以自行了解一下， 本文不做赘述 负载均衡导致的问题在实际应用中，负载均衡肯定不会只用于静态页面，更多的是页面的交互，这样一来session会话的保持变成了负载均衡的问题所在。 session的保持主要可以使用三种方式 1、会话保持 对于Nginx可以选用Session保持的方法实行负载均衡，nginx的upstream目前支持5种方式的分配方式，其中有两种比较通用的Session解决方法，ip_hash和url_hash。注意：后者不是官方模块，需要额外安装。 ip_hash 每个请求按访问ip的hash结果分配，这样每个访客固定访问一个后端服务器，达到了Session保持的方法。此种方法实现在上面有说明。 它的缺点是 负载未实现真正意义的均衡：由于使用了Session保持，很显然就无法保证负载绝对的均衡。 会话丢失可能性较大：如果后端有服务器宕机，那么这台服务器的Session丢失，被分配到这台服务请求的用户还是需要重新登录。 2、会话复制 会话复制在Tomcat上得到了支持，它是基于IP组播（multicast）来完成Session的复制，Tomcat的会话复制分为两种： 全局会话复制：利用Delta Manager复制会话中的变更信息到集群中的所有其他节点。 非全局复制：使用Backup Manager进行复制，它会把Session复制给一个指定的备份节点。 可以参考Tomcat官方文档，主要是因为会话复制不适合大的集群。不推荐生产服务器使用此种方式。 3、会话共享 共享就意味着借用第三方缓存来对seesion进行存储，后端服务器可根据存储来判断会话的正确性。 缓存的方式较多，比较常用的方法是redis缓存，redis是key-value的内存性数据库，吞吐量极高，在一定的内存下，除非并发数极高，否则很难达到redis的吞吐极限。 使用redis作为session缓存，直接将会话信息存储到redis中，服务端以高效率读取redis中session，实现了负载均衡情况下seesion的会话保持。它的性能决定了它的瓶颈较高，一般情况下足够使用。","raw":null,"content":null,"categories":[{"name":"Linux","slug":"Linux","permalink":"https://blog.bosong.online/categories/Linux/"}],"tags":[{"name":"nginx","slug":"nginx","permalink":"https://blog.bosong.online/tags/nginx/"}]},{"title":"mysql-slave踩坑日记","slug":"Mysql-slave踩坑日记","date":"2018-10-12T01:59:34.000Z","updated":"2022-06-02T01:05:59.614Z","comments":true,"path":"Mysql-slave踩坑日记.html","link":"","permalink":"https://blog.bosong.online/Mysql-slave%E8%B8%A9%E5%9D%91%E6%97%A5%E8%AE%B0.html","excerpt":"晚上闲来无事，想找点事做于是手动删除了一些无用的数据库，手贱的是在从库里面删除了","text":"晚上闲来无事，想找点事做于是手动删除了一些无用的数据库，手贱的是在从库里面删除了 然后，在主库里面也进行该数据库删除，发现未手动删除的从库正常执行了binlog日志中的sql语句 一段时间后，问题出现了自己手动在主库里插入一条语句，发现两个备库只有一个备库更新了最新的数据，手动删除数据库的那个从库并未更新语句 接下来，查询从库mysql日志 发现 122018-08-19T19:27:04.704407+08:00 6 [ERROR] Slave SQL for channel &#x27;&#x27;: Error &#x27;Can&#x27;t drop database &#x27;jeewx-h5&#x27;; database doesn&#x27;t exist&#x27; on query. Default database: &#x27;jeewx-h5&#x27;. Query: &#x27;DROP DATABASE `jeewx-h5`&#x27;, Error_code: 10082018-08-19T19:27:04.704429+08:00 6 [Warning] Slave: Can&#x27;t drop database &#x27;jeewx-h5&#x27;; database doesn&#x27;t exist Error_code: 1008 主从复制报错，出现故障，导致后面的日志内容无法进行 接下来，解决方法： 1234567891011121314151617181920mysql -uroot -p mysql&gt; slave stop; Query OK, 0 rows affected (0.01 sec)mysql&gt; set GLOBAL SQL_SLAVE_SKIP_COUNTER=1;Query OK, 0 rows affected (0.00 sec)mysql&gt; slave start;Query OK, 0 rows affected (0.00 sec)mysql&gt; show slave status\\G;Slave_IO_Running: YesSlave_SQL_Running: YesLast_IO_Errno: 0Last_IO_Error: Last_SQL_Errno: 0 将指针移动下一位，问题得到解决。并且后面的操作正常执行。 仅此记录，另外 少操作，甚至不操作从库！！！！","raw":null,"content":null,"categories":[{"name":"数据库","slug":"数据库","permalink":"https://blog.bosong.online/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"https://blog.bosong.online/tags/mysql/"}]},{"title":"kafka使用规范","slug":"kafka使用规范","date":"2018-10-12T01:56:05.000Z","updated":"2022-06-02T01:05:59.615Z","comments":true,"path":"kafka使用规范.html","link":"","permalink":"https://blog.bosong.online/kafka%E4%BD%BF%E7%94%A8%E8%A7%84%E8%8C%83.html","excerpt":"客户端：根据具体消息业务需要，调整配置以下参数：","text":"客户端：根据具体消息业务需要，调整配置以下参数： 1.是否启用压缩方式compressionCodec 2.消息确认方式：request.required.acks 3.消息发送类型，同步异步：producer.type 4.异步模式下缓冲的最大消息数(queue.buffering.max.messages) 5.异步模式下，每次发送的消息数(batch.num.messages) 6.消费者socket接收缓存空间大小(socket.receive.buffer.bytes) 7.消费者从每个分区fetch的消息大小(fetch.message.max.bytes) 8.消费者配置rebalance.max.retries * rebalance.backoff.ms &gt; zookeeper.session.timeout.ms 9.消费者消费起始位置配置：auto.offset.reset 10.消费者group.id 服务端：1.调整服务器最大打开文件数限制：ulimit 2.Kafka建议开启JMX监控端口 3.broker配置： kafka server.properties配置参数策略 注：以下各值仅供参考，具体配置值需根据实际硬件环境情况调整 必须的参数配置： #broker在集群中的唯一表示 broker.id&#x3D;0 #broker处理消息的最大线程数，建议为cpu核数 num.network.threads&#x3D;4 #broker处理磁盘IO的线程数 ，建议为cpu核数2倍 num.io.threads&#x3D;8 #socket的发送缓冲区 socket.send.buffer.bytes&#x3D;1048576 #socket的接受缓冲区 socket.receive.buffer.bytes&#x3D;1048576 #socket请求的最大数值，防止serverOOM，message.max.bytes要小于socket.request.max.bytes，会被topic创建时的指定参数覆盖 socket.request.max.bytes&#x3D;104857600 #kafka数据的存放地址，多个地址的话用逗号分割,多个目录分布在不同磁盘上可以提高读写性能 log.dirs&#x3D;&#x2F;tmp&#x2F;kafka-logs #topic的分区个数,根据broker数量灵活调整 num.partitions&#x3D;2 #数据文件保留多长时间， 存储的最大时间,超过这个时间会根据log.cleanup.policy设置数据清除策略 log.retention.hours&#x3D;168 #topic的分区是以一堆segment文件存储的，控制每个segment的大小 log.segment.bytes&#x3D;536870912 #文件大小检查的周期时间，是否触发 log.cleanup.policy中设置的策略 log.retention.check.interval.ms&#x3D;600000 #是否开启日志清理 log.cleaner.enable&#x3D;true #zookeeper集群的地址，逗号分隔多个 zookeeper.connect&#x3D; #ZooKeeper连接超时时间 zookeeper.connection.timeout.ms&#x3D;1000000 建议优化的参数配置： #broker的主机地址，默认null,一般不设置. #若是设置会绑定到这个特定地址（IP或hostName,若设置为hostname时消费者端服务器需配置host解析） #若是没有，会绑定到所有的IP地址上，并将其中之一发送到ZK host.name&#x3D;borkerIp #为提高producer写入TPS,建议设置如下参数，取值根据应用情况 #每达到消息数时写入磁盘 log.flush.interval.messages&#x3D;10000 #每间隔1秒钟时间，刷数据到磁盘 log.flush.interval.ms&#x3D;1000 #日志文件清理策略：delete和compact（删除\\压缩）主要针对过期数据的处理 log.cleanup.policy &#x3D; delete #replication对写入TPS有影响，建议设置为最小副本数 default.replication.factor&#x3D;3","raw":null,"content":null,"categories":[{"name":"研发规范","slug":"研发规范","permalink":"https://blog.bosong.online/categories/%E7%A0%94%E5%8F%91%E8%A7%84%E8%8C%83/"}],"tags":[{"name":"kafka","slug":"kafka","permalink":"https://blog.bosong.online/tags/kafka/"}]},{"title":"RabbitMQ使用规范","slug":"RabbitMQ使用规范","date":"2018-10-12T01:54:04.000Z","updated":"2022-06-02T01:05:59.615Z","comments":true,"path":"RabbitMQ使用规范.html","link":"","permalink":"https://blog.bosong.online/RabbitMQ%E4%BD%BF%E7%94%A8%E8%A7%84%E8%8C%83.html","excerpt":"命名规范\n #命名规范：容器名称.[队列特点or路由特点].使用的平台名称.作用","text":"命名规范 #命名规范：容器名称.[队列特点or路由特点].使用的平台名称.作用 #@容器名称：queue、exchange #@队列特点：非持久化标记(undurable)、延时队列(delay)、优先级队列(priority) #@路由特点：direct、topic、fanout、headers #@使用的平台名称：xiangshang、xiangqian…… #@作用：干什么的 #eg：消息队列（queue.xiangshang.message）、延时消息队列（queue.delay.xiangshang.message）、普通路由（exchange.direct.xiangshang.common）、通用路由（exchange.direct.xiangshang.common）","raw":null,"content":null,"categories":[{"name":"研发规范","slug":"研发规范","permalink":"https://blog.bosong.online/categories/%E7%A0%94%E5%8F%91%E8%A7%84%E8%8C%83/"}],"tags":[{"name":"rabbitmq","slug":"rabbitmq","permalink":"https://blog.bosong.online/tags/rabbitmq/"}]},{"title":"MongoDB研发规范","slug":"MongoDB研发规范","date":"2018-10-12T01:51:01.000Z","updated":"2022-06-02T01:05:59.614Z","comments":true,"path":"MongoDB研发规范.html","link":"","permalink":"https://blog.bosong.online/MongoDB%E7%A0%94%E5%8F%91%E8%A7%84%E8%8C%83.html","excerpt":"库设计l mongodb数据库命名规范：db_xxxx禁止使用任何 “ _ “（下划线）外的特殊字符","text":"库设计l mongodb数据库命名规范：db_xxxx禁止使用任何 “ _ “（下划线）外的特殊字符 l 库名全部小写，禁止使用任何_以外的特殊字符，禁止使用数字打头的库名，如：123_abc l 库以文件夹的形式存在，使用特殊字符或其它不规范的命名方式会导致命名混乱数据库名最多为64字符 l 在创建新的库前应尽量评估该库的体积、QPS等 l 不能为空字符串(” “) l 不能以$开头 l 不能包含.(点号)和空字符串 l 数据库名区分大小写(建议数据库名全部使用小写) l 数据库名最长为64个字节 l 不要与系统保留的数据库名相同,这写数据库包括:admin,local,config等 集合设计l mongodb集合命名规范：t_xxxx l 集合名全部小写，禁止使用任何_以外的特殊字符，禁止使用数字打头的集合名，如：123_abc，禁止system打头 l system是系统集合前缀集合名称最多为64字符为了避免库级锁带来的问题，应尽量对写入较大的集合使用“单库单集合”的结构，所以对于新增业务应尽量创建新库，而不是在现有库中创建新集合 l 一个库中写入较大的集合会影响其它集合的读写性能如果评估单集合数据量较大，可以将一个大表拆分为多个小表，然后将每一个小表存放在独立的库中，由于MongoDB是库级锁，因此这样做可以大幅减少并发写入带来的锁争用问题 l 集合名不能为空字符串(” “) l 不能包含\\0或空字符,这个字符表示键的结尾 l 集合名不能以”system.”开头,此前缀是系统本身保留的 l 集合名不能包含$字符(注:可包含 . 点号) 文档设计l 文档中的key禁止使用任何_以外的特殊字符 l 尽量将同样类型的文档存放在一个集合中，将不同类型的文档分散在不同的集合中 l 相同类型的文档能够大幅度提高索引利用率，如果文档混杂存放则可能会出现查询经常需要全表扫描的情况 l 禁止使用_id，如：向_id中写入自定义内容 l 尽量存放统一小写后的数据 l 尽可能的缩短key的长度(注意是尽可能！会涉及到性能问题) 索引设计l 优先使用覆盖索引 l MongoDB 的组合索引使用策略与 MySQL 一致，遵循“最左原则” l 索引名称长度不要超过128字符 l 应尽量综合评估查询场景,通过评估尽可能的将单列索引并入组合索引以降低所以数量，结合1，2点 l 在创建组合索引的时候，应评估索引中包含的字段，尽量将数据基数大的字段放在组合索引的前面 l 在数据量较大的时候，MongoDB 索引的创建是一个缓慢的过程，所以应当在上前线或数据量变得很大前尽量评估，按需创建会用到的索引 l MongoDB 的索引创建是库级锁，在索引创建时该集合所在库不可读写 l 特别注意基于地理位置的索引建立时会带来的问题。","raw":null,"content":null,"categories":[{"name":"研发规范","slug":"研发规范","permalink":"https://blog.bosong.online/categories/%E7%A0%94%E5%8F%91%E8%A7%84%E8%8C%83/"}],"tags":[{"name":"mongodb","slug":"mongodb","permalink":"https://blog.bosong.online/tags/mongodb/"}]},{"title":"记录一次数据库慢sql","slug":"记录一次数据库慢sql","date":"2018-10-10T10:28:34.000Z","updated":"2022-06-02T01:05:59.618Z","comments":true,"path":"记录一次数据库慢sql.html","link":"","permalink":"https://blog.bosong.online/%E8%AE%B0%E5%BD%95%E4%B8%80%E6%AC%A1%E6%95%B0%E6%8D%AE%E5%BA%93%E6%85%A2sql.html","excerpt":"起因由于数据库系统的查询一直在使用es监控，某一天收到一条报警记录","text":"起因由于数据库系统的查询一直在使用es监控，某一天收到一条报警记录 在遇到这个告警的时候，还存在一些疑问，这么简单的sql居然会报慢查询。 经过经过查看数据库数据，发现由于topic_type只有1和0两个状态，就未给它设置索引 结果经过查看该表有数据40+W，在sql中topic_type&#x3D;1的数据比formid的数据多的多，导致了查询时导致了慢sql 后记修改了sql的查询顺序，发现再也没有慢日志产生，由此得出结论： 数据库语句查询条件并非并行，而是有先后关系，所以一定要注意查询语句的先后关系，范围小的先放前面 该加索引就必须加索引，数据库性能达到瓶颈能导致整个系统崩溃 微服务环境下，不仅要分库分表，还需要将不同服务的数据库分别部署，增强容灾性，一旦某个库达到瓶颈，后果会形成链式反应","raw":null,"content":null,"categories":[{"name":"Java","slug":"Java","permalink":"https://blog.bosong.online/categories/Java/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"https://blog.bosong.online/tags/mysql/"}]},{"title":"Elasticsearch的功能、使用场景以及特点","slug":"Elasticsearch的功能、使用场景以及特点","date":"2018-10-10T07:39:28.000Z","updated":"2022-06-02T01:05:59.612Z","comments":true,"path":"Elasticsearch的功能、使用场景以及特点.html","link":"","permalink":"https://blog.bosong.online/Elasticsearch%E7%9A%84%E5%8A%9F%E8%83%BD%E3%80%81%E4%BD%BF%E7%94%A8%E5%9C%BA%E6%99%AF%E4%BB%A5%E5%8F%8A%E7%89%B9%E7%82%B9.html","excerpt":"1、Elasticsearch的功能（1）分布式的搜索引擎和数据分析引擎","text":"1、Elasticsearch的功能（1）分布式的搜索引擎和数据分析引擎 搜索：百度，网站的站内搜索，IT系统的检索数据分析：电商网站，最近7天牙膏这种商品销量排名前10的商家有哪些；新闻网站，最近1个月访问量排名前3的新闻版块是哪些分布式，搜索，数据分析 （2）全文检索，结构化检索，数据分析 全文检索：我想搜索商品名称包含牙膏的商品，select * from products where product_name like “%牙膏%”结构化检索：我想搜索商品分类为日化用品的商品都有哪些，select * from products where category_id&#x3D;’日化用品’ 部分匹配、自动完成、搜索纠错、搜索推荐 数据分析：我们分析每一个商品分类下有多少个商品，select category_id,count(*) from products group by category_id （3）对海量数据进行近实时的处理 分布式：ES自动可以将海量数据分散到多台服务器上去存储和检索海量数据的处理：分布式以后，就可以采用大量的服务器去存储和检索数据，自然而然就可以实现海量数据的处理了 近实时：检索个数据要花费1小时（这就不要近实时，离线批处理，batch-processing）；在秒级别对数据进行搜索和分析跟分布式&#x2F;海量数据相反的：lucene，单机应用，只能在单台服务器上使用，最多只能处理单台服务器可以处理的数据量 2、Elasticsearch的适用场景国外 （1）维基百科，类似百度百科，牙膏，牙膏的维基百科，全文检索，高亮，搜索推荐 （2）The Guardian（国外新闻网站），类似搜狐新闻，用户行为日志（点击，浏览，收藏，评论）+社交网络数据（对某某新闻的相关看法），数据分析，给到每篇新闻文章的作者，让他知道他的文章的公众反馈（好，坏，热门，垃圾，鄙视，崇拜） （3）Stack Overflow（国外的程序异常讨论论坛），IT问题，程序的报错，提交上去，有人会跟你讨论和回答，全文检索，搜索相关问题和答案，程序报错了，就会将报错信息粘贴到里面去，搜索有没有对应的答案 （4）GitHub（开源代码管理），搜索上千亿行代码（5）电商网站，检索商品（6）日志数据分析，logstash采集日志，ES进行复杂的数据分析（ELK技术，elasticsearch+logstash+kibana） （7）商品价格监控网站，用户设定某商品的价格阈值，当低于该阈值的时候，发送通知消息给用户，比如说订阅牙膏的监控，如果高露洁牙膏的家庭套装低于50块钱，就通知我，我就去买 （8）BI系统，商业智能，Business Intelligence。比如说有个大型商场集团，BI，分析一下某某区域最近3年的用户消费金额的趋势以及用户群体的组成构成，产出相关的数张报表，**区，最近3年，每年消费金额呈现100%的增长，而且用户群体85%是高级白领，开一个新商场。ES执行数据分析和挖掘，Kibana进行数据可视化 国内（9）国内：站内搜索（电商，招聘，门户，等等），IT系统搜索（OA，CRM，ERP，等等），数据分析（ES热门的一个使用场景） 3、Elasticsearch的特点（1）可以作为一个大型分布式集群（数百台服务器）技术，处理PB级数据，服务大公司；也可以运行在单机上，服务小公司 （2）Elasticsearch不是什么新技术，主要是将全文检索、数据分析以及分布式技术，合并在了一起，才形成了独一无二的ES；lucene（全文检索），商用的数据分析软件（也是有的），分布式数据库（mycat） （3）对用户而言，是开箱即用的，非常简单，作为中小型的应用，直接3分钟部署一下ES，就可以作为生产环境的系统来使用了，数据量不大，操作不是太复杂 （4）数据库的功能面对很多领域是不够用的（事务，还有各种联机事务型的操作）；特殊的功能，比如全文检","raw":null,"content":null,"categories":[{"name":"数据库","slug":"数据库","permalink":"https://blog.bosong.online/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"elasticsearch","slug":"elasticsearch","permalink":"https://blog.bosong.online/tags/elasticsearch/"}]},{"title":"MYSQL线上审核规范","slug":"MYSQL线上审核规范","date":"2018-10-10T07:39:28.000Z","updated":"2022-06-02T01:05:59.614Z","comments":true,"path":"MYSQL线上审核规范.html","link":"","permalink":"https://blog.bosong.online/MYSQL%E7%BA%BF%E4%B8%8A%E5%AE%A1%E6%A0%B8%E8%A7%84%E8%8C%83.html","excerpt":"命名规范Ø库名、表名、字段名，使用小写字母","text":"命名规范Ø库名、表名、字段名，使用小写字母 Ø库名、表名、字段名，不要超过30个字符 Ø库名、表名、字段名，尽量见名知意，使用下划线分割 Ø库名、表名、字段名，禁止使用MySQL保留字 Ø临时库、表名，必须以tmp为前缀，以日期为后缀，例如tmp_product_20151229 Ø备份表、表名，必须以日期为后缀，例如produce_bak_20151229 库表设计Ø表必须有主键，使用bigint unsigned类型auto_increment属性 Ø除主键外的其他字段都必须有注释，所有表都必须有说明 Ø最多更改和查询的字段放在基础表内，方便完整载入内存 Ø访问频率低的或大字段放到扩展表里，分离冷热数据 Ø多张关联表之间，适当的冗余字段，可以减少JOIN查询 Ø如果预计数据量较大，预先制定分表策略，如按日期拆分或按某键值取模分表 Ø尽量不用分区表，如需使用请与DBA沟通 字段设计Ø只有主键使用UNSIGNED属性，其他数值列不要使用，因为计算出现负数时会报错 Ø当字符串较短，或数据频繁更新时，可以使用CHAR(N)，N表示字符数而非字节数 Ø当字符串长度可预见时，可以使用VARCHAR(N)，N表示字符数而非字节数 Ø使用DECIMAL代替FLOAT和DOUBLE，以存储精确浮点数，例如支付相关数据 Ø使用INT系类型代替ENUM类型，前者只要自己定义，后者却要修改表 Ø使用INT UNSIGNED存储IPV4，inet_aton()和inet_ntoa()用于IPV4与INT互转 Ø尽可能不使用TEXT类型，禁止使用BLOB类型 Ø所有字段必须定义为NOT NULL，定义为default 0或default ‘’，NULL可能在计数(count)和匹配(is null)时引起歧义 索引设计Ø如多个字段组合有唯一性需要，可以创建唯一索引 Ø不在低基数(低筛选度)的列上建立索引，例如“性别” Ø一条SQL只会用到一个索引，无用的索引越多，写入性能越差 Ø禁止冗余索引，如已有(a,b)索引，可以删除(a)索引 Ø合理创建组合索引，(a,b,c)相当于(a)、(a,b)、(a,b,c) Ø组合索引的组成字段数尽量不超过3个 Ø组合索引中，区分度大(高筛选度)的字段放在最前 Ø尽可能利用索引完成排序，即排序的字段在索引里，且不使用降序排序 Ø适度将组合索引提升为覆盖索引，避免回表，减少IO Ø对较长字符串可使用前缀索引，前缀索引长度由数据区分度确定 Ø禁止使用外键，防止死锁，避免隐藏的数据逻辑 Ø数据扫描过多，如所有索引的过虑性不佳，会放弃使用索引 Ø仅使用最有效的过滤条件，索引不是越长越好，where条件并不是越多越好 Ø普通索引按照“idx_表名_字段名称”进行命名，例如idx_table1_name Ø唯一索引按照“uniq_表名_字段名称”进行命名，例如uniq_table1_name Ø索引名必须全部使用小写，过长的字段名可以采⽤缩写形式，例如idx_t1_name_ageSQL编写 Ø尽量使用主键，且不要修改主键的值 Ø只select需要的字段，禁止使用select * Ø分批获取大量数据时，禁止大偏移量的limit M,N语句，使用主键游标 where PK&gt;… limit N Ø同字段OR条件，用IN代替，包含的值个数应少于300个 Ø禁止隐式转换，数值类型禁止加引号，字符和日期类型必须加引号 Ø减少与数据库交互次数，尽量采用批量递交、块插入和缓存(memcache) Ø使用prepared statement批量递交语句，可以提升性能，且避免SQL注⼊ Ø注意UNION ALL和UNION的区别，UNION默认有去重效果 Ø统计行数时，使用COUNT(*)或COUNT(1)，不要使用count(字段名)，会忽略值为NULL的行 Ø写入语句中禁止出现结果不确定的函数，如sysdate()、rand()、current_user()等 ØINSERT语句必须指定字段列表，禁止使用 INSERT INTO xxx values() Ø执行频率高的SQL和重要功能的SQL，都必须能有索引可用 Ø禁止使用左%模糊匹配，例如like ‘%abc’，无法用到索引 Ø禁止使用反向匹配，例如 not in、!&#x3D;、not like，无法用到索引 Ø禁止在SQL中进行算术和函数计算，应放置到应用服务器端 Ø保证每张表的JOIN列的数据类型相同，并且都建立了索引 Ø禁止使用order by rand()实现乱序效果，会导致CPU过高 Ø禁止JOIN和子查询，如无法避免，应尽可能进行优化 Ø适当增加冗余字段，避免关联JOIN查询 Ø可以拆分复杂的JOIN为多个小SQL，避免大语句 Ø尽可能减少Join语句中的循环总次数，就是让驱动表的结果集尽可能的小，永远用小结果集驱动大的结果集 Ø优先优化内层循环，内层循环是循环中执行次数最多的，每次循环节约很小的资源，在整个循环中就能节约很大的资源 Ø子查询只允许返回主键和必须的字段，不允许select * Ø禁止单条SQL语句同时更新多个表，拆分成多条SQL，放在一个事务里 Ø程序应有捕获SQL异常的处理机制，必要时通过rollback显式回滚 Ø严禁大事务，会锁住更多的资源，引发更多的等待和竞争 Ø不同事务对同一批表的操作，要前后顺序一致","raw":null,"content":null,"categories":[{"name":"研发规范","slug":"研发规范","permalink":"https://blog.bosong.online/categories/%E7%A0%94%E5%8F%91%E8%A7%84%E8%8C%83/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"https://blog.bosong.online/tags/mysql/"}]},{"title":"MySQL特殊字段类型选择","slug":"MySQL特殊字段类型选择","date":"2018-10-10T07:39:28.000Z","updated":"2022-06-02T01:05:59.614Z","comments":true,"path":"MySQL特殊字段类型选择.html","link":"","permalink":"https://blog.bosong.online/MySQL%E7%89%B9%E6%AE%8A%E5%AD%97%E6%AE%B5%E7%B1%BB%E5%9E%8B%E9%80%89%E6%8B%A9.html","excerpt":"","text":"金额字段类型选择1.decimaldecimal(M,N) 0&lt;M&lt;65,0&lt;N&lt;30,且N&lt;M,M和N的长度直接影响存储空间 默认情况，表示金额的情况，decimal(16,2),范围是99,999,999,999,999.99 to -99,999,999,999,999.99 占用空间为8个字节 存储时会四舍五入 2.bigint占用空间为8个字节 存储相同大写的数字是，decimal比bigint多1个字节 存入数据库时，decimal会做四舍五入 create table ta (a decimal(4,2),b int); insert into ta (a,b) values(99.006,9900); select * from ta; 12345678910+-------+------+| a | b |+-------+------+| 99.01 | 9900 |+-------+------+ 总结：1.decimal&amp;bigtin在做计算时，都不会丢失精度（float&amp;double在极端情况下会丢失精度），但是在存入mysql数据库时，decimal会做四舍五入，而int不存在这种情况。 2.金额字段使用decimal类型时，默认单位为元，比较直观，没有歧义 3.金额字段使用bigint时，需要特殊说明单位为分，程序处理时，可以直接使用整数类型long，较通用 4.存储相关大小的金额时（bigint以分为单位），decimal占用空间比bigint微大 综上所诉：建议用bigint来存储金额 时间字段类型选择1.timestamp占用4个字节 时区转化 ，存储时对当前的时区进行转换，检索时再转换回当前的时区，对于跨时区跨机房的主从同步有影响 默认值为CURRENT_TIMESTAMP()，其实也就是当前的系统时间 timestamp容易受mysql sqlmode，timezone参数影响，局限性大 支持范围1970-01-01 08:00:01 ~ 2038-01-19 11:14:07 不推荐使用 2.bigint占用8个字节 与时区有关，通过System.currentTimeMillis()获取 建立索引之后，查询速度快，条件范围搜索可以使用使用between 支持范围1970-01-01 08:00:01 ~ 2038-01-19 11:14:07 支持精确到毫秒级别 PS: 适合需要进行大量时间范围查询的数据表 3.datetime占用8个字节 允许为空值，可以自定义值，系统不会自动修改其值 与时区无关 不可以设定默认值，所以在不允许为空值的情况下，必须手动指定datetime字段的值才可以成功插入数据 可以在指定datetime字段的值的时候使用now()变量来自动插入系统的当前时间 支持范围：1000-01-01 00:00:00 ~ 9999-12-31 23:59:59 总结：1.性能：bigint性能最高，如果程序有通过时间排序的场景，优势巨大 2.通用性：bigint不受平台限制，所有系统都能通用，不会对后期的升级迁移造成困扰 3.精度：bigint能够精确到毫秒级别，对于高并发，高精度查询，帮助大 4.可读性：bigint不如datetime,开发成本大","raw":null,"content":null,"categories":[{"name":"数据库","slug":"数据库","permalink":"https://blog.bosong.online/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"https://blog.bosong.online/tags/mysql/"}]},{"title":"MySQL线上语句标准格式","slug":"MySQL线上语句标准格式","date":"2018-10-10T07:39:28.000Z","updated":"2022-06-02T01:05:59.614Z","comments":true,"path":"MySQL线上语句标准格式.html","link":"","permalink":"https://blog.bosong.online/MySQL%E7%BA%BF%E4%B8%8A%E8%AF%AD%E5%8F%A5%E6%A0%87%E5%87%86%E6%A0%BC%E5%BC%8F.html","excerpt":"CREATE DATABASE标准SQL12345SET NAMES UTF8;CREATE DATABASE example_db DEFAULT CHARACTER SET utf8 COLLATE utf8_bin; #collate建议使用utf8-bin","text":"CREATE DATABASE标准SQL12345SET NAMES UTF8;CREATE DATABASE example_db DEFAULT CHARACTER SET utf8 COLLATE utf8_bin; #collate建议使用utf8-bin CREATE TABLE标准SQL12345678910111213141516171819202122232425262728293031323334353637SET NAMES UTF8;DROP TABLE IF EXISTS example_db.example;CREATE TABLE example_db.example( #常规字段为 int,bigint,varchar,text,tinyint`id` int(10) UNSIGNED NOT NULL COMMENT &#x27;comment&#x27; AUTO_INCREMENT,`account_id` bigint(20) UNSIGNED NOT NULL DEFAULT 0 COMMENT &#x27;comment&#x27;, `telephone` bigint(20) UNSIGNED NOT NULL DEFAULT 0 COMMENT &#x27;comment&#x27;,`card_amount` bigint(20) UNSIGNED NOT NULL DEFAULT 0 COMMENT &#x27;comment&#x27;, #涉及到金额的，请使用bigint，单位为分 `name` varchar(5) NOT NULL DEFAULT &#x27;&#x27; COMMENT &#x27;comment&#x27;, #varchar字段，建议使用长度5,30,50,100,255,500,1000,5000`desc` varchar(30) NOT NULL DEFAULT &#x27;&#x27; COMMENT &#x27;comment&#x27;,`info` varchar(50) NOT NULL DEFAULT &#x27;&#x27; COMMENT &#x27;comment&#x27;,`addr` varchar(100) NOT NULL DEFAULT &#x27;&#x27; COMMENT &#x27;comment&#x27;,`json` text NOT NULL COMMENT &#x27;comment&#x27;, #存储json格式字段`status` tinyint(1) UNSIGNED NOT NULL DEFAULT 1 COMMENT &#x27;comment&#x27;, #1为正常数据，0为删除数据`create_time` datetime default now() comment &#x27;创建时间&#x27;,`update_time` datetime default now() comment &#x27;更新时间&#x27;,PRIMARY KEY `idx_id` (`id`), #主键，请合理选择KEY `idx_user_name` (`name`) #请加必要的业务相关索引，命名规则为idx_field1_field2) ENGINE=InnoDB AUTO_INCREMENT=1 DEFAULT CHARSET=utf8 COMMENT &#x27;comment&#x27;; INSERT&amp;UPDATE标准SQL12345678SET NAMES UTF8;INSERT INTO example (iIntID,sVar0,sVar1,sVar2) VALUES (1,&#x27;中国&#x27;,&#x27;上海&#x27;,&#x27;浦东&#x27;);UPDATE example SET iStatus = 0, type = 1 WHERE iAutoID = 1; 修改表结构标准SQL12345678ALTER TABLE example_db.exampleADD COLUMN sMobilePhone VARCHAR(30) NOT NULL DEFAULT &#x27;&#x27; COMMENT &#x27;手机号码&#x27; AFTER create_time; #建议指定新加column的位置ALTER TABLE example_db.exampleCHANGE COLUMN smobilePhone sMobilePhone VARCHAR(50) NOT NULL DEFAULT &#x27;&#x27; COMMENT &#x27;手机号码&#x27;; 增加索引1ALTER TABLE example_db.example ADD INDEX idx_name(name); 删除表字段1ALTER TABLE products DROP COLUMN description;","raw":null,"content":null,"categories":[{"name":"研发规范","slug":"研发规范","permalink":"https://blog.bosong.online/categories/%E7%A0%94%E5%8F%91%E8%A7%84%E8%8C%83/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"https://blog.bosong.online/tags/mysql/"}]},{"title":"redis-开发规范","slug":"Redis-开发规范","date":"2018-10-10T07:39:28.000Z","updated":"2022-06-02T01:05:59.615Z","comments":true,"path":"Redis-开发规范.html","link":"","permalink":"https://blog.bosong.online/Redis-%E5%BC%80%E5%8F%91%E8%A7%84%E8%8C%83.html","excerpt":"1.冷热数据分离，不要将所有数据全部都放到Redis中虽然Redis支持持久化，但是Redis的数据存储全部都是在内存中的，成本昂贵。建议根据业务只将高频热数据存储到Redis中【QPS大于5000】，对于低频冷数据可以使用MySQL&#x2F;ElasticSearch&#x2F;MongoDB等基于磁盘的存储方式，不仅节省内存成本，而且数据量小在操作时速度更快、效率更高！","text":"1.冷热数据分离，不要将所有数据全部都放到Redis中虽然Redis支持持久化，但是Redis的数据存储全部都是在内存中的，成本昂贵。建议根据业务只将高频热数据存储到Redis中【QPS大于5000】，对于低频冷数据可以使用MySQL&#x2F;ElasticSearch&#x2F;MongoDB等基于磁盘的存储方式，不仅节省内存成本，而且数据量小在操作时速度更快、效率更高！ 2.不同的业务数据要分开存储不要将不相关的业务数据都放到一个Redis实例中，建议新业务申请新的单独实例。因为Redis为单线程处理，独立存储会减少不同业务相互操作的影响，提高请求响应速度；同时也避免单个实例内存数据量膨胀过大，在出现异常情况时可以更快恢复服务！ 3.存储的Key一定要设置超时时间如果应用将Redis定位为缓存Cache使用，对于存放的Key一定要设置超时时间！因为若不设置，这些Key会一直占用内存不释放，造成极大的浪费，而且随着时间的推移会导致内存占用越来越大，直到达到服务器内存上限！另外Key的超时长短要根据业务综合评估，而不是越长越好！ 4.对于必须要存储的大文本数据一定要压缩后存储对于大文本【超过500字节】写入到Redis时，一定要压缩后存储！大文本数据存入Redis，除了带来极大的内存占用外，在访问量高时，很容易就会将网卡流量占满，进而造成整个服务器上的所有服务不可用，并引发雪崩效应，造成各个系统瘫痪！ 5.线上Redis禁止使用Keys正则匹配操作Redis是单线程处理，在线上KEY数量较多时，操作效率极低【时间复杂度为O(N)】，该命令一旦执行会严重阻塞线上其它命令的正常请求，而且在高QPS情况下会直接造成Redis服务崩溃！如果有类似需求，请使用scan命令代替！ 6.可靠的消息队列服务Redis List经常被用于消息队列服务。假设消费者程序在从队列中取出消息后立刻崩溃，但由于该消息已经被取出且没有被正常处理，那么可以认为该消息已经丢失，由此可能会导致业务数据丢失，或业务状态不一致等现象发生。为了避免这种情况，Redis提供了RPOPLPUSH命令，消费者程序会原子性的从主消息队列中取出消息并将其插入到备份队列中，直到消费者程序完成正常的处理逻辑后再将该消息从备份队列中删除。同时还可以提供一个守护进程，当发现备份队列中的消息过期时，可以重新将其再放回到主消息队列中，以便其它的消费者程序继续处理。 7.谨慎全量操作Hash、Set等集合结构在使用HASH结构存储对象属性时，开始只有有限的十几个field，往往使用HGETALL获取所有成员，效率也很高，但是随着业务发展，会将field扩张到上百个甚至几百个，此时还使用HGETALL会出现效率急剧下降、网卡频繁打满等问题【时间复杂度O(N)】,此时建议根据业务拆分为多个Hash结构；或者如果大部分都是获取所有属性的操作,可以将所有属性序列化为一个STRING类型存储！同样在使用SMEMBERS操作SET结构类型时也是相同的情况！ 8.根据业务场景合理使用不同的数据结构类型目前Redis支持的数据库结构类型较多：字符串（String），哈希（Hash），列表（List），集合（Set），有序集合（Sorted Set）, Bitmap, HyperLogLog和地理空间索引（geospatial）等,需要根据业务场景选择合适的类型，常见的如：String可以用作普通的K-V、计数类；Hash可以用作对象如商品、经纪人等，包含较多属性的信息；List可以用作消息队列、粉丝&#x2F;关注列表等；Set可以用于推荐；Sorted Set可以用于排行榜等！ 9.命名规范redis的key命名尽量简单明确，容易阅读理解，如：系统名+业务名+业务数据+其他 10.线上禁止使用monitor命令禁止生产环境使用monitor命令，monitor命令在高并发条件下，会存在内存暴增和影响Redis性能的隐患 11.禁止大string核心集群禁用1mb的string大key(虽然redis支持512MB大小的string)，如果1mb的key每秒重复写入10次，就会导致写入网络IO达10MB; 12.redis容量单实例的内存大小不建议过大，建议在10~20GB以内。redis实例包含的键个数建议控制在1kw内，单实例键个数过大，可能导致过期键的回收不及时。","raw":null,"content":null,"categories":[{"name":"研发规范","slug":"研发规范","permalink":"https://blog.bosong.online/categories/%E7%A0%94%E5%8F%91%E8%A7%84%E8%8C%83/"}],"tags":[{"name":"redis","slug":"redis","permalink":"https://blog.bosong.online/tags/redis/"}]}]}